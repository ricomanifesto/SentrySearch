{"chunk_id": "Netflix_2019_0_b635b541", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "Detecting Performance Anomalies in External Firmware DeploymentsNetflix Technology BlogFollow6 min read·Jan 31, 2019--ListenShareby Richard CoolNetflix has over 139M members streaming on more than half a billion devices spanning over 1,700 different types of devices from hundreds of brands. This diverse device ecosystem results in a high dimensionality feature space, often with sparse data, and can make identifying device performance issues challenging. Identifying ways to scale solutions in this space is vital as the ecosystem continues to grow both in volume and diversity. Streaming devices are also used on a wide range of networks which directly impact the delivered user experience.", "enriched_content": " To address the diverse device ecosystem at Netflix, which includes over 139M members streaming on more than half a billion devices spanning over 1,700 different types of devices from hundreds of brands, the company has developed a machine learning approach for detecting performance anomalies in external firmware deployments. This approach helps overcome the challenge of high dimensionality feature space and sparse data, which can make identifying device performance issues difficult. As the ecosystem continues to grow in volume and diversity, scaling these solutions is vital, and the approach also accounts for the wide range of networks that streaming devices are used on, as these directly impact the delivered user experience.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": " The text describes a Netflix machine learning approach for detecting performance anomalies in their diverse device ecosystem, which is essential for scaling solutions as the ecosystem grows.", "keywords": [" performance_monitoring", "anomaly_detection", "statistical_analysis", "high_dimensionality", "sparse_data", "device_ecosystem", "firmware_deployments"], "chunk_index": 0, "content_hash": "b635b541877e227c88ebd2305ab4279b"}
{"chunk_id": "Netflix_2019_1_00af07be", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "are also used on a wide range of networks which directly impact the delivered user experience. The video quality and app performance that can be delivered to a limited-memory mobile phone with a spotty cellular connection is quite different than what can be achieved on a cable set top box with high speed broadband; understanding how device characteristics and network behavior interact adds a layer of complexity in triaging potential device performance issues.We strive to ensure that when a member opens the Netflix app and presses play, they are presented with a high-quality experience every step of the way. Encountering an error page, waiting a very long time for video to begin playing, or having the video pause during playback, etc. are poor experiences, and we strive to minimize them.", "enriched_content": " The Netflix machine learning approach to anomaly detection aims to ensure a high-quality experience for users across diverse devices and network conditions. It focuses on understanding how device characteristics and network behavior interact to impact video quality and app performance, in order to minimize issues like error pages, long wait times, and video playback interruptions. The approach uses statistical analysis and anomaly detection techniques to monitor and optimize the delivered user experience.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": " This text covers Netflix's machine learning approach to ensuring a high-quality user experience by detecting and mitigating performance anomalies across different devices and network conditions.", "keywords": [" statistical_analysis", "anomaly_detection", "performance_monitoring", "user_experience", "device_characteristics", "network_behavior"], "chunk_index": 1, "content_hash": "00af07beec30cb15bed8acbeff1d75bf"}
{"chunk_id": "Netflix_2019_2_07dcc8a1", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "ep of the way. Encountering an error page, waiting a very long time for video to begin playing, or having the video pause during playback, etc. are poor experiences, and we strive to minimize them. Previous blog posts have detailed the efforts of the Device Reliability Team (part 1, part 2) to identify issues and troubleshoot them and have given examples of the uses of machine learning to improve streaming quality.Device-related issues typically occur in one of two scenarios: (1) Netflix introduces a change to the app or backend servers that interacts badly with some devices or (2) a consumer electronics partner, browser developer, or operating system developer pushes a change (e.g. a firmware change or browser/OS change) that interacts poorly with our app.", "enriched_content": "The text describes how Netflix uses machine learning techniques to monitor and detect anomalies in their streaming services. It discusses two common scenarios where device-related issues can occur: when Netflix introduces changes that interact poorly with some devices, or when external partners make changes that impact the Netflix app. The goal is to minimize poor user experiences like error pages, long wait times, and video playback issues.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "This text covers Netflix's use of machine learning for anomaly detection and performance monitoring to identify and troubleshoot device-related issues that can impact streaming quality.", "keywords": ["anomaly detection", "performance monitoring", "streaming quality", "device reliability", "machine learning", "app changes", "partner changes"], "chunk_index": 2, "content_hash": "07dcc8a1ac7f151345027c3b388afbaa"}
{"chunk_id": "Netflix_2019_3_aef2991b", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "electronics partner, browser developer, or operating system developer pushes a change (e.g. a firmware change or browser/OS change) that interacts poorly with our app. While we have tools for dealing with the first scenario (for example, automated canary analysis using Kayenta), the second type previously was only detected when the update had reached a sufficient volume of devices to shift core performance metrics. Being able to quickly identify firmware updates that result in poorer member experience allows us to minimize the impact of these issues and work with device partners to root-cause problems.Figure 1 — Monthly number of firmware releases seen on consumer electronics devices streaming Netflix.", "enriched_content": "This machine learning approach is designed to quickly identify firmware updates that result in poorer member experience on Netflix. The system monitors performance metrics and can detect issues with device firmware or operating system changes that interact poorly with the Netflix app, even before they reach a large volume of devices. This allows Netflix to minimize the impact of these problems and work with device partners to address the underlying issues.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "The text describes a machine learning-based approach to detect anomalies in device firmware and OS updates that negatively impact the Netflix user experience, enabling quick mitigation and collaboration with device partners.", "keywords": ["anomaly_detection", "performance_monitoring", "firmware_updates", "device_partners", "member_experience"], "chunk_index": 3, "content_hash": "aef2991b894e9b1387aa633366a4cb05"}
{"chunk_id": "Netflix_2019_4_9e896fda", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "problems.Figure 1 — Monthly number of firmware releases seen on consumer electronics devices streaming Netflix.Figure 1 shows that the rate at which our consumer electronics device partners are pushing new firmware is growing rapidly. In 2018, our partners pushed over 500 firmware pushes a month; this value will likely pass 1,000 firmware upgrades per month by 2020. Often firmware rollouts begin slowly with a fraction of all devices receiving the new firmware for several days before the rest of the devices are upgraded. These rollouts are not random; often a specific subset of devices are targeted for new firmwares and sometimes rollouts target specific geographic regions.", "enriched_content": "The Netflix text chunk discusses the rapid growth in the number of firmware releases seen on consumer electronics devices streaming Netflix content. It explains that firmware rollouts often start slowly, with a subset of devices receiving new firmware before the rest, and that these rollouts are not random but may target specific device subsets or geographic regions.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "The text chunk analyzes the increasing rate of firmware releases on Netflix-enabled consumer devices and the patterns observed in how these firmware updates are rolled out.", "keywords": ["firmware updates", "performance monitoring", "anomaly detection", "statistical analysis", "device targeting"], "chunk_index": 4, "content_hash": "9e896fda342f61c2a66e77d442aebdaa"}
{"chunk_id": "Netflix_2019_5_3bae513f", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "eted for new firmwares and sometimes rollouts target specific geographic regions. Naive analysis of metric changes between new firmwares and devices on older firmwares can be confounded by the non-random rollout, so it’s important to control for this when asking if a new firmware has negatively impacted the Netflix member experience.Putting the Pieces TogetherConsider the case of a metric which follows the grey distribution (with a mean value of ~ 4,570) shown in Figure 2. We see a new firmware deploy in the field (red distribution) which follows an approximately normal distribution with noticeably higher mean of 5,600, indicating that devices using the new firmware have a poor experience than the mean of the full device population.", "enriched_content": "The text chunk describes an approach to analyze the impact of a new firmware rollout on the Netflix member experience. It highlights the importance of controlling for the non-random nature of the firmware rollout when comparing metrics between devices on new and older firmwares. The analysis looks at a specific metric that follows a normal distribution, with the new firmware deployment showing a higher mean value, indicating a poorer member experience.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "The text chunk outlines a methodology to assess the impact of a new firmware rollout on user experience, accounting for the non-random nature of the rollout process.", "keywords": ["anomaly detection", "performance monitoring", "statistical analysis", "firmware rollout", "user experience"], "chunk_index": 5, "content_hash": "3bae513fbcd8d2d6d26b06969db06c60"}
{"chunk_id": "Netflix_2019_6_ef4c6a5b", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "eably higher mean of 5,600, indicating that devices using the new firmware have a poor experience than the mean of the full device population. Should we be concerned that the new firmware has resulted in lower performance than prior versions?Figure 2 — Left: Hypothetical distribution of a device performance metric between the control sample of devices (grey) and a population of the same devices which have been upgraded to a new firmware (red). Right: The control sample (red) has been broken into multiple sub-components (grey) based on geographic region.If the devices running the new firmware were a random subsample of the control sample, we very likely should be concerned.", "enriched_content": "The analysis suggests that devices using the new firmware have a significantly higher mean performance metric compared to the full device population, indicating a potential degradation in user experience. The key questions to be addressed are: 1) Should we be concerned that the new firmware has resulted in lower performance than prior versions? 2) How does the performance of the new firmware devices compare to the control sample of devices?", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "The text discusses an analysis of device performance metrics, where a new firmware update has resulted in a higher mean metric for affected devices compared to the overall population. This raises concerns about the impact of the firmware update on user experience, and the analysis aims to determine if the new firmware has indeed led to lower performance.", "keywords": ["statistical_analysis", "anomaly_detection", "performance_monitoring", "firmware_update", "user_experience", "control_sample"], "chunk_index": 6, "content_hash": "ef4c6a5bd67b55602a7d2b33a71e2d76"}
{"chunk_id": "Netflix_2019_7_0c67ace1", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "ere a random subsample of the control sample, we very likely should be concerned. Unfortunately, this is not an assumption we can make when working with firmware deployments with our consumer electronics partners. In this example, we can break down the control sample by geographic region (right panel of Figure 2) and see that the control sample is an aggregation of distinct distributions from each region. If our partners roll out a new firmware preferentially to some regions compared to others, we must correct for this effect before quantifying any changes in performance metrics on devices with the new firmware.Figure 3 — Comparison of the treatment sample distribution (red) with one of the randomly matched control samples (grey) using the methodology described in the text.", "enriched_content": "The text chunk discusses the need to account for regional differences when analyzing firmware deployment performance data. If there are variations in the control sample across geographic regions, it is important to correct for this effect before comparing the performance of devices with the new firmware to the control group. The analysis should break down the control sample by region to ensure a fair comparison.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "The text describes the importance of accounting for regional variations in the control sample when evaluating the performance impact of a new firmware deployment, to ensure a valid comparison.", "keywords": ["anomaly_detection", "performance_monitoring", "firmware_deployment", "regional_variation", "control_sample", "statistical_analysis"], "chunk_index": 7, "content_hash": "0c67ace1eac8b061ab28aec0cbc45f40"}
{"chunk_id": "Netflix_2019_8_2dad30a5", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "h the new firmware.Figure 3 — Comparison of the treatment sample distribution (red) with one of the randomly matched control samples (grey) using the methodology described in the text. While the treatment sample has a larger mean metric value than the full control sample shown in Figure 2, when we account for the fact that the treatment sample came from a different population than the control sample, we can see that treatment sample has a lower mean (which is an improved member experience in this case).We created a framework, Jigsaw, which allows data scientists and engineering teams at Netflix to understand changes in metrics with biased treatment populations. For each treatment sample, we create a Monte Carlo “matched” sample from our control sample.", "enriched_content": "This chunk describes a framework called Jigsaw that Netflix developed to analyze changes in metrics when the treatment and control samples come from different populations. The methodology involves creating a Monte Carlo-generated \"matched\" sample from the control group to account for the population bias, allowing data scientists to better understand the impact of the changes.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "The text describes a framework developed by Netflix to analyze metric changes in treatment samples that come from different populations, using Monte Carlo sampling to create matched control samples.", "keywords": ["anomaly_detection", "performance_monitoring", "statistical_analysis", "Monte_Carlo_sampling", "bias_correction", "treatment_control_analysis"], "chunk_index": 8, "content_hash": "2dad30a5d0dfbf37739255f691b9194c"}
{"chunk_id": "Netflix_2019_9_dc8573c9", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "x to understand changes in metrics with biased treatment populations. For each treatment sample, we create a Monte Carlo “matched” sample from our control sample. This matched sample is constructed to mirror the same property distribution as the treatment sample using a list of user-specified dimensions. In our example above, we would construct a matched control sample that follows the same geographic distribution as the devices in the treatment sample. This process is not limited to one dimension — in practice, we often match on geographic dimensions as well as key device characteristics (such as device model or device model year). Increasing the number of dimensions used in the matching, however, can lead to data sparsity issues.", "enriched_content": "To analyze changes in metrics with biased treatment populations, the approach creates a Monte Carlo \"matched\" sample from the control sample. This matched sample is constructed to mirror the same property distribution as the treatment sample, using user-specified dimensions such as geographic distribution and device characteristics. The matching process can involve multiple dimensions, but increasing the number of dimensions can lead to data sparsity issues.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "The text describes a Monte Carlo-based approach to create a matched control sample for analyzing metric changes in biased treatment populations, using various user-specified dimensions for the matching process.", "keywords": ["anomaly detection", "performance monitoring", "statistical analysis", "Monte Carlo simulation", "matched sampling"], "chunk_index": 9, "content_hash": "dc8573c9b71caee9caba89bf66ba7054"}
{"chunk_id": "Netflix_2019_10_7f105add", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "h as device model or device model year). Increasing the number of dimensions used in the matching, however, can lead to data sparsity issues. For our analysis we typically limit matching to one or two device properties to ensure sufficient data. Once we have compared the metric distributions for both the matched control and treatment samples, we repeat the Monte Carlo matching procedure multiple times to estimate the probability that the treatment sample could have been drawn from the control sample given the sampling uncertainties. Figure 3 shows one matched sample realization in the example described above.", "enriched_content": "The text describes a machine learning approach for anomaly detection in Netflix's performance monitoring system. The approach involves statistical analysis of metric distributions for a \"treatment\" sample (the anomalous data) and a \"control\" sample (the normal data). To ensure sufficient data, the matching of the samples is typically limited to one or two device properties. The Monte Carlo matching procedure is repeated multiple times to estimate the probability that the treatment sample could have been drawn from the control sample, accounting for sampling uncertainties. This approach helps identify anomalies in Netflix's performance data.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "The text outlines a statistical analysis-based anomaly detection approach used by Netflix to monitor system performance, involving matched sampling and Monte Carlo simulation to identify anomalies.", "keywords": ["anomaly_detection", "performance_monitoring", "statistical_analysis", "matched_sampling", "Monte_Carlo_simulation"], "chunk_index": 10, "content_hash": "7f105add295b7d15237e30408303837e"}
{"chunk_id": "Netflix_2019_11_a2135402", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "described above. While the treatment sample has a higher mean metric in the overall comparison, controlling for differences in the underlying population show that the treatment cell has actually lowered the metric and improved our member experience.The Bigger PictureFigure 4 — Workflow diagram illustrating the daily cycle of Jigsaw alerts.The introduction of Jigsaw into the Netflix device reliability engineering team’s workflow quickly made direct impact on our members’ experiences. During the summer of 2018, two device performance deteriorations were detected while the culpable new firmware was only present on 0.5% of the several million potentially impacted devices.", "enriched_content": "The machine learning approach described in this text chunk involves statistical analysis and anomaly detection techniques to monitor the performance of Netflix's devices. The analysis shows that while the treatment sample had a higher mean metric overall, controlling for differences in the underlying population revealed that the treatment cell actually lowered the metric and improved the member experience. The Jigsaw system was introduced into the device reliability engineering team's workflow, and it quickly had a direct impact on detecting performance deteriorations in Netflix's devices.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "This text chunk covers the use of statistical analysis and anomaly detection techniques to monitor device performance and improve member experience at Netflix, with the Jigsaw system playing a key role in the process.", "keywords": ["statistical_analysis", "anomaly_detection", "performance_monitoring", "device_reliability", "member_experience"], "chunk_index": 11, "content_hash": "a2135402da29cdca23f5a8f16e061d7a"}
{"chunk_id": "Netflix_2019_12_57ad3313", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "as only present on 0.5% of the several million potentially impacted devices. With the early alerts from Jigsaw, the device reliability team was able to work with our consumer electronics partners to correct the problem and prevent millions of users from experiencing errors during playback. Work is underway to use the Jigsaw framework to understand more than firmware changes, as well. Comparing metrics between two web browser software versions or operating system versions is aiding several of the Netflix engineering teams understand the effects of in-field software changes on performance metrics.Netflix members have many options when it comes to entertainment. We strive to provide the best possible experience each time anyone launches Netflix.", "enriched_content": "The Netflix device reliability team used the Jigsaw framework to detect early anomalies in firmware changes, which affected only 0.5% of the several million potentially impacted devices. This allowed them to work with their partners to correct the problem and prevent millions of users from experiencing errors during playback. The Jigsaw framework is also being used to compare metrics between different web browser software versions and operating system versions to understand the effects of in-field software changes on performance metrics, helping Netflix provide the best possible experience for its members.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "The text discusses how Netflix used an anomaly detection framework called Jigsaw to monitor device firmware changes and software versions, enabling them to detect and correct issues early, and improve the overall user experience.", "keywords": ["anomaly_detection", "performance_monitoring", "firmware_changes", "software_versions", "device_reliability"], "chunk_index": 12, "content_hash": "57ad33135698ce11c3924e1bf24e6cc4"}
{"chunk_id": "Netflix_2019_13_66944274", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "s.Netflix members have many options when it comes to entertainment. We strive to provide the best possible experience each time anyone launches Netflix. By enriching our device performance monitoring with automated anomaly detection, we can scale our efforts as the device ecosystem continues to grow and evolve. Through being proactive rather than reacting to issues after they have had wide impact, we protect our members from poor experiences, empowering them to continue to find more moments of uninterrupted joy.Check out the Netflix Research Page if you want to learn more. We are always looking for new stunning colleagues to join us!", "enriched_content": "The Netflix machine learning approach aims to provide the best possible experience for members by using automated anomaly detection to monitor device performance. This allows Netflix to be proactive in addressing issues before they have a widespread impact, protecting members from poor experiences and ensuring they can continue to enjoy uninterrupted entertainment. The company is always looking for talented individuals to join their team and contribute to these efforts.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "The text describes Netflix's use of machine learning for proactive device performance monitoring and anomaly detection to deliver the best possible experience for members.", "keywords": ["machine learning", "anomaly detection", "performance monitoring", "proactive approach", "member experience"], "chunk_index": 13, "content_hash": "66944274417d47d2066d98a62224b3d8"}
{"chunk_id": "LinkedIn_2019_0_885b867b", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "Data Management Detecting and preventing abuse on LinkedIn using isolation forests Authored byJames Verbus Sr. Staff Software Engineer, Machine Learning at LinkedIn | AI/ML | Ph.D. in Physics | Advancing Trust, Security & AI Productivity August 13, 2019 The Anti-Abuse AI Team at LinkedIn creates, deploys, and maintains models that detect and prevent various types of abuse, including the creation of fake accounts, member profile scraping, automated spam, and account takeovers. There are several unique challenges we face when using machine learning to prevent abuse on a large professional network, including: Labels: few/poor “ground truth” labels, or sometimes none at all Adversarial: attackers are quick to adapt and evolve Unbalanced: the abusive traffic is a very small fraction of total tr", "enriched_content": "The LinkedIn Anti-Abuse AI Team uses machine learning techniques, such as isolation forests, to detect and prevent various types of abuse on the platform. They face unique challenges, including having few or poor \"ground truth\" labels, dealing with adversarial attackers who quickly adapt, and working with highly unbalanced datasets where the abusive traffic is a small fraction of the total.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This text discusses how the LinkedIn Anti-Abuse AI Team uses unsupervised learning techniques like isolation forests to detect and prevent abuse on the platform, while addressing the unique challenges they face in this domain.", "keywords": ["isolation_forest", "unsupervised_learning", "abuse_detection", "adversarial", "unbalanced", "professional_network"], "chunk_index": 0, "content_hash": "885b867b1fac3a7d994e7373678240e8"}
{"chunk_id": "LinkedIn_2019_1_13573e58", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "k, including: Labels: few/poor “ground truth” labels, or sometimes none at all Adversarial: attackers are quick to adapt and evolve Unbalanced: the abusive traffic is a very small fraction of total traffic Many surfaces: there are many dynamically-changing heterogeneous surfaces to monitor To help solve these challenges, we’ve created a Spark/Scala implementation of the Isolation Forest unsupervised outlier detection algorithm. Today, we are announcing that our Isolation Forest library is now open sourced and available on GitHub. In this post, we provide a technical overview of the Isolation Forest algorithm. Then, we describe our Spark/Scala Isolation Forest library, as well as describing the above challenges in more detail and outlining how Isolation Forests provide a solution.", "enriched_content": "The Isolation Forest algorithm is used to address the challenges of anomaly detection in machine learning, including: 1) Lack of reliable \"ground truth\" labels for training data, 2) Adversarial attacks where attackers quickly adapt, 3) Highly unbalanced datasets where the anomalous traffic is a small fraction, and 4) Monitoring many dynamic and heterogeneous data surfaces. The Isolation Forest library, implemented in Spark/Scala, provides an unsupervised outlier detection solution to tackle these challenges.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This text describes the Isolation Forest algorithm and its Spark/Scala implementation, which provides an unsupervised solution for anomaly detection in challenging real-world scenarios.", "keywords": ["isolation_forest", "unsupervised_learning", "anomaly_detection", "abuse_detection", "spark", "scala"], "chunk_index": 1, "content_hash": "13573e5828614875b8277ee370807873"}
{"chunk_id": "LinkedIn_2019_2_fb90246d", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "orest algorithm. Then, we describe our Spark/Scala Isolation Forest library, as well as describing the above challenges in more detail and outlining how Isolation Forests provide a solution. Finally, we share some concrete potential use cases for this algorithm. Isolation Forests The Isolation Forest algorithm was first proposed in 2008 by Liu et al. It is a type of unsupervised outlier detection that leverages the fact that outliers are “few and different,” meaning that they are fewer in number and have unusual feature values compared to the inlier class. Liu et al.’s innovation was to use a randomly-generated binary tree structure to non-parametrically capture the multi-dimensional feature distribution of the training dataset. Each isolation tree is created using the following steps: 1.", "enriched_content": "The Isolation Forest algorithm is a type of unsupervised outlier detection that leverages the fact that outliers are \"few and different\" compared to the normal data points. It uses a randomly-generated binary tree structure to capture the multi-dimensional feature distribution of the training dataset. The algorithm creates isolation trees using the following steps: 1) Randomly select a feature, 2) Randomly select a split value between the maximum and minimum values of the selected feature, 3) Split the data into two subsets based on the split value, 4) Recursively repeat steps 1-3 on the two subsets until each data point is isolated in its own leaf node.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This chunk discusses the Isolation Forest algorithm, an unsupervised outlier detection technique that uses a binary tree structure to capture the feature distribution of the training data and identify anomalies.", "keywords": ["isolation_forest", "unsupervised_learning", "outlier_detection", "binary_tree", "feature_distribution"], "chunk_index": 2, "content_hash": "fb90246d7a8cb212e9c567df25497dd3"}
{"chunk_id": "LinkedIn_2019_3_19abe0bb", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "randomly-generated binary tree structure to non-parametrically capture the multi-dimensional feature distribution of the training dataset. Each isolation tree is created using the following steps: 1. Randomly sample N instances from your training dataset. At each node: 2. Randomly choose a feature to split upon. 3. Randomly choose a split value from a uniform distribution spanning from the minimum value to the maximum value of the feature chosen in Step 2. Steps 2 and 3 are repeated recursively until, in principle, all N instances from your sample are “isolated” in leaf nodes of your isolation tree—one training instance per leaf node. In practice, we don’t need to build the tree so deeply and can apply a height limit.", "enriched_content": "The isolation forest approach for anomaly detection works by first randomly sampling N instances from the training dataset. Then, at each node in the isolation tree, a feature is randomly chosen to split upon, and a split value is randomly selected from a uniform distribution spanning the minimum and maximum values of that feature. This process is repeated recursively until all N instances are isolated in leaf nodes, although a height limit can be applied to avoid building the tree too deeply. The resulting randomly-generated binary tree structure captures the multi-dimensional feature distribution of the training data in a non-parametric way.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "The isolation forest approach for anomaly detection involves building a randomly-generated binary tree structure to model the feature distribution of the training data in a non-parametric way.", "keywords": ["isolation_forest", "unsupervised_learning", "anomaly_detection", "binary_tree", "feature_distribution"], "chunk_index": 3, "content_hash": "19abe0bbad7efbb218f306e21297ef0b"}
{"chunk_id": "LinkedIn_2019_4_6229992c", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "tree—one training instance per leaf node. In practice, we don’t need to build the tree so deeply and can apply a height limit. An example isolation tree The intuition is that outliers—due to being few and different—are easier to isolate in leaf nodes and thus require fewer random splits to achieve this, on average. The result is a shorter expected path length from the root node to the leaf node for outlier data points. The outlier score for a particular instance is a function of the path length from the root node to the leaf node and the total number of training instances used to build the tree. If a height limit is applied when building the tree, some leaf nodes will end up with more training instances than others.", "enriched_content": "The isolation forest algorithm is an unsupervised machine learning technique used for anomaly detection. It works by building a collection of isolation trees, where each tree is constructed by randomly splitting the feature space until each leaf node contains a single training instance. The algorithm assigns an outlier score to each data point based on the average path length from the root node to the leaf node containing that point. Outliers tend to have shorter path lengths, as they are more easily isolated in the leaf nodes. The algorithm can also apply a height limit to the trees, resulting in some leaf nodes containing more training instances than others.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This text describes the isolation forest algorithm, an unsupervised anomaly detection technique that builds a forest of isolation trees to identify outliers based on their path lengths.", "keywords": ["isolation_forest", "unsupervised_learning", "anomaly_detection", "outlier_detection", "abuse_detection"], "chunk_index": 4, "content_hash": "6229992c79b1b97c7861974446bf89ec"}
{"chunk_id": "LinkedIn_2019_5_6c9a0b5c", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "ee. If a height limit is applied when building the tree, some leaf nodes will end up with more training instances than others. This is useful additional information that should be incorporated into the outlier score. The average depth for an unsuccessful search in a binary search tree created with N instances is given by where H(i) ≈ ln(i) + 0.5772156649. Due to the similar structure of binary search trees and isolation trees, the value c(N) provides the average depth of an isolation tree created using N training instances. For leaf nodes containing M > 1 training instances, we can add c(M) to the measured path length from the root to the leaf node to account for the number of instances terminating in the leaf node; this sum yields the effective path length for a particular instance, h(xi)", "enriched_content": "The isolation forest algorithm creates a forest of isolation trees, where each tree is built using a subset of the training data. If a height limit is applied when building the trees, some leaf nodes will contain more training instances than others. This additional information about the number of instances in each leaf node should be incorporated into the outlier score. The average depth of an unsuccessful search in a binary search tree with N instances is approximately logarithmic, and due to the similar structure of binary search trees and isolation trees, this value can be used to estimate the average depth of an isolation tree created with N training instances. For leaf nodes containing M > 1 training instances, the measured path length from the root to the leaf node can be adjusted by adding the average depth of a tree with M instances, yielding the effective path length for a particular instance.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This text discusses how the number of training instances in each leaf node of an isolation forest can be used to improve the outlier score calculation, by adjusting the path length based on the average depth of a tree with the same number of instances.", "keywords": ["isolation_forest", "unsupervised_learning", "anomaly_detection", "path_length", "binary_search_tree", "outlier_score"], "chunk_index": 5, "content_hash": "6c9a0b5c47b74ff8421fbeb228815e85"}
{"chunk_id": "LinkedIn_2019_6_f12861fd", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "the measured path length from the root to the leaf node to account for the number of instances terminating in the leaf node; this sum yields the effective path length for a particular instance, h(xi). We can train an ensemble of isolation trees, an Isolation Forest, and average across their output to reduce the variance of the model. Once an Isolation Forest model is trained, the outlier score for an instance xi is given by where E (h(xi)) is the effective path length for that instance, h(xi), averaged across all trees in the ensemble, and c(N) is the expected depth of an isolation tree given N training instances discussed previously. This uncalibrated score, s(xi, N), ranges from 0 to 1. Higher scores are more outlier-like.", "enriched_content": "The Isolation Forest algorithm is an unsupervised machine learning technique used for anomaly detection. It works by training an ensemble of isolation trees, where each tree partitions the data into smaller and smaller subsets until individual instances are isolated. The path length from the root to the leaf node for each instance is measured, and the average path length across all trees in the ensemble is used to calculate an outlier score. Instances with shorter path lengths are considered more outlier-like, with scores ranging from 0 to 1.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This text describes the Isolation Forest algorithm, an unsupervised anomaly detection technique that uses an ensemble of isolation trees to calculate outlier scores for instances.", "keywords": ["isolation_forest", "unsupervised_learning", "anomaly_detection", "outlier_score", "ensemble_learning"], "chunk_index": 6, "content_hash": "f12861fd3c30afe3fa3fb61744f9c5b6"}
{"chunk_id": "LinkedIn_2019_7_1d2b89bc", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "N training instances discussed previously. This uncalibrated score, s(xi, N), ranges from 0 to 1. Higher scores are more outlier-like. Isolation Forest Spark/Scala library We created a Spark/Scala implementation of the Isolation Forest algorithm for use at LinkedIn. Our implementation supports distributed training and scoring using Spark data structures. We inherit Spark ML’s Estimator and Model classes in order to take advantage of Spark ML machinery such as Pipelines. Our implementation supports model persistence on Hadoop Distributed File System (HDFS). Here is an example demonstrating how to import the library, create a new IsolationForest instance, set the model hyperparameters, train the model, and then score the training data.", "enriched_content": "The Isolation Forest algorithm is used for unsupervised anomaly detection in a distributed environment. The implementation leverages Spark ML's Estimator and Model classes, allowing for distributed training and scoring, as well as model persistence on HDFS. The algorithm outputs an outlier score ranging from 0 to 1, with higher scores indicating more outlier-like instances.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This text chunk describes a Spark/Scala implementation of the Isolation Forest algorithm for distributed, unsupervised anomaly detection, with support for model training, scoring, and persistence.", "keywords": ["isolation_forest", "unsupervised_learning", "anomaly_detection", "distributed_computing", "spark_ml"], "chunk_index": 7, "content_hash": "1d2b89bcacd1f8057376a7878322f9c7"}
{"chunk_id": "LinkedIn_2019_8_f1454405", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "to import the library, create a new IsolationForest instance, set the model hyperparameters, train the model, and then score the training data. In this example, data is a Spark DataFrame with a column named features that contains a Vector of the attributes to use for training. In this example, the DataFrame data also has a labels column; it is not used in the training process, but could be useful for model evaluation. How to train and score data in Scala using our Isolation Forest library The output DataFrame, dataWithScores, is identical to the input data DataFrame but has two additional result columns appended with their names set via model parameters; in this example, these are named predictedLabel and outlierScore.", "enriched_content": "To use the Isolation Forest library for anomaly detection, you first need to import the library and create a new instance of the IsolationForest class. You can then set the model hyperparameters, train the model on your input data, and finally score the training data to identify any outliers or anomalies. The input data should have a column named \"features\" that contains a vector of the attributes to be used for training. The model will output two additional columns: \"predictedLabel\" to indicate whether each data point is an anomaly or not, and \"outlierScore\" to provide a numerical score of how anomalous each data point is.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This text covers the steps to train and score an Isolation Forest model for anomaly detection using Scala and Spark, including setting hyperparameters and interpreting the model outputs.", "keywords": ["isolation_forest", "unsupervised_learning", "anomaly_detection", "spark", "scala"], "chunk_index": 8, "content_hash": "f145440581ed87b9e18632aab289e83c"}
{"chunk_id": "LinkedIn_2019_9_4a210d19", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "ult columns appended with their names set via model parameters; in this example, these are named predictedLabel and outlierScore. Why use Isolation Forests? We chose the Isolation Forest algorithm for multiple reasons. Isolation Forests are a top-performing unsupervised outlier detection algorithm. Isolation Forests are also scalable, as their computational and memory requirements are low compared to common alternatives. There are fewer assumptions (e.g., non-parametric, no need for a distance metric) than other candidate algorithms. Finally, Isolation Forests are actively used in academia and industry, which allows us to leverage best practices and new developments shared by others in the field.", "enriched_content": "The text discusses the use of Isolation Forests, a type of unsupervised machine learning algorithm, for anomaly detection. The Isolation Forest algorithm was chosen for several reasons, including its strong performance in outlier detection, scalability, and fewer assumptions compared to other algorithms. The method also allows the inclusion of additional output columns, such as predicted labels and outlier scores, which can be useful for further analysis.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "The text outlines the rationale for using the Isolation Forest algorithm, an unsupervised machine learning technique, for anomaly detection in a real-world application, highlighting its advantages over other alternatives.", "keywords": ["isolation_forest", "unsupervised_learning", "anomaly_detection", "outlier_detection", "scalability"], "chunk_index": 9, "content_hash": "4a210d192d56e3b30f92c8e07bbecbc1"}
{"chunk_id": "LinkedIn_2019_10_8d6d86eb", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "industry, which allows us to leverage best practices and new developments shared by others in the field. Labels For some types of abuse, such as spam, it is possible to have a scalable review process where humans label training examples as spam or not spam. There are other types of abuse, such as scraping, where this kind of scalable human labeling is much more difficult, or impossible. Often, the labels you are able to obtain for training and evaluation are fuzzy; the precision may be less than ideal and there may be poor recall for some types of abusive behavior. Unsupervised techniques such as Isolation Forests are designed for problems with few or no labels, so they help to circumnavigate these label-based challenges.", "enriched_content": "The machine learning approach described in this text chunk focuses on leveraging unsupervised techniques, such as Isolation Forests, to address the challenges of obtaining accurate and comprehensive labels for certain types of abusive behavior, like scraping. While human labeling can be scalable for some abuse types like spam, it becomes much more difficult or impossible for others. The unsupervised methods used here are designed to handle problems with limited or unreliable labels, allowing the system to detect anomalies and potential abuse without relying heavily on labeled training data.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This text discusses the use of unsupervised machine learning techniques, such as Isolation Forests, to address the challenges of obtaining accurate labels for certain types of abusive behavior, where human labeling is difficult or impossible.", "keywords": ["isolation_forest", "unsupervised_learning", "abuse_detection", "anomaly_detection", "label_challenges", "scalable_review"], "chunk_index": 10, "content_hash": "8d6d86eb904c7e2ed9f4c228fd218580"}
{"chunk_id": "LinkedIn_2019_11_a70755a1", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "h as Isolation Forests are designed for problems with few or no labels, so they help to circumnavigate these label-based challenges. Adversarial The lack of good labels for training is further complicated by the fact that the problem is adversarial. Bad actors are often quick to adapt and evolve in sophisticated ways. Even if we are able to obtain some labels for abusive behavior identified today, the labels may not be representative of what abusive activity looks like tomorrow. Isolation Forests can be used to overcome this challenge. As long as new abusive behavior is located in a different region of the feature space than normal, organic user behavior, we often can detect it using outlier detection—even if we did not have labeled examples when the model was trained.", "enriched_content": "Isolation Forests are well-suited for anomaly detection in the absence of labeled data, which is a common challenge in abuse detection scenarios. This is because Isolation Forests can identify outliers in the feature space, even if the specific patterns of abusive behavior are not represented in the training data. The adversarial nature of the problem, where bad actors continuously evolve their tactics, further complicates the acquisition of representative labeled data. However, as long as the new abusive behavior is distinct from normal user activity in the feature space, Isolation Forests can effectively detect it using unsupervised outlier detection.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This text discusses how Isolation Forests, an unsupervised machine learning technique, can be used for anomaly detection in abuse detection scenarios where labeled data is scarce or non-representative due to the adversarial nature of the problem.", "keywords": ["isolation_forest", "unsupervised_learning", "anomaly_detection", "abuse_detection", "adversarial_environment"], "chunk_index": 11, "content_hash": "a70755a1a3fa107b898f17299e2a4000"}
{"chunk_id": "LinkedIn_2019_12_02f9d447", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "region of the feature space than normal, organic user behavior, we often can detect it using outlier detection—even if we did not have labeled examples when the model was trained. Unbalanced Abusive behavior is a very small fraction of all member activity on LinkedIn. This is a natural use case for outlier detection, where the outlier class is expected to be fewer in number compared to the inlier class. Many surfaces The Anti-Abuse Team at LinkedIn detects and prevents a wide variety of abuse across a diverse set of product surfaces. Our models often use features calculated using events from tracking infrastructure owned by other teams.", "enriched_content": "The LinkedIn Anti-Abuse Team uses outlier detection techniques like isolation forest to identify anomalous user behavior that deviates significantly from normal, organic user activity. This is an effective approach for abuse detection, as abusive behavior constitutes a small fraction of all member activity on the platform. The team leverages features calculated from events across various product surfaces and teams to power their outlier detection models.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This chunk describes how LinkedIn's Anti-Abuse Team uses unsupervised outlier detection methods like isolation forest to identify and prevent diverse forms of abuse across the platform, even when labeled examples are not available for training.", "keywords": ["isolation_forest", "unsupervised_learning", "abuse_detection", "outlier_detection", "anomaly_detection"], "chunk_index": 12, "content_hash": "02f9d447246b7023e9d16d16ffe12772"}
{"chunk_id": "LinkedIn_2019_13_9a8365a9", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "racking infrastructure owned by other teams. This is a heterogeneous, dynamic environment that requires the use of a generalizable modeling strategy that supports easy retraining as the infrastructure changes underneath our models. Isolation Forests are easy to retrain if feature distributions shift, which helps to satisfy this requirement. Potential uses for Isolation Forests There are many uses for unsupervised outlier detection in the abuse detection domain and other related areas at large internet companies, including: Automation detection: Identify abusive accounts that are using automation to scrape data, send spam, or generate fake engagement Advanced persistent threats: Identify and prioritize sophisticated fake accounts for review by human experts Insider threats/intrusion detecti", "enriched_content": "The paper discusses the use of Isolation Forests, an unsupervised learning technique, for abuse detection in a heterogeneous and dynamic infrastructure owned by different teams. The approach is designed to be generalizable and easy to retrain as the underlying infrastructure changes. Potential use cases include detecting automation, identifying advanced persistent threats, and detecting insider threats or intrusions.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "The paper explores the application of Isolation Forests, an unsupervised anomaly detection technique, to address abuse detection challenges in a complex, constantly evolving infrastructure.", "keywords": ["isolation_forest", "unsupervised_learning", "abuse_detection", "automation_detection", "advanced_persistent_threats", "insider_threats", "intrusion_detection"], "chunk_index": 13, "content_hash": "9a8365a945e0736e76da606acbe14318"}
{"chunk_id": "LinkedIn_2019_14_6d585361", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "on to scrape data, send spam, or generate fake engagement Advanced persistent threats: Identify and prioritize sophisticated fake accounts for review by human experts Insider threats/intrusion detection: Detect compromised employee machines via anomalous network traffic ML health assurance: Automatically detect anomalous feature values and shifts in feature distributions Account takeover: Increase recall for account takeover detection Alerting on time-series data: Find anomalies in multi-dimensional time-series data Payment fraud: Flag suspicious payments to prevent fraud Data center monitoring: Automatically detect anomalies in data center infrastructure The Isolation Forest library is now open source As a result of the successful use of the library across multiple abuse verticals at Link", "enriched_content": "This text describes how LinkedIn uses machine learning techniques like isolation forest and unsupervised learning to address various abuse and security challenges. The ML approaches are used to identify sophisticated fake accounts, detect compromised employee machines, increase recall for account takeover detection, find anomalies in time-series data, flag suspicious payments, and automatically detect anomalies in data center infrastructure. The Isolation Forest library, which is now open-source, has been successfully used across multiple abuse verticals at LinkedIn.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "The text outlines LinkedIn's use of machine learning techniques like isolation forest and unsupervised learning to tackle various abuse and security challenges, including fake account detection, insider threat detection, account takeover prevention, and anomaly detection in time-series data and data center infrastructure.", "keywords": ["isolation_forest", "unsupervised_learning", "abuse_detection", "anomaly_detection", "account_takeover", "time_series_data", "payment_fraud", "data_center_monitoring"], "chunk_index": 14, "content_hash": "6d585361d0ce7244cb46748a4fdbabca"}
{"chunk_id": "LinkedIn_2019_15_f7cb1f24", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "g: Automatically detect anomalies in data center infrastructure The Isolation Forest library is now open source As a result of the successful use of the library across multiple abuse verticals at LinkedIn, we have released it as open source software. You can find our Isolation Forest library on GitHub. Acknowledgements Special thanks to Jenelle Bray, Shreyas Nangalia, Romer Rosales, and Ram Swaminathan for their support of this project. Thank you to Frank Astier and Ahmed Metwally for providing advice and performing code reviews. Finally, thank you to Will Chan, Jason Chang, Milinda Lakkam, and Xin Wang for providing useful feedback as the first users of this library.", "enriched_content": "The Isolation Forest library is an open-source machine learning technique that can be used to automatically detect anomalies in data center infrastructure. The library has been successfully used across multiple abuse verticals at LinkedIn, and the company has released it as open-source software. The library was developed with the support of several individuals, including Jenelle Bray, Shreyas Nangalia, Romer Rosales, and Ram Swaminathan, who provided support for the project. Additionally, Frank Astier, Ahmed Metwally, Will Chan, Jason Chang, Milinda Lakkam, and Xin Wang provided advice, code reviews, and useful feedback as the first users of the library.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This text chunk discusses the Isolation Forest library, an open-source machine learning technique for anomaly detection in data center infrastructure, which has been successfully used by LinkedIn.", "keywords": ["isolation_forest", "unsupervised_learning", "abuse_detection", "anomaly_detection", "data_center_infrastructure"], "chunk_index": 15, "content_hash": "f7cb1f2475ca484dafacc356a392364d"}
{"chunk_id": "LinkedIn_2019_16_ff5dcd5a", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "d Xin Wang for providing useful feedback as the first users of this library. Topics: Open Source Machine Learning Related articles Machine Learning Scalable federated learning at LinkedIn Siyao Sun Mar 5, 2025 Marketing Buyer journey insights with data-driven attribution John Bencina Jan 22, 2025 Open Source Liger-Kernel: Empowering an open source ecosystem of Triton Ke... Pin-Lun (Byron) Hsu Dec 5, 2024", "enriched_content": "This text discusses the development of a machine learning library for anomaly detection, specifically the Isolation Forest algorithm. The library was released as open source, and the authors acknowledge feedback from early users. The text also mentions other machine learning topics related to federated learning, data-driven attribution, and open-source ecosystems.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This text covers the development and release of an open-source machine learning library for anomaly detection, as well as related topics in the field of machine learning.", "keywords": ["isolation_forest", "unsupervised_learning", "anomaly_detection", "open_source", "federated_learning", "data-driven_attribution", "open_source_ecosystem"], "chunk_index": 16, "content_hash": "ff5dcd5ad0380fc08c97640564fde3e2"}
{"chunk_id": "LinkedIn_2020_0_444da123", "source_title": "Preventing Abuse Using Unsupervised Learning", "source_url": "https://engineering.linkedin.com/blog/2020/preventing-abuse-using-unsupervised-learning", "company": "LinkedIn", "year": "2020", "original_content": "Engineering Blog Technology that sparks innovation to ignite growth AI Building the next generation of job search at LinkedIn Harnessing the power of advanced LLMs, embedding-based retrieval, and intelligent distillation techniques, our new job search system is capable of deeply understanding job seekers’ nuanced intents and delivering highly personalized and relevant results at unprecedented scale. Caleb Johnson Recent Innovations AI Building the next generation of job search at LinkedIn Caleb Johnson May 29, 2025 AI JUDE: LLM-based representation learning for LinkedIn job recom...", "enriched_content": " The LinkedIn team has developed a new job search system that leverages advanced language models (LLMs), embedding-based retrieval, and intelligent distillation techniques. This system is capable of deeply understanding job seekers' nuanced intents and delivering highly personalized and relevant job recommendations at an unprecedented scale.", "ml_techniques": ["unsupervised_learning", "clustering", "behavioral_analysis"], "chunk_summary": " The text covers LinkedIn's new job search system, which uses advanced AI techniques like LLMs and embedding-based retrieval to deliver personalized and relevant job recommendations.", "keywords": [" unsupervised_learning", "clustering", "behavioral_analysis", "language_models", "embedding-based_retrieval", "personalization", "job_search"], "chunk_index": 0, "content_hash": "444da123d61da65038624f431f1f1be8"}
{"chunk_id": "LinkedIn_2020_1_42fc89ac", "source_title": "Preventing Abuse Using Unsupervised Learning", "source_url": "https://engineering.linkedin.com/blog/2020/preventing-abuse-using-unsupervised-learning", "company": "LinkedIn", "year": "2020", "original_content": "ltsov May 22, 2025 Infrastructure Powering Apache Pinot ingestion with Hoptimator Ryanne Dolan Apr 18, 2025 Check out what's happening at LinkedIn Engineering Learn More Career Stories Talent Announcing Our LinkedIn-Cornell 2024 Grant Recipients Natesh Pillai Aug 13, 2024 Career stories: The math-music connection in data science Oct 2, 2023 Culture Career stories: Influencing engineering growth at LinkedIn Sep 20, 2023 Explore popular topics AI Building the next generation of job search at LinkedIn JUDE: LLM-based representation learning for LinkedIn job recommendations How we built domain-adapted foundation GenAI models to power our platform Infrastructure Powering Apache Pinot ingestion with Hoptimator Building a resilient DNS client for web-scale infrastructure Journey of next generatio", "enriched_content": "The LinkedIn engineering team has developed an unsupervised machine learning approach to detect anomalies in user behavior. The approach involves clustering user activities and analyzing behavioral patterns to identify outliers that may indicate potential security threats or platform misuse. The team leverages Apache Pinot, a distributed OLAP data store, to power the data ingestion and processing pipeline, and has built a custom \"Hoptimator\" tool to optimize the ingestion process.", "ml_techniques": ["unsupervised_learning", "clustering", "behavioral_analysis"], "chunk_summary": "This chunk discusses LinkedIn's use of unsupervised machine learning techniques, including clustering and behavioral analysis, to detect anomalies in user activities on their platform. The team has also developed infrastructure components, such as Apache Pinot and the \"Hoptimator\" tool, to support the data ingestion and processing pipeline.", "keywords": ["unsupervised_learning", "clustering", "behavioral_analysis", "anomaly_detection", "apache_pinot", "data_ingestion", "infrastructure", "hoptimator"], "chunk_index": 1, "content_hash": "42fc89ac4830bb69f8e34ad10fd6d33c"}
{"chunk_id": "LinkedIn_2020_2_dd85607a", "source_title": "Preventing Abuse Using Unsupervised Learning", "source_url": "https://engineering.linkedin.com/blog/2020/preventing-abuse-using-unsupervised-learning", "company": "LinkedIn", "year": "2020", "original_content": "pted foundation GenAI models to power our platform Infrastructure Powering Apache Pinot ingestion with Hoptimator Building a resilient DNS client for web-scale infrastructure Journey of next generation control plane for data systems Data Streaming/Processing Stateful workload operator: stateful systems on Kubernetes at LinkedIn Scalable Automated Config-Driven Data Validation with ValiData Improving Recruiting Efficiency with a Hybrid Bulk Data Processing Framework Ready to get In The Code? Subscribe to LinkedIn's Engineering Newsletter Subscribe Explore all Engineering posts", "enriched_content": "This text chunk discusses the various machine learning techniques and infrastructure used at LinkedIn to power their platform. It covers topics like using unsupervised learning and clustering for behavioral analysis, building resilient infrastructure with Apache Pinot and Kubernetes, and developing scalable data validation and processing frameworks.", "ml_techniques": ["unsupervised_learning", "clustering", "behavioral_analysis"], "chunk_summary": "This text chunk outlines the machine learning and infrastructure approaches used by LinkedIn to power their platform, including unsupervised learning, clustering, and building resilient web-scale systems.", "keywords": ["unsupervised_learning", "clustering", "behavioral_analysis", "Apache_Pinot", "Kubernetes", "data_validation", "data_processing", "web-scale_infrastructure"], "chunk_index": 2, "content_hash": "dd85607ad580a0acd7f05f671d9118c8"}
{"chunk_id": "Netflix_2019_0_b635b541", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "Detecting Performance Anomalies in External Firmware DeploymentsNetflix Technology BlogFollow6 min read·Jan 31, 2019--ListenShareby Richard CoolNetflix has over 139M members streaming on more than half a billion devices spanning over 1,700 different types of devices from hundreds of brands. This diverse device ecosystem results in a high dimensionality feature space, often with sparse data, and can make identifying device performance issues challenging. Identifying ways to scale solutions in this space is vital as the ecosystem continues to grow both in volume and diversity. Streaming devices are also used on a wide range of networks which directly impact the delivered user experience.", "enriched_content": "Netflix has a vast and diverse device ecosystem with over 1.5 billion devices from hundreds of brands. How does Netflix approach the challenge of detecting performance anomalies in this complex environment? The article discusses the high dimensionality feature space, sparse data, and the impact of various networks on user experience. The key focus is on scaling solutions to identify device performance issues as the ecosystem continues to grow in volume and diversity.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "This article describes Netflix's approach to detecting performance anomalies in their external firmware deployments, which involves addressing the challenges of a high-dimensional feature space, sparse data, and the impact of diverse networks on user experience, while emphasizing the need to scale solutions as the device ecosystem grows.", "keywords": ["performance_monitoring", "anomaly_detection", "statistical_analysis", "high_dimensionality", "sparse_data", "device_ecosystem", "user_experience", "scaling_solutions"], "chunk_index": 0, "content_hash": "b635b541877e227c88ebd2305ab4279b"}
{"chunk_id": "Netflix_2019_1_00af07be", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "are also used on a wide range of networks which directly impact the delivered user experience. The video quality and app performance that can be delivered to a limited-memory mobile phone with a spotty cellular connection is quite different than what can be achieved on a cable set top box with high speed broadband; understanding how device characteristics and network behavior interact adds a layer of complexity in triaging potential device performance issues.We strive to ensure that when a member opens the Netflix app and presses play, they are presented with a high-quality experience every step of the way. Encountering an error page, waiting a very long time for video to begin playing, or having the video pause during playback, etc. are poor experiences, and we strive to minimize them.", "enriched_content": " The Netflix video quality and app performance can vary significantly depending on the user's device and network conditions. We need to understand how device characteristics and network behavior interact to ensure a high-quality experience for our members. We strive to minimize poor experiences like encountering errors, long wait times, or video playback issues.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": " This chunk discusses the challenges of delivering a consistent high-quality video experience across various devices and network conditions, and Netflix's efforts to minimize poor user experiences.", "keywords": [" video_quality", "app_performance", "device_characteristics", "network_behavior", "user_experience", "anomaly_detection", "performance_monitoring"], "chunk_index": 1, "content_hash": "00af07beec30cb15bed8acbeff1d75bf"}
{"chunk_id": "Netflix_2019_2_07dcc8a1", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "ep of the way. Encountering an error page, waiting a very long time for video to begin playing, or having the video pause during playback, etc. are poor experiences, and we strive to minimize them. Previous blog posts have detailed the efforts of the Device Reliability Team (part 1, part 2) to identify issues and troubleshoot them and have given examples of the uses of machine learning to improve streaming quality.Device-related issues typically occur in one of two scenarios: (1) Netflix introduces a change to the app or backend servers that interacts badly with some devices or (2) a consumer electronics partner, browser developer, or operating system developer pushes a change (e.g. a firmware change or browser/OS change) that interacts poorly with our app.", "enriched_content": "The text describes how Netflix uses machine learning techniques to detect and address anomalies in their streaming service. It explains that device-related issues can arise from Netflix's own changes or from changes made by partner companies. The team aims to identify and troubleshoot these issues to minimize poor user experiences like error pages, long loading times, and playback interruptions.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "The text discusses Netflix's use of machine learning for anomaly detection and performance monitoring in their streaming service, to address device-related issues caused by internal changes or external partner changes.", "keywords": ["machine learning", "anomaly detection", "performance monitoring", "streaming quality", "device reliability", "troubleshooting"], "chunk_index": 2, "content_hash": "07dcc8a1ac7f151345027c3b388afbaa"}
{"chunk_id": "Netflix_2019_3_aef2991b", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "electronics partner, browser developer, or operating system developer pushes a change (e.g. a firmware change or browser/OS change) that interacts poorly with our app. While we have tools for dealing with the first scenario (for example, automated canary analysis using Kayenta), the second type previously was only detected when the update had reached a sufficient volume of devices to shift core performance metrics. Being able to quickly identify firmware updates that result in poorer member experience allows us to minimize the impact of these issues and work with device partners to root-cause problems.Figure 1 — Monthly number of firmware releases seen on consumer electronics devices streaming Netflix.", "enriched_content": "The machine learning approach described in this text chunk is used to quickly identify firmware updates that result in poorer member experience for Netflix. It allows Netflix to minimize the impact of these issues and work with device partners to root-cause problems. The approach is able to detect these issues before they reach a sufficient volume of devices to shift core performance metrics, which was a limitation of previous methods.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "This chunk describes a machine learning approach used by Netflix to quickly identify firmware updates that negatively impact user experience, enabling them to address the issues before they become widespread.", "keywords": ["anomaly_detection", "performance_monitoring", "firmware_updates", "device_partner_collaboration", "member_experience_optimization"], "chunk_index": 3, "content_hash": "aef2991b894e9b1387aa633366a4cb05"}
{"chunk_id": "Netflix_2019_4_9e896fda", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "problems.Figure 1 — Monthly number of firmware releases seen on consumer electronics devices streaming Netflix.Figure 1 shows that the rate at which our consumer electronics device partners are pushing new firmware is growing rapidly. In 2018, our partners pushed over 500 firmware pushes a month; this value will likely pass 1,000 firmware upgrades per month by 2020. Often firmware rollouts begin slowly with a fraction of all devices receiving the new firmware for several days before the rest of the devices are upgraded. These rollouts are not random; often a specific subset of devices are targeted for new firmwares and sometimes rollouts target specific geographic regions.", "enriched_content": "The text discusses the rapid growth in the monthly number of firmware releases seen on consumer electronics devices streaming Netflix. It explains that firmware rollouts often start slowly with a fraction of devices receiving the new firmware before the rest are upgraded, and that these rollouts are not random but can target specific device subsets or geographic regions.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "The text analyzes the increasing rate of firmware releases on consumer electronics devices streaming Netflix, highlighting the gradual and targeted nature of these firmware rollouts.", "keywords": ["firmware releases", "consumer electronics", "performance monitoring", "anomaly detection", "statistical analysis"], "chunk_index": 4, "content_hash": "9e896fda342f61c2a66e77d442aebdaa"}
{"chunk_id": "Netflix_2019_5_3bae513f", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "eted for new firmwares and sometimes rollouts target specific geographic regions. Naive analysis of metric changes between new firmwares and devices on older firmwares can be confounded by the non-random rollout, so it’s important to control for this when asking if a new firmware has negatively impacted the Netflix member experience.Putting the Pieces TogetherConsider the case of a metric which follows the grey distribution (with a mean value of ~ 4,570) shown in Figure 2. We see a new firmware deploy in the field (red distribution) which follows an approximately normal distribution with noticeably higher mean of 5,600, indicating that devices using the new firmware have a poor experience than the mean of the full device population.", "enriched_content": "To analyze the impact of a new firmware on the Netflix member experience, it's important to control for the non-random rollout of the firmware. The text describes a scenario where a new firmware deployment (red distribution) has a higher mean value (5,600) compared to the overall device population (grey distribution with mean 4,570), indicating a poorer experience for devices using the new firmware. The analysis needs to account for the non-random nature of the rollout to accurately assess the impact of the new firmware.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "The text discusses the importance of controlling for non-random firmware rollouts when analyzing the impact on user experience metrics, using a scenario with a new firmware deployment showing a higher mean metric value compared to the overall device population.", "keywords": ["anomaly_detection", "performance_monitoring", "statistical_analysis", "firmware_rollout", "user_experience"], "chunk_index": 5, "content_hash": "3bae513fbcd8d2d6d26b06969db06c60"}
{"chunk_id": "Netflix_2019_6_ef4c6a5b", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "eably higher mean of 5,600, indicating that devices using the new firmware have a poor experience than the mean of the full device population. Should we be concerned that the new firmware has resulted in lower performance than prior versions?Figure 2 — Left: Hypothetical distribution of a device performance metric between the control sample of devices (grey) and a population of the same devices which have been upgraded to a new firmware (red). Right: The control sample (red) has been broken into multiple sub-components (grey) based on geographic region.If the devices running the new firmware were a random subsample of the control sample, we very likely should be concerned.", "enriched_content": "The text discusses a scenario where a new firmware update for devices has resulted in a significantly higher mean performance metric compared to the full device population. The key questions it addresses are: Should we be concerned that the new firmware has led to lower performance than prior versions? What can we infer about the device population running the new firmware compared to the control sample?", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "The text analyzes a hypothetical scenario where a new firmware update for devices has resulted in a higher mean performance metric, suggesting potential performance issues. It examines whether this is a concern and how the new firmware population compares to the control sample.", "keywords": ["anomaly detection", "performance monitoring", "firmware update", "statistical analysis", "device population", "control sample"], "chunk_index": 6, "content_hash": "ef4c6a5bd67b55602a7d2b33a71e2d76"}
{"chunk_id": "Netflix_2019_7_0c67ace1", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "ere a random subsample of the control sample, we very likely should be concerned. Unfortunately, this is not an assumption we can make when working with firmware deployments with our consumer electronics partners. In this example, we can break down the control sample by geographic region (right panel of Figure 2) and see that the control sample is an aggregation of distinct distributions from each region. If our partners roll out a new firmware preferentially to some regions compared to others, we must correct for this effect before quantifying any changes in performance metrics on devices with the new firmware.Figure 3 — Comparison of the treatment sample distribution (red) with one of the randomly matched control samples (grey) using the methodology described in the text.", "enriched_content": "The text describes a challenge in using a control sample for anomaly detection in firmware deployments. When working with firmware deployments with consumer electronics partners, the control sample may be an aggregation of distinct distributions from different geographic regions. If the firmware is rolled out preferentially to some regions, the effect must be corrected before quantifying changes in performance metrics. The methodology involves comparing the treatment sample distribution to a randomly matched control sample.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "The text addresses the challenge of using a control sample for anomaly detection in firmware deployments, where the control sample may be an aggregation of distinct regional distributions, requiring correction before analyzing performance changes.", "keywords": ["anomaly_detection", "performance_monitoring", "firmware_deployment", "control_sample", "regional_distribution"], "chunk_index": 7, "content_hash": "0c67ace1eac8b061ab28aec0cbc45f40"}
{"chunk_id": "Netflix_2019_8_2dad30a5", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "h the new firmware.Figure 3 — Comparison of the treatment sample distribution (red) with one of the randomly matched control samples (grey) using the methodology described in the text. While the treatment sample has a larger mean metric value than the full control sample shown in Figure 2, when we account for the fact that the treatment sample came from a different population than the control sample, we can see that treatment sample has a lower mean (which is an improved member experience in this case).We created a framework, Jigsaw, which allows data scientists and engineering teams at Netflix to understand changes in metrics with biased treatment populations. For each treatment sample, we create a Monte Carlo “matched” sample from our control sample.", "enriched_content": "The new firmware update resulted in a larger mean metric value for the treatment sample compared to the full control sample. However, when accounting for the fact that the treatment sample came from a different population, the treatment sample actually had a lower mean value, which indicates an improved member experience. To understand these changes in metrics with biased treatment populations, Netflix created a framework called Jigsaw, which generates a Monte Carlo \"matched\" sample from the control sample for each treatment sample.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "The text describes a framework developed by Netflix to analyze changes in metrics for treatment populations that differ from the control population, using a matched sampling approach.", "keywords": ["anomaly_detection", "performance_monitoring", "statistical_analysis", "treatment_sample", "control_sample", "Monte_Carlo_simulation", "Jigsaw"], "chunk_index": 8, "content_hash": "2dad30a5d0dfbf37739255f691b9194c"}
{"chunk_id": "Netflix_2019_9_dc8573c9", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "x to understand changes in metrics with biased treatment populations. For each treatment sample, we create a Monte Carlo “matched” sample from our control sample. This matched sample is constructed to mirror the same property distribution as the treatment sample using a list of user-specified dimensions. In our example above, we would construct a matched control sample that follows the same geographic distribution as the devices in the treatment sample. This process is not limited to one dimension — in practice, we often match on geographic dimensions as well as key device characteristics (such as device model or device model year). Increasing the number of dimensions used in the matching, however, can lead to data sparsity issues.", "enriched_content": "To analyze changes in metrics, the approach creates a Monte Carlo \"matched\" sample from the control sample that mirrors the same property distribution as the treatment sample. This matching is done on user-specified dimensions, such as geographic location and device characteristics, to account for potential biases in the treatment population. The number of matching dimensions used can impact data sparsity.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "The approach uses Monte Carlo sampling to create a matched control group that mirrors the treatment group, allowing for unbiased analysis of metric changes across the two populations.", "keywords": ["anomaly_detection", "performance_monitoring", "monte_carlo_sampling", "bias_correction", "data_matching", "data_sparsity"], "chunk_index": 9, "content_hash": "dc8573c9b71caee9caba89bf66ba7054"}
{"chunk_id": "Netflix_2019_10_7f105add", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "h as device model or device model year). Increasing the number of dimensions used in the matching, however, can lead to data sparsity issues. For our analysis we typically limit matching to one or two device properties to ensure sufficient data. Once we have compared the metric distributions for both the matched control and treatment samples, we repeat the Monte Carlo matching procedure multiple times to estimate the probability that the treatment sample could have been drawn from the control sample given the sampling uncertainties. Figure 3 shows one matched sample realization in the example described above.", "enriched_content": "To analyze the machine learning approach in this paper, we can ask the following questions: 1. How does the paper handle the issue of data sparsity when increasing the number of dimensions used in matching? 2. What is the process for comparing the metric distributions between the matched control and treatment samples? 3. How does the paper use the Monte Carlo matching procedure to estimate the probability that the treatment sample could have been drawn from the control sample? 4. Can you provide an example of a matched sample realization, as shown in Figure 3?", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "This paper discusses a machine learning approach for anomaly detection and performance monitoring, which involves matching control and treatment samples based on device properties and using a Monte Carlo simulation to estimate the probability of the treatment sample being drawn from the control sample.", "keywords": ["statistical_analysis", "anomaly_detection", "performance_monitoring", "matching", "data_sparsity", "Monte_Carlo_simulation", "device_properties"], "chunk_index": 10, "content_hash": "7f105add295b7d15237e30408303837e"}
{"chunk_id": "Netflix_2019_11_a2135402", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "described above. While the treatment sample has a higher mean metric in the overall comparison, controlling for differences in the underlying population show that the treatment cell has actually lowered the metric and improved our member experience.The Bigger PictureFigure 4 — Workflow diagram illustrating the daily cycle of Jigsaw alerts.The introduction of Jigsaw into the Netflix device reliability engineering team’s workflow quickly made direct impact on our members’ experiences. During the summer of 2018, two device performance deteriorations were detected while the culpable new firmware was only present on 0.5% of the several million potentially impacted devices.", "enriched_content": "The introduced machine learning approach, called Jigsaw, was able to detect device performance deteriorations even when the problematic firmware was only present on a small fraction of the affected devices. While the overall comparison showed a higher mean metric for the treatment sample, controlling for underlying population differences revealed that the treatment actually lowered the metric and improved member experience.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "The text describes how the Jigsaw anomaly detection system at Netflix was able to quickly identify device performance issues, despite the problematic firmware being present on only a small percentage of devices.", "keywords": ["anomaly_detection", "performance_monitoring", "statistical_analysis", "device_reliability", "member_experience"], "chunk_index": 11, "content_hash": "a2135402da29cdca23f5a8f16e061d7a"}
{"chunk_id": "Netflix_2019_12_57ad3313", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "as only present on 0.5% of the several million potentially impacted devices. With the early alerts from Jigsaw, the device reliability team was able to work with our consumer electronics partners to correct the problem and prevent millions of users from experiencing errors during playback. Work is underway to use the Jigsaw framework to understand more than firmware changes, as well. Comparing metrics between two web browser software versions or operating system versions is aiding several of the Netflix engineering teams understand the effects of in-field software changes on performance metrics.Netflix members have many options when it comes to entertainment. We strive to provide the best possible experience each time anyone launches Netflix.", "enriched_content": "The paper discusses a machine learning-based anomaly detection system called Jigsaw that Netflix uses to monitor device performance and detect issues. The system can identify anomalies in metrics like firmware changes, web browser versions, and operating system versions, allowing the device reliability team to work with partners to quickly resolve problems and prevent widespread user impact. The system helps Netflix understand the effects of software changes on performance metrics and ensure a high-quality experience for Netflix members.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "This text discusses Netflix's use of a machine learning-based anomaly detection system called Jigsaw to monitor device performance, detect issues, and understand the impact of software changes on user experience.", "keywords": ["anomaly detection", "performance monitoring", "statistical analysis", "device reliability", "software changes"], "chunk_index": 12, "content_hash": "57ad33135698ce11c3924e1bf24e6cc4"}
{"chunk_id": "Netflix_2019_13_66944274", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "s.Netflix members have many options when it comes to entertainment. We strive to provide the best possible experience each time anyone launches Netflix. By enriching our device performance monitoring with automated anomaly detection, we can scale our efforts as the device ecosystem continues to grow and evolve. Through being proactive rather than reacting to issues after they have had wide impact, we protect our members from poor experiences, empowering them to continue to find more moments of uninterrupted joy.Check out the Netflix Research Page if you want to learn more. We are always looking for new stunning colleagues to join us!", "enriched_content": " The Netflix machine learning approach to anomaly detection aims to provide the best possible experience for Netflix members. By using automated anomaly detection techniques to monitor device performance, Netflix can proactively identify and address issues before they have a wide impact on members. This allows Netflix to protect members from poor experiences and ensure they can continue to enjoy uninterrupted entertainment. The Netflix Research Page provides more information on the company's machine learning efforts, and they are always seeking talented individuals to join their team.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": " Netflix's machine learning-based anomaly detection system monitors device performance to proactively identify and address issues, ensuring the best possible experience for members.", "keywords": [" anomaly_detection", "performance_monitoring", "device_monitoring", "proactive_approach", "member_experience"], "chunk_index": 13, "content_hash": "66944274417d47d2066d98a62224b3d8"}
{"chunk_id": "LinkedIn_2019_0_885b867b", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "Data Management Detecting and preventing abuse on LinkedIn using isolation forests Authored byJames Verbus Sr. Staff Software Engineer, Machine Learning at LinkedIn | AI/ML | Ph.D. in Physics | Advancing Trust, Security & AI Productivity August 13, 2019 The Anti-Abuse AI Team at LinkedIn creates, deploys, and maintains models that detect and prevent various types of abuse, including the creation of fake accounts, member profile scraping, automated spam, and account takeovers. There are several unique challenges we face when using machine learning to prevent abuse on a large professional network, including: Labels: few/poor “ground truth” labels, or sometimes none at all Adversarial: attackers are quick to adapt and evolve Unbalanced: the abusive traffic is a very small fraction of total tr", "enriched_content": "The isolation forest technique is used by the Anti-Abuse AI Team at LinkedIn to detect and prevent various types of abuse, such as the creation of fake accounts, member profile scraping, automated spam, and account takeovers. The team faces unique challenges in using machine learning for abuse detection, including a lack of reliable \"ground truth\" labels, the need to adapt to evolving adversarial attacks, and an imbalance between abusive and legitimate traffic.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This text chunk discusses how LinkedIn's Anti-Abuse AI Team uses isolation forests, an unsupervised learning technique, to detect and prevent abuse on the platform, while addressing the unique challenges they face in this domain.", "keywords": ["isolation_forest", "unsupervised_learning", "abuse_detection", "adversarial", "unbalanced_data", "professional_network"], "chunk_index": 0, "content_hash": "885b867b1fac3a7d994e7373678240e8"}
{"chunk_id": "LinkedIn_2019_1_13573e58", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "k, including: Labels: few/poor “ground truth” labels, or sometimes none at all Adversarial: attackers are quick to adapt and evolve Unbalanced: the abusive traffic is a very small fraction of total traffic Many surfaces: there are many dynamically-changing heterogeneous surfaces to monitor To help solve these challenges, we’ve created a Spark/Scala implementation of the Isolation Forest unsupervised outlier detection algorithm. Today, we are announcing that our Isolation Forest library is now open sourced and available on GitHub. In this post, we provide a technical overview of the Isolation Forest algorithm. Then, we describe our Spark/Scala Isolation Forest library, as well as describing the above challenges in more detail and outlining how Isolation Forests provide a solution.", "enriched_content": "The machine learning approach described in this text chunk aims to address the challenges faced in anomaly detection for abuse detection, including the lack of ground truth labels, the adaptability of attackers, the unbalanced nature of abusive traffic, and the complexity of monitoring many heterogeneous surfaces. The authors have created a Spark/Scala implementation of the Isolation Forest unsupervised outlier detection algorithm to tackle these challenges and have made the library open-source.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This text chunk outlines the challenges of anomaly detection for abuse detection and introduces a Spark/Scala implementation of the Isolation Forest unsupervised outlier detection algorithm as a solution.", "keywords": ["anomaly detection", "abuse detection", "unsupervised learning", "isolation forest", "spark", "scala"], "chunk_index": 1, "content_hash": "13573e5828614875b8277ee370807873"}
{"chunk_id": "LinkedIn_2019_2_fb90246d", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "orest algorithm. Then, we describe our Spark/Scala Isolation Forest library, as well as describing the above challenges in more detail and outlining how Isolation Forests provide a solution. Finally, we share some concrete potential use cases for this algorithm. Isolation Forests The Isolation Forest algorithm was first proposed in 2008 by Liu et al. It is a type of unsupervised outlier detection that leverages the fact that outliers are “few and different,” meaning that they are fewer in number and have unusual feature values compared to the inlier class. Liu et al.’s innovation was to use a randomly-generated binary tree structure to non-parametrically capture the multi-dimensional feature distribution of the training dataset. Each isolation tree is created using the following steps: 1.", "enriched_content": "The text discusses the use of the Isolation Forest algorithm for unsupervised anomaly detection. It describes the key features of the algorithm, including its ability to capture the multi-dimensional feature distribution of the training dataset using a randomly-generated binary tree structure. The text also mentions the challenges in implementing the algorithm and how the Spark/Scala Isolation Forest library addresses these challenges. Finally, it provides examples of potential use cases for the Isolation Forest algorithm.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "The text outlines the Isolation Forest algorithm for unsupervised anomaly detection, including its key features, implementation challenges, and potential use cases.", "keywords": ["isolation_forest", "unsupervised_learning", "anomaly_detection", "binary_tree", "multi-dimensional_feature_distribution"], "chunk_index": 2, "content_hash": "fb90246d7a8cb212e9c567df25497dd3"}
{"chunk_id": "LinkedIn_2019_3_19abe0bb", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "randomly-generated binary tree structure to non-parametrically capture the multi-dimensional feature distribution of the training dataset. Each isolation tree is created using the following steps: 1. Randomly sample N instances from your training dataset. At each node: 2. Randomly choose a feature to split upon. 3. Randomly choose a split value from a uniform distribution spanning from the minimum value to the maximum value of the feature chosen in Step 2. Steps 2 and 3 are repeated recursively until, in principle, all N instances from your sample are “isolated” in leaf nodes of your isolation tree—one training instance per leaf node. In practice, we don’t need to build the tree so deeply and can apply a height limit.", "enriched_content": "The machine learning approach uses isolation forests, an unsupervised anomaly detection technique, to capture the multidimensional feature distribution of the training dataset. It builds a randomly-generated binary tree structure, where each node randomly selects a feature and a split value to recursively isolate the training instances in the leaf nodes. This process is repeated until all instances are isolated or a height limit is reached.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "The chunk describes the isolation forest algorithm, an unsupervised anomaly detection technique that builds a randomly-generated binary tree structure to capture the feature distribution of the training data.", "keywords": ["isolation_forest", "unsupervised_learning", "anomaly_detection", "binary_tree", "feature_distribution"], "chunk_index": 3, "content_hash": "19abe0bbad7efbb218f306e21297ef0b"}
{"chunk_id": "LinkedIn_2019_4_6229992c", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "tree—one training instance per leaf node. In practice, we don’t need to build the tree so deeply and can apply a height limit. An example isolation tree The intuition is that outliers—due to being few and different—are easier to isolate in leaf nodes and thus require fewer random splits to achieve this, on average. The result is a shorter expected path length from the root node to the leaf node for outlier data points. The outlier score for a particular instance is a function of the path length from the root node to the leaf node and the total number of training instances used to build the tree. If a height limit is applied when building the tree, some leaf nodes will end up with more training instances than others.", "enriched_content": "The isolation forest approach used in this machine learning anomaly detection technique aims to identify outliers by creating isolation trees. The intuition is that outliers, being few and different, are easier to isolate in the leaf nodes and thus require fewer random splits to achieve this, resulting in a shorter expected path length from the root node to the leaf node for outlier data points. The outlier score for a particular instance is a function of this path length and the total number of training instances used to build the tree. When a height limit is applied to the tree, some leaf nodes will end up with more training instances than others.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This passage describes the isolation forest approach, an unsupervised machine learning technique for anomaly detection that identifies outliers based on their path length in randomly constructed isolation trees.", "keywords": ["isolation_forest", "unsupervised_learning", "anomaly_detection", "outlier_detection", "path_length"], "chunk_index": 4, "content_hash": "6229992c79b1b97c7861974446bf89ec"}
{"chunk_id": "LinkedIn_2019_5_6c9a0b5c", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "ee. If a height limit is applied when building the tree, some leaf nodes will end up with more training instances than others. This is useful additional information that should be incorporated into the outlier score. The average depth for an unsuccessful search in a binary search tree created with N instances is given by where H(i) ≈ ln(i) + 0.5772156649. Due to the similar structure of binary search trees and isolation trees, the value c(N) provides the average depth of an isolation tree created using N training instances. For leaf nodes containing M > 1 training instances, we can add c(M) to the measured path length from the root to the leaf node to account for the number of instances terminating in the leaf node; this sum yields the effective path length for a particular instance, h(xi)", "enriched_content": "The isolation forest approach applies a height limit when building the isolation tree, resulting in some leaf nodes containing more training instances than others. This additional information should be incorporated into the outlier score calculation. The average depth for an unsuccessful search in a binary search tree with N instances is given by a formula that can be applied to the similar structure of isolation trees. For leaf nodes containing M > 1 training instances, the average depth of the isolation tree, c(M), can be added to the measured path length from the root to the leaf node to obtain the effective path length for a particular instance, h(xi).", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This text chunk describes how the isolation forest algorithm can incorporate the number of training instances in leaf nodes to calculate more accurate outlier scores.", "keywords": ["isolation_forest", "unsupervised_learning", "binary_search_tree", "outlier_detection", "effective_path_length"], "chunk_index": 5, "content_hash": "6c9a0b5c47b74ff8421fbeb228815e85"}
{"chunk_id": "LinkedIn_2019_6_f12861fd", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "the measured path length from the root to the leaf node to account for the number of instances terminating in the leaf node; this sum yields the effective path length for a particular instance, h(xi). We can train an ensemble of isolation trees, an Isolation Forest, and average across their output to reduce the variance of the model. Once an Isolation Forest model is trained, the outlier score for an instance xi is given by where E (h(xi)) is the effective path length for that instance, h(xi), averaged across all trees in the ensemble, and c(N) is the expected depth of an isolation tree given N training instances discussed previously. This uncalibrated score, s(xi, N), ranges from 0 to 1. Higher scores are more outlier-like.", "enriched_content": " The Isolation Forest approach used in this work aims to detect anomalies in data by measuring the effective path length of each instance through an ensemble of isolation trees. The path length reflects the number of instances terminating in the leaf node, and by averaging the path lengths across the ensemble, the variance of the model is reduced. The outlier score for an instance is then calculated based on the expected depth of an isolation tree given the number of training instances, providing a score between 0 and 1, where higher scores indicate more outlier-like behavior.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": " The text describes the Isolation Forest approach for unsupervised anomaly detection, which measures the effective path length of instances through an ensemble of isolation trees to generate outlier scores.", "keywords": [" isolation_forest", "unsupervised_learning", "anomaly_detection", "ensemble_methods", "path_length"], "chunk_index": 6, "content_hash": "f12861fd3c30afe3fa3fb61744f9c5b6"}
{"chunk_id": "LinkedIn_2019_7_1d2b89bc", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "N training instances discussed previously. This uncalibrated score, s(xi, N), ranges from 0 to 1. Higher scores are more outlier-like. Isolation Forest Spark/Scala library We created a Spark/Scala implementation of the Isolation Forest algorithm for use at LinkedIn. Our implementation supports distributed training and scoring using Spark data structures. We inherit Spark ML’s Estimator and Model classes in order to take advantage of Spark ML machinery such as Pipelines. Our implementation supports model persistence on Hadoop Distributed File System (HDFS). Here is an example demonstrating how to import the library, create a new IsolationForest instance, set the model hyperparameters, train the model, and then score the training data.", "enriched_content": "The Isolation Forest algorithm is an unsupervised machine learning technique used for anomaly detection at LinkedIn. The algorithm generates an outlier score for each data instance, with higher scores indicating more outlier-like behavior. The LinkedIn team has created a Spark/Scala implementation of the Isolation Forest algorithm that supports distributed training and scoring, model persistence on HDFS, and integration with Spark ML Pipelines.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This text covers LinkedIn's Spark/Scala implementation of the Isolation Forest algorithm for unsupervised anomaly detection, including details about the algorithm's capabilities and integration with Spark ML.", "keywords": ["isolation_forest", "unsupervised_learning", "anomaly_detection", "spark", "scala", "spark_ml", "hdfs"], "chunk_index": 7, "content_hash": "1d2b89bcacd1f8057376a7878322f9c7"}
{"chunk_id": "LinkedIn_2019_8_f1454405", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "to import the library, create a new IsolationForest instance, set the model hyperparameters, train the model, and then score the training data. In this example, data is a Spark DataFrame with a column named features that contains a Vector of the attributes to use for training. In this example, the DataFrame data also has a labels column; it is not used in the training process, but could be useful for model evaluation. How to train and score data in Scala using our Isolation Forest library The output DataFrame, dataWithScores, is identical to the input data DataFrame but has two additional result columns appended with their names set via model parameters; in this example, these are named predictedLabel and outlierScore.", "enriched_content": "The code snippet demonstrates how to use the Isolation Forest library in Scala to train an unsupervised machine learning model for anomaly detection. It shows the steps to import the library, create an Isolation Forest instance, set the model hyperparameters, train the model, and then score the training data. The example uses a Spark DataFrame with a 'features' column containing the attributes to be used for training, and a 'labels' column that is not used in the training process but could be useful for model evaluation. The output DataFrame includes two additional columns, 'predictedLabel' and 'outlierScore', which contain the model's predictions and outlier scores, respectively.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This code snippet covers the steps to train and score an Isolation Forest model for unsupervised anomaly detection in Scala using a Spark DataFrame as the input data.", "keywords": ["isolation_forest", "unsupervised_learning", "anomaly_detection", "spark_dataframe", "model_training", "model_scoring"], "chunk_index": 8, "content_hash": "f145440581ed87b9e18632aab289e83c"}
{"chunk_id": "LinkedIn_2019_9_4a210d19", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "ult columns appended with their names set via model parameters; in this example, these are named predictedLabel and outlierScore. Why use Isolation Forests? We chose the Isolation Forest algorithm for multiple reasons. Isolation Forests are a top-performing unsupervised outlier detection algorithm. Isolation Forests are also scalable, as their computational and memory requirements are low compared to common alternatives. There are fewer assumptions (e.g., non-parametric, no need for a distance metric) than other candidate algorithms. Finally, Isolation Forests are actively used in academia and industry, which allows us to leverage best practices and new developments shared by others in the field.", "enriched_content": "The paper uses the Isolation Forest algorithm for unsupervised anomaly detection. Isolation Forests are a top-performing outlier detection algorithm that is scalable and has fewer assumptions compared to other techniques. The authors chose this algorithm because it is widely used in both academia and industry, allowing them to leverage best practices and new developments in the field.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "The paper discusses the use of the Isolation Forest algorithm for unsupervised anomaly detection, highlighting its advantages in terms of performance, scalability, and flexibility compared to other techniques.", "keywords": ["isolation_forest", "unsupervised_learning", "anomaly_detection", "outlier_detection", "scalable_algorithms"], "chunk_index": 9, "content_hash": "4a210d192d56e3b30f92c8e07bbecbc1"}
{"chunk_id": "LinkedIn_2019_10_8d6d86eb", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "industry, which allows us to leverage best practices and new developments shared by others in the field. Labels For some types of abuse, such as spam, it is possible to have a scalable review process where humans label training examples as spam or not spam. There are other types of abuse, such as scraping, where this kind of scalable human labeling is much more difficult, or impossible. Often, the labels you are able to obtain for training and evaluation are fuzzy; the precision may be less than ideal and there may be poor recall for some types of abusive behavior. Unsupervised techniques such as Isolation Forests are designed for problems with few or no labels, so they help to circumnavigate these label-based challenges.", "enriched_content": "The text describes the challenges in obtaining labeled data for certain types of abuse, such as scraping, where a scalable human labeling process is difficult or impossible. To address this, the paper explores the use of unsupervised techniques like Isolation Forests, which are designed to work with limited or imprecise labels. This approach helps overcome the label-based challenges encountered in abuse detection.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "The text discusses the challenges of obtaining labeled data for certain types of abuse, and proposes the use of unsupervised techniques like Isolation Forests to address these challenges.", "keywords": ["abuse_detection", "isolation_forest", "unsupervised_learning", "label_challenges", "scalable_review"], "chunk_index": 10, "content_hash": "8d6d86eb904c7e2ed9f4c228fd218580"}
{"chunk_id": "LinkedIn_2019_11_a70755a1", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "h as Isolation Forests are designed for problems with few or no labels, so they help to circumnavigate these label-based challenges. Adversarial The lack of good labels for training is further complicated by the fact that the problem is adversarial. Bad actors are often quick to adapt and evolve in sophisticated ways. Even if we are able to obtain some labels for abusive behavior identified today, the labels may not be representative of what abusive activity looks like tomorrow. Isolation Forests can be used to overcome this challenge. As long as new abusive behavior is located in a different region of the feature space than normal, organic user behavior, we often can detect it using outlier detection—even if we did not have labeled examples when the model was trained.", "enriched_content": "The Isolation Forest algorithm is well-suited for anomaly detection in unsupervised learning scenarios, where labeled data is scarce or non-existent. It can effectively identify novel abusive behaviors that may emerge over time, even if the training data did not include examples of such activities. The lack of good labels is a challenge, as bad actors can quickly adapt and evolve their tactics. However, Isolation Forests can detect anomalies as long as the new abusive behavior is located in a different region of the feature space compared to normal user activity.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This text discusses how the Isolation Forest algorithm can be used for unsupervised anomaly detection, particularly in the context of abuse detection, where labeled data is limited and adversaries are quick to adapt.", "keywords": ["isolation_forest", "unsupervised_learning", "anomaly_detection", "abuse_detection", "adversarial_behavior"], "chunk_index": 11, "content_hash": "a70755a1a3fa107b898f17299e2a4000"}
{"chunk_id": "LinkedIn_2019_12_02f9d447", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "region of the feature space than normal, organic user behavior, we often can detect it using outlier detection—even if we did not have labeled examples when the model was trained. Unbalanced Abusive behavior is a very small fraction of all member activity on LinkedIn. This is a natural use case for outlier detection, where the outlier class is expected to be fewer in number compared to the inlier class. Many surfaces The Anti-Abuse Team at LinkedIn detects and prevents a wide variety of abuse across a diverse set of product surfaces. Our models often use features calculated using events from tracking infrastructure owned by other teams.", "enriched_content": "The machine learning approach used in this paper aims to detect anomalous or abusive behavior on LinkedIn's platform. Even without labeled examples of abusive behavior during the model training phase, the technique can identify outliers in the feature space that deviate from normal, organic user activity. The approach leverages features from various product surfaces and data sources across the company to train unsupervised models like isolation forest to identify these rare instances of abuse.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This paper describes an unsupervised machine learning approach to detect abusive behavior on LinkedIn's platform, even in the absence of labeled training data, by identifying outliers in the feature space that deviate from normal user activity.", "keywords": ["anomaly_detection", "outlier_detection", "isolation_forest", "unsupervised_learning", "abuse_detection", "unbalanced_data", "linkedin"], "chunk_index": 12, "content_hash": "02f9d447246b7023e9d16d16ffe12772"}
{"chunk_id": "LinkedIn_2019_13_9a8365a9", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "racking infrastructure owned by other teams. This is a heterogeneous, dynamic environment that requires the use of a generalizable modeling strategy that supports easy retraining as the infrastructure changes underneath our models. Isolation Forests are easy to retrain if feature distributions shift, which helps to satisfy this requirement. Potential uses for Isolation Forests There are many uses for unsupervised outlier detection in the abuse detection domain and other related areas at large internet companies, including: Automation detection: Identify abusive accounts that are using automation to scrape data, send spam, or generate fake engagement Advanced persistent threats: Identify and prioritize sophisticated fake accounts for review by human experts Insider threats/intrusion detecti", "enriched_content": "The text describes the use of Isolation Forests, an unsupervised machine learning technique, for anomaly detection in a heterogeneous and dynamic infrastructure. This approach is chosen to support easy retraining as the infrastructure changes over time. The potential uses of this technique include automating the detection of abusive accounts, identifying advanced persistent threats, and detecting insider threats or intrusions.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "The text discusses the use of Isolation Forests, an unsupervised learning technique, for anomaly detection in a dynamic infrastructure, with potential applications in abuse detection, advanced threat identification, and insider threat/intrusion detection.", "keywords": ["isolation_forest", "unsupervised_learning", "anomaly_detection", "abuse_detection", "heterogeneous_infrastructure", "dynamic_environment", "retraining"], "chunk_index": 13, "content_hash": "9a8365a945e0736e76da606acbe14318"}
{"chunk_id": "LinkedIn_2019_14_6d585361", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "on to scrape data, send spam, or generate fake engagement Advanced persistent threats: Identify and prioritize sophisticated fake accounts for review by human experts Insider threats/intrusion detection: Detect compromised employee machines via anomalous network traffic ML health assurance: Automatically detect anomalous feature values and shifts in feature distributions Account takeover: Increase recall for account takeover detection Alerting on time-series data: Find anomalies in multi-dimensional time-series data Payment fraud: Flag suspicious payments to prevent fraud Data center monitoring: Automatically detect anomalies in data center infrastructure The Isolation Forest library is now open source As a result of the successful use of the library across multiple abuse verticals at Link", "enriched_content": "What are the different use cases for the Isolation Forest library at LinkedIn? The Isolation Forest library has been used for various anomaly detection tasks at LinkedIn, including detecting sophisticated fake accounts, compromised employee machines, anomalous feature values, account takeovers, suspicious payments, and anomalies in data center infrastructure. The library has been particularly effective in identifying advanced persistent threats, insider threats, and payment fraud, and has helped increase the recall for account takeover detection.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "The Isolation Forest library has been successfully used for a variety of anomaly detection tasks at LinkedIn, including abuse detection, intrusion detection, payment fraud, and data center monitoring.", "keywords": ["isolation_forest", "unsupervised_learning", "abuse_detection", "anomaly_detection", "advanced_persistent_threats", "insider_threats", "account_takeover", "payment_fraud", "data_center_monitoring"], "chunk_index": 14, "content_hash": "6d585361d0ce7244cb46748a4fdbabca"}
{"chunk_id": "LinkedIn_2019_15_f7cb1f24", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "g: Automatically detect anomalies in data center infrastructure The Isolation Forest library is now open source As a result of the successful use of the library across multiple abuse verticals at LinkedIn, we have released it as open source software. You can find our Isolation Forest library on GitHub. Acknowledgements Special thanks to Jenelle Bray, Shreyas Nangalia, Romer Rosales, and Ram Swaminathan for their support of this project. Thank you to Frank Astier and Ahmed Metwally for providing advice and performing code reviews. Finally, thank you to Will Chan, Jason Chang, Milinda Lakkam, and Xin Wang for providing useful feedback as the first users of this library.", "enriched_content": "The Isolation Forest library is an open-source machine learning tool for automatically detecting anomalies in data center infrastructure. The library has been successfully used across multiple abuse verticals at LinkedIn, and the company has now released it as open-source software. The development and support of this project involved contributions from various individuals, including Jenelle Bray, Shreyas Nangalia, Romer Rosales, Ram Swaminathan, Frank Astier, Ahmed Metwally, Will Chan, Jason Chang, Milinda Lakkam, and Xin Wang.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This text chunk discusses the open-sourcing of LinkedIn's Isolation Forest library, a machine learning tool for unsupervised anomaly detection in data center infrastructure, and the acknowledgments for the individuals involved in its development and support.", "keywords": ["isolation_forest", "unsupervised_learning", "anomaly_detection", "data_center_infrastructure", "abuse_detection"], "chunk_index": 15, "content_hash": "f7cb1f2475ca484dafacc356a392364d"}
{"chunk_id": "LinkedIn_2019_16_ff5dcd5a", "source_title": "Detecting and Preventing Abuse on LinkedIn using Isolation Forests", "source_url": "https://engineering.linkedin.com/blog/2019/isolation-forest", "company": "LinkedIn", "year": "2019", "original_content": "d Xin Wang for providing useful feedback as the first users of this library. Topics: Open Source Machine Learning Related articles Machine Learning Scalable federated learning at LinkedIn Siyao Sun Mar 5, 2025 Marketing Buyer journey insights with data-driven attribution John Bencina Jan 22, 2025 Open Source Liger-Kernel: Empowering an open source ecosystem of Triton Ke... Pin-Lun (Byron) Hsu Dec 5, 2024", "enriched_content": "This text discusses the development of an open-source machine learning library at LinkedIn. It mentions that Xin Wang provided useful feedback as one of the first users of the library. The library was likely used for anomaly detection and abuse detection within LinkedIn's systems.", "ml_techniques": ["isolation_forest", "unsupervised_learning", "abuse_detection"], "chunk_summary": "This text covers the development and open-sourcing of a machine learning library at LinkedIn, which was used for tasks like anomaly and abuse detection.", "keywords": ["isolation_forest", "unsupervised_learning", "abuse_detection", "open_source", "machine_learning", "linkedin"], "chunk_index": 16, "content_hash": "ff5dcd5ad0380fc08c97640564fde3e2"}
{"chunk_id": "LinkedIn_2020_0_444da123", "source_title": "Preventing Abuse Using Unsupervised Learning", "source_url": "https://engineering.linkedin.com/blog/2020/preventing-abuse-using-unsupervised-learning", "company": "LinkedIn", "year": "2020", "original_content": "Engineering Blog Technology that sparks innovation to ignite growth AI Building the next generation of job search at LinkedIn Harnessing the power of advanced LLMs, embedding-based retrieval, and intelligent distillation techniques, our new job search system is capable of deeply understanding job seekers’ nuanced intents and delivering highly personalized and relevant results at unprecedented scale. Caleb Johnson Recent Innovations AI Building the next generation of job search at LinkedIn Caleb Johnson May 29, 2025 AI JUDE: LLM-based representation learning for LinkedIn job recom...", "enriched_content": " The LinkedIn AI team has developed a new job search system that leverages advanced language models, embedding-based retrieval, and intelligent distillation techniques. This system is capable of deeply understanding job seekers' nuanced intents and delivering highly personalized and relevant job recommendations at an unprecedented scale.", "ml_techniques": ["unsupervised_learning", "clustering", "behavioral_analysis"], "chunk_summary": " The LinkedIn AI team has developed a new job search system that uses advanced ML techniques to understand job seekers' intents and provide highly personalized and relevant job recommendations.", "keywords": [" unsupervised_learning", "clustering", "behavioral_analysis", "representation_learning", "language_models", "embedding-based_retrieval", "intelligent_distillation"], "chunk_index": 0, "content_hash": "444da123d61da65038624f431f1f1be8"}
{"chunk_id": "LinkedIn_2020_1_42fc89ac", "source_title": "Preventing Abuse Using Unsupervised Learning", "source_url": "https://engineering.linkedin.com/blog/2020/preventing-abuse-using-unsupervised-learning", "company": "LinkedIn", "year": "2020", "original_content": "ltsov May 22, 2025 Infrastructure Powering Apache Pinot ingestion with Hoptimator Ryanne Dolan Apr 18, 2025 Check out what's happening at LinkedIn Engineering Learn More Career Stories Talent Announcing Our LinkedIn-Cornell 2024 Grant Recipients Natesh Pillai Aug 13, 2024 Career stories: The math-music connection in data science Oct 2, 2023 Culture Career stories: Influencing engineering growth at LinkedIn Sep 20, 2023 Explore popular topics AI Building the next generation of job search at LinkedIn JUDE: LLM-based representation learning for LinkedIn job recommendations How we built domain-adapted foundation GenAI models to power our platform Infrastructure Powering Apache Pinot ingestion with Hoptimator Building a resilient DNS client for web-scale infrastructure Journey of next generatio", "enriched_content": "The text discusses an approach for powering Apache Pinot ingestion using Hoptimator at LinkedIn. It covers the techniques used to build a resilient DNS client for web-scale infrastructure and the journey of next-generation infrastructure at the company.", "ml_techniques": ["unsupervised_learning", "clustering", "behavioral_analysis"], "chunk_summary": "The text discusses LinkedIn's approach to powering Apache Pinot ingestion using Hoptimator and building a resilient DNS client for web-scale infrastructure, as part of the company's journey towards next-generation infrastructure.", "keywords": ["Apache Pinot", "Hoptimator", "DNS client", "web-scale infrastructure", "unsupervised learning", "clustering", "behavioral analysis", "representation learning", "foundation models", "infrastructure engineering"], "chunk_index": 1, "content_hash": "42fc89ac4830bb69f8e34ad10fd6d33c"}
{"chunk_id": "LinkedIn_2020_2_dd85607a", "source_title": "Preventing Abuse Using Unsupervised Learning", "source_url": "https://engineering.linkedin.com/blog/2020/preventing-abuse-using-unsupervised-learning", "company": "LinkedIn", "year": "2020", "original_content": "pted foundation GenAI models to power our platform Infrastructure Powering Apache Pinot ingestion with Hoptimator Building a resilient DNS client for web-scale infrastructure Journey of next generation control plane for data systems Data Streaming/Processing Stateful workload operator: stateful systems on Kubernetes at LinkedIn Scalable Automated Config-Driven Data Validation with ValiData Improving Recruiting Efficiency with a Hybrid Bulk Data Processing Framework Ready to get In The Code? Subscribe to LinkedIn's Engineering Newsletter Subscribe Explore all Engineering posts", "enriched_content": "The text chunk covers LinkedIn's machine learning-powered platform infrastructure, including the use of unsupervised learning, clustering, and behavioral analysis techniques to power their systems. It highlights various engineering projects, such as Apache Pinot ingestion, building a resilient DNS client, and developing a next-generation control plane for data systems. The chunk also discusses stateful workload operators, scalable automated data validation, and a hybrid bulk data processing framework for improving recruiting efficiency.", "ml_techniques": ["unsupervised_learning", "clustering", "behavioral_analysis"], "chunk_summary": "This text chunk provides an overview of LinkedIn's machine learning-powered platform infrastructure, covering various engineering projects and techniques like unsupervised learning, clustering, and behavioral analysis.", "keywords": ["unsupervised_learning", "clustering", "behavioral_analysis", "Apache_Pinot", "data_systems", "stateful_workloads", "data_validation", "bulk_data_processing"], "chunk_index": 2, "content_hash": "dd85607ad580a0acd7f05f671d9118c8"}
{"chunk_id": "Stack Exchange_2020_0_2c1408a6", "source_title": "How Does Spam Protection Work on Stack Exchange?", "source_url": "https://stackoverflow.blog/2020/06/25/how-does-spam-protection-work-on-stack-exchange/", "company": "Stack Exchange", "year": "2020", "original_content": "If you put a textbox on the Internet, someone will put spam in it. If you put a textbox on a site that gets millions of hits a day, lots of someones will put lots of spam in it. If you put lots of textboxes on that site... you get the point.Spam protection is like ogres—it has layersMany large web applications are deployed in layers. When your browser sends a HTTP request to bigsite.example.com, it might hit a CDN first (like Cloudflare), then get forwarded to a proxy or load balancer, then to a single server, which might in its turn have a reverse proxy, then a web server, and only then does your request actually make it to the application itself. I won't go into exactly how Stack Exchange is deployed, because Nick Craver can explain it much better than I can.", "enriched_content": "The text discusses the layered approach to spam protection in large web applications. It explains that when a user makes a request to a site, the request goes through multiple layers, such as a CDN, proxy, load balancer, and reverse proxy, before reaching the application itself. This layered approach is necessary to handle the large volume of requests and combat the widespread problem of spam on the internet.", "ml_techniques": ["text_classification", "nlp", "spam_detection"], "chunk_summary": "The text outlines the layered approach to spam protection in large web applications, where requests go through multiple layers before reaching the application to handle high traffic and combat spam.", "keywords": ["spam_detection", "web_application", "layered_architecture", "CDN", "proxy", "load_balancer", "reverse_proxy"], "chunk_index": 0, "content_hash": "2c1408a6f802106678d6f16eae69626c"}
{"chunk_id": "Stack Exchange_2020_1_a91a4ed6", "source_title": "How Does Spam Protection Work on Stack Exchange?", "source_url": "https://stackoverflow.blog/2020/06/25/how-does-spam-protection-work-on-stack-exchange/", "company": "Stack Exchange", "year": "2020", "original_content": "your request actually make it to the application itself. I won't go into exactly how Stack Exchange is deployed, because Nick Craver can explain it much better than I can.Each of those layers can be tuned to help block spam. If you use Cloudflare, that'll do a lot of automatic spam protection for you without needing to think about it; there are a number of other CDNs that do likewise. A load balancer can have a simple IP blocking mechanism added to it. A reverse proxy can be configured to drop requests from suspicious origins—and that's all before you get to the application, where more sophisticated protection measures can be built in.Stack Exchange makes use of a bunch of these layers to help alleviate the spam problem.", "enriched_content": "The provided text discusses the various layers and techniques used by Stack Exchange to detect and mitigate spam in their application. It explains how the different components, such as the CDN, load balancer, and reverse proxy, can be configured to automatically block suspicious activity before it reaches the application. More sophisticated spam protection measures are also implemented at the application level.", "ml_techniques": ["text_classification", "nlp", "spam_detection"], "chunk_summary": "The text describes the multi-layered approach Stack Exchange employs to detect and block spam, including the use of CDNs, load balancers, reverse proxies, and application-level protection measures.", "keywords": ["spam_detection", "anomaly_detection", "text_classification", "network_security", "layered_architecture", "reverse_proxy", "load_balancing"], "chunk_index": 1, "content_hash": "a91a4ed6165e0d5c71e48a4b984aa0ec"}
{"chunk_id": "Stack Exchange_2020_2_3ed8a5ae", "source_title": "How Does Spam Protection Work on Stack Exchange?", "source_url": "https://stackoverflow.blog/2020/06/25/how-does-spam-protection-work-on-stack-exchange/", "company": "Stack Exchange", "year": "2020", "original_content": "icated protection measures can be built in.Stack Exchange makes use of a bunch of these layers to help alleviate the spam problem. Some of them are deliberately secretive, to avoid making it too easy to get around them; others are much more public knowledge. The bits I'm talking about here are the more public parts, which are generally in the lower layers of the request's path.Unlucky spammers get HTTP errorsIf one day I suddenly decide to take a new career path and try to make my fortune spamming Stack Exchange, I might start off by thinking that I'll just copy the HTTP request that happens when I post a new question, and write some code to repeat it really fast with spam in every post.", "enriched_content": "To combat the spam problem, Stack Exchange employs a multi-layered approach, including both publicly known and deliberately secretive protection measures. The publicly known components are typically in the lower layers of the request's path. If a spammer tries to automate the HTTP request for posting new questions, they may encounter HTTP errors, indicating the presence of these protective measures.", "ml_techniques": ["text_classification", "nlp", "spam_detection"], "chunk_summary": "This chunk describes Stack Exchange's multi-layered approach to spam detection, including both public and secretive components, and the potential for spammers to encounter HTTP errors when attempting to automate the posting process.", "keywords": ["spam_detection", "multilayer_approach", "http_request", "request_path", "protection_measures"], "chunk_index": 2, "content_hash": "3ed8a5ae3c78a6507961d8807543b9b1"}
{"chunk_id": "Stack Exchange_2020_3_5fda7cc8", "source_title": "How Does Spam Protection Work on Stack Exchange?", "source_url": "https://stackoverflow.blog/2020/06/25/how-does-spam-protection-work-on-stack-exchange/", "company": "Stack Exchange", "year": "2020", "original_content": "hen I post a new question, and write some code to repeat it really fast with spam in every post.I would be an unlucky spammer, because I would very quickly hit the first level of spam protection: a 429. For those unfamiliar with HTTP status codes, 429 is Too Many Requests. The threshold here is deliberately not made public, but when Stack Exchange notices that you've been sending way too many requests to be humanly possible, it cuts you off and send you this charming message:Now given that I've written some code to do this, the likelihood is that I'll never see that error page, and my script will just keep on... and on... and on.", "enriched_content": "The text describes how Stack Exchange's machine learning-based anomaly detection system works to detect and block spam attempts. When a user posts new questions or content rapidly, the system identifies this as anomalous behavior and responds with a \"429 Too Many Requests\" error. This automatic detection and blocking mechanism prevents the spammer's script from continuing to flood the platform with spam content.", "ml_techniques": ["text_classification", "nlp", "spam_detection"], "chunk_summary": "The text discusses Stack Exchange's use of machine learning for anomaly detection to identify and block spam attempts through rate limiting and automated response.", "keywords": ["anomaly_detection", "spam_detection", "rate_limiting", "http_status_codes", "machine_learning", "natural_language_processing", "text_classification"], "chunk_index": 3, "content_hash": "5fda7cc8435e0e40ce8d219b83df4e3d"}
{"chunk_id": "Stack Exchange_2020_4_03100f0d", "source_title": "How Does Spam Protection Work on Stack Exchange?", "source_url": "https://stackoverflow.blog/2020/06/25/how-does-spam-protection-work-on-stack-exchange/", "company": "Stack Exchange", "year": "2020", "original_content": "ill just keep on... and on... and on. At some point, a Stack Exchange SRE might have a look while they're doing the rounds and decide I'm being a pest, and (figuratively) route any requests from my IP to /dev/null.That I might notice.\"But aha,\" I hear you say, \"you can just get a new IP!\" Which I could, until I got that banned too.\"But aha, you can just use Tor!\" Which sounds like a good idea on the face of it, until you realise that the list of Tor exit nodes is public and that's not changing any time soon. In other words, Stack Exchange can tell when you're using Tor, and if you're being a pest, can simply... turn Tor access off.", "enriched_content": "The text discusses various techniques an individual could use to bypass IP-based restrictions, such as getting a new IP address or using Tor, and how the Stack Exchange platform can detect and mitigate these attempts. The text emphasizes that Stack Exchange has measures in place to identify and block users who are being \"a pest\" and attempting to bypass their security measures.", "ml_techniques": ["text_classification", "nlp", "spam_detection"], "chunk_summary": "The text describes how Stack Exchange can detect and block users who try to circumvent IP-based restrictions, even through the use of techniques like getting a new IP or using Tor.", "keywords": ["anomaly detection", "IP address", "Tor", "spam detection", "text classification", "natural language processing", "security measures"], "chunk_index": 4, "content_hash": "03100f0def89b64f9b9874aa8d1dc2d3"}
{"chunk_id": "Stack Exchange_2020_5_5abd8962", "source_title": "How Does Spam Protection Work on Stack Exchange?", "source_url": "https://stackoverflow.blog/2020/06/25/how-does-spam-protection-work-on-stack-exchange/", "company": "Stack Exchange", "year": "2020", "original_content": "est, can simply... turn Tor access off.Lucky spammers get IP-blocked anywayOnce a HTTP request makes it to the Stack Exchange application, there's another roadblock in front of any potential spammers: SpamRam.SpamRam is Stack Exchange's custom-built spam-prevention system. It monitors all incoming new posts, squints at them suspiciously to decide whether they're spam, and knocks them for six if they are. It's... really good at it:Admittedly that's an old graph, but it's indicative of how good SpamRam is at getting rid of the crap before it even hits the sites.Part of why it's so good is that once it's identified spam, it feeds directly into IP blocking mechanisms. If a post gets blocked as potential spam, the IP address it came from can be blocked completely, hobbled (i.e.", "enriched_content": "The text describes a custom-built spam prevention system called SpamRam that is used by Stack Exchange to detect and block spam. Once a spam post is identified, the IP address of the spammer can be blocked completely or throttled, effectively preventing the spammer from continuing their activities. The system is highly effective at catching spam, as indicated by the graph showing the majority of spam being filtered out before it even reaches the site.", "ml_techniques": ["text_classification", "nlp", "spam_detection"], "chunk_summary": "The text outlines a robust spam detection and blocking system called SpamRam that is used by Stack Exchange to effectively combat spam on their platform.", "keywords": ["spam_detection", "spam_prevention", "IP_blocking", "custom_built_system", "text_classification", "anomaly_detection"], "chunk_index": 5, "content_hash": "5abd89624d66ce72e02cb8da7b50a347"}
{"chunk_id": "Stack Exchange_2020_6_eae5295b", "source_title": "How Does Spam Protection Work on Stack Exchange?", "source_url": "https://stackoverflow.blog/2020/06/25/how-does-spam-protection-work-on-stack-exchange/", "company": "Stack Exchange", "year": "2020", "original_content": "nce it's identified spam, it feeds directly into IP blocking mechanisms. If a post gets blocked as potential spam, the IP address it came from can be blocked completely, hobbled (i.e. severely rate-limited), or prevented from posting—that's the source of the \"You can't post due to the volume of spam/abuse originating from your network\" message, complaints about which pop up on meta every now and then.So what about that orange line? That's the stuff that gets through—that's the spam that users actually see. These posts get flagged as spam by users, which also feeds back into SpamRam and helps, again, to inform IP blocks.", "enriched_content": "The blog post discusses how the machine learning-based spam detection system at Stack Exchange works. Once a post is identified as spam, the system can take various actions, such as blocking the IP address completely, severely rate-limiting it, or preventing the user from posting. The orange line represents the spam that users see and report, which then feeds back into the system to improve the spam detection model.", "ml_techniques": ["text_classification", "nlp", "spam_detection"], "chunk_summary": "The blog post explains the workflow of Stack Exchange's machine learning-based spam detection system, including how it identifies and blocks spam, and how user feedback is used to further improve the system.", "keywords": ["machine learning", "anomaly detection", "spam detection", "natural language processing", "text classification", "IP blocking", "user feedback"], "chunk_index": 6, "content_hash": "eae5295bf4f312f8ad04ea54bdc0748a"}
{"chunk_id": "Stack Exchange_2020_7_31b6849e", "source_title": "How Does Spam Protection Work on Stack Exchange?", "source_url": "https://stackoverflow.blog/2020/06/25/how-does-spam-protection-work-on-stack-exchange/", "company": "Stack Exchange", "year": "2020", "original_content": "again, to inform IP blocks. Actions that moderators take can help fuel the system—moderators can flag spam too, of course, but they can also destroy users and specifically state that they're doing so because the user is a spammer, which is a strong signal to SpamRam that the IP address it came from is bad news.So how do folks find these posts to flag? That's where this last bit comes in.Really lucky spammers get spam-flagged to deathIf you're a crafty, sneaky, very lucky spammer, you might get some spam through and have it successfully land on a site without being blocked. Congratulations! Now you hit the last line of defence—the community's defence mechanisms.I mentioned spam flagging—anyone with over 15 reputation can do that.", "enriched_content": "The machine learning approach described in this text chunk involves using moderator actions and community feedback to detect and block spam. Moderators can flag spam posts, and they can also explicitly state that a user is a spammer, which sends a strong signal to the spam detection system. Users with sufficient reputation can also flag posts as spam. This community-driven process helps identify and block successful spam attempts that manage to bypass initial security measures.", "ml_techniques": ["text_classification", "nlp", "spam_detection"], "chunk_summary": "The text chunk describes how a machine learning-based spam detection system leverages moderator actions and community feedback to identify and block spam content, even for spammers who manage to bypass initial defenses.", "keywords": ["spam_detection", "anomaly_detection", "moderator_actions", "community_feedback", "text_classification"], "chunk_index": 7, "content_hash": "31b6849e2afba49ab3b6a8e00bfbfb59"}
{"chunk_id": "Stack Exchange_2020_8_d7e5f17d", "source_title": "How Does Spam Protection Work on Stack Exchange?", "source_url": "https://stackoverflow.blog/2020/06/25/how-does-spam-protection-work-on-stack-exchange/", "company": "Stack Exchange", "year": "2020", "original_content": "you hit the last line of defence—the community's defence mechanisms.I mentioned spam flagging—anyone with over 15 reputation can do that. If you see a spam post while browsing around the sites, you can spam-flag it. Six of these spam flags will automatically delete the post, mark it as spam (including hiding the contents), and feed it and its author to SpamRam.That relies on folks seeing spam while casually browsing. For the most part, that works pretty well, especially on the higher-traffic sites, but particularly on smaller sites, spam can linger for a while before it collects enough flags. Fortunately, this is a problem that some folks in the community recognised a long time ago, and started a project aimed at solving it.", "enriched_content": "To address the issue of spam detection on Stack Exchange, the community has implemented a multi-layered approach. Firstly, users with over 15 reputation can flag suspected spam posts, and once six such flags are received, the post is automatically deleted, marked as spam, and the author is penalized. This helps address spam on high-traffic sites, but on smaller sites, spam can sometimes linger before reaching the required number of flags. To address this, the community has recognized the need for a more proactive solution and has started a project aimed at solving the problem of lingering spam.", "ml_techniques": ["text_classification", "nlp", "spam_detection"], "chunk_summary": "The text discusses Stack Exchange's community-driven spam detection approach, which involves user flagging and automatic deletion, as well as a project to address the issue of lingering spam on smaller sites.", "keywords": ["text_classification", "nlp", "spam_detection", "community_moderation", "reputation_system", "flag_system", "proactive_detection"], "chunk_index": 8, "content_hash": "d7e5f17dfc2a0519ca7112686f41c2d5"}
{"chunk_id": "Stack Exchange_2020_9_cec063f5", "source_title": "How Does Spam Protection Work on Stack Exchange?", "source_url": "https://stackoverflow.blog/2020/06/25/how-does-spam-protection-work-on-stack-exchange/", "company": "Stack Exchange", "year": "2020", "original_content": "Fortunately, this is a problem that some folks in the community recognised a long time ago, and started a project aimed at solving it. Enter:Charcoal is the organisation that runs SmokeDetector, which, fundamentally, is a bot that looks for spam and feeds it into chatrooms where waiting users can follow the link and spam-flag it.Technically, it does this by listening to a Stack Exchange websocket and requesting the same action that's used to feed the realtime page. This gets us every new and edited question or answer, everywhere on the network. Each of these posts gets scanned, which involves running its content through an unholy amount of regular expressions and some heuristic tests, and seeing if any come back true.", "enriched_content": "The text describes a machine learning approach to detect spam on Stack Exchange. The key components are: - Charcoal, an organization that runs SmokeDetector, a bot that scans new and edited posts across the Stack Exchange network - The bot listens to a websocket to get real-time data on new and edited posts - It then runs the post content through a large number of regular expressions and heuristic tests to identify potential spam - This allows the bot to quickly flag spam and feed it into chatrooms where users can review and mark it as spam", "ml_techniques": ["text_classification", "nlp", "spam_detection"], "chunk_summary": "This text describes a real-time, rule-based machine learning approach to detecting spam on the Stack Exchange network, using a bot that scans new and edited posts.", "keywords": ["text classification", "natural language processing", "spam detection", "real-time", "rule-based", "websocket"], "chunk_index": 9, "content_hash": "cec063f53941f679ef8b36c7460e301b"}
{"chunk_id": "Stack Exchange_2020_10_6ce68250", "source_title": "How Does Spam Protection Work on Stack Exchange?", "source_url": "https://stackoverflow.blog/2020/06/25/how-does-spam-protection-work-on-stack-exchange/", "company": "Stack Exchange", "year": "2020", "original_content": "running its content through an unholy amount of regular expressions and some heuristic tests, and seeing if any come back true. The vast majority, of course, aren't spam, but there's a significant volume that are—and those get posted to chat to be flagged into ignominy.Doing things this way means we catch a lot of posts that aren't spam too (false positives). That's okay—because there's a human reviewing each post before flagging it, we're not aiming for a 0% false positive rate, but a 0% false negative rate—in other words, we're trying not to miss any spam, even if that means occasionally mistakenly identifying a good post as spam.Sometimes, though, humans aren't enough. No matter how quickly spam can get flagged and deleted, there's always more.", "enriched_content": "The machine learning approach described in this text chunk involves running the content through a series of regular expressions and heuristic tests to detect potential spam. While this method captures a significant amount of spam, it also results in some false positives, where non-spam posts are mistakenly identified as spam. The goal is to prioritize a low false negative rate, ensuring that no spam goes undetected, even if it means occasional false positives. However, the author acknowledges that human review alone is not sufficient to keep up with the constant influx of spam, and additional automated solutions may be necessary.", "ml_techniques": ["text_classification", "nlp", "spam_detection"], "chunk_summary": "This text chunk describes a machine learning approach to spam detection that uses regular expressions and heuristic tests, aiming for a low false negative rate at the cost of some false positives, and recognizing the need for more automated solutions to keep up with the volume of spam.", "keywords": ["spam_detection", "text_classification", "natural_language_processing", "regular_expressions", "heuristics", "false_positives", "false_negatives", "automated_solutions"], "chunk_index": 10, "content_hash": "6ce68250610233e7729012eeb6040502"}
{"chunk_id": "Stack Exchange_2020_11_525e339b", "source_title": "How Does Spam Protection Work on Stack Exchange?", "source_url": "https://stackoverflow.blog/2020/06/25/how-does-spam-protection-work-on-stack-exchange/", "company": "Stack Exchange", "year": "2020", "original_content": "stakenly identifying a good post as spam.Sometimes, though, humans aren't enough. No matter how quickly spam can get flagged and deleted, there's always more. It often comes in waves, and the volume of spam coming in at the peak of a wave can easily overwhelm human flaggers and take some time to catch up on and get everything deleted. That said—there's a theme here—there's a solution for that too.Arm the robot and set it looseWhen the flagging gets tough, the tough... hand over the reins to the computers and let them do the work.When Smokey decides that a post is spam, it sends it over to our web dashboard, metasmoke. Metasmoke is one of those applications that was originally really simple—just keep a record of the posts—but over time it's grown, and now it handles a whole lot of stuff.", "enriched_content": "The text discusses how machine learning techniques can be used to automate the process of identifying and removing spam posts in online communities. It explains that while human moderation is effective, it can be overwhelmed by the sheer volume of spam, especially during peak periods. To address this, the authors have developed a \"robot\" system called Smokey that can automatically detect and flag spam posts, which are then sent to a web dashboard called Metasmoke for further processing and deletion.", "ml_techniques": ["text_classification", "nlp", "spam_detection"], "chunk_summary": "The text describes how a machine learning-based system called Smokey is used to automatically detect and remove spam posts, complementing human moderation efforts.", "keywords": ["text classification", "natural language processing", "spam detection", "machine learning", "automation", "online moderation"], "chunk_index": 11, "content_hash": "525e339b142b7695ce0eb2e40a01babb"}
{"chunk_id": "Stack Exchange_2020_12_a102e135", "source_title": "How Does Spam Protection Work on Stack Exchange?", "source_url": "https://stackoverflow.blog/2020/06/25/how-does-spam-protection-work-on-stack-exchange/", "company": "Stack Exchange", "year": "2020", "original_content": "web dashboard, metasmoke. Metasmoke is one of those applications that was originally really simple—just keep a record of the posts—but over time it's grown, and now it handles a whole lot of stuff. Stuff like:Keep a record of the postsRecord any feedback that posts get—true positive, false positive, not an answer, etc.Run review queues to get feedback on posts that nobody's looked at yetRecord and classify websites that have been used in spamCoordinate multiple SmokeDetector instances and manage failoverDisplay all the pretty graphsHost an API for other things (like userscripts) to integrate with itPerhaps most importantly, run autoflagging.In November-December 2016, we built a system into metasmoke that identifies the posts most likely to be spam as they come in.", "enriched_content": " Metasmoke is a web dashboard that was originally designed to keep a record of posts, but has since grown to handle a variety of tasks. These include recording feedback on posts, running review queues, recording and classifying websites used in spam, coordinating multiple SmokeDetector instances, displaying analytics, and hosting an API for integration with other tools. Perhaps the most important feature is the autoflagging system, which was built into Metasmoke in late 2016 to identify the posts most likely to be spam as they come in.", "ml_techniques": ["text_classification", "nlp", "spam_detection"], "chunk_summary": " Metasmoke is a web dashboard that started as a simple post tracking tool but has evolved to handle a wide range of spam detection and management tasks, including an autoflagging system to identify potential spam posts.", "keywords": [" web_dashboard", "metasmoke", "spam_detection", "text_classification", "nlp", "autoflagging", "anomaly_detection"], "chunk_index": 12, "content_hash": "a102e13594c3e13ac1defec7841eeb02"}
{"chunk_id": "Stack Exchange_2020_13_e11cada2", "source_title": "How Does Spam Protection Work on Stack Exchange?", "source_url": "https://stackoverflow.blog/2020/06/25/how-does-spam-protection-work-on-stack-exchange/", "company": "Stack Exchange", "year": "2020", "original_content": "ith itPerhaps most importantly, run autoflagging.In November-December 2016, we built a system into metasmoke that identifies the posts most likely to be spam as they come in. We tested it for a while on dry-run (not casting any flags), then we tested again, casting flags using one lucky victim volunteer's account. It exceeded our expectations—the accuracy was through the roof, and it was catching almost all of the blatantly obvious spam. In February, we launched the system publicly and included an appeal for flaggers to lend us their flags, that is, to sign up with metasmoke so that the system can flag posts in their name. Not long after that, we moved the system from casting a single automatic flag on each post, to casting three automatic flags on each post.", "enriched_content": "The text describes a system that was developed to detect spam posts on the website. The system was first tested in a dry-run mode, then with the help of a volunteer account, and found to be highly accurate in identifying blatant spam. The system was then launched publicly, and the company appealed for users to lend their flagging capabilities to the system, which then started casting three automatic flags on each post identified as spam.", "ml_techniques": ["text_classification", "nlp", "spam_detection"], "chunk_summary": "The text discusses the development and implementation of an automated spam detection system that uses machine learning to identify and flag spam posts with high accuracy.", "keywords": ["spam_detection", "text_classification", "anomaly_detection", "natural_language_processing", "automated_flagging", "machine_learning"], "chunk_index": 13, "content_hash": "e11cada225bd114cce704efcb890c139"}
{"chunk_id": "Stack Exchange_2020_14_c436c58e", "source_title": "How Does Spam Protection Work on Stack Exchange?", "source_url": "https://stackoverflow.blog/2020/06/25/how-does-spam-protection-work-on-stack-exchange/", "company": "Stack Exchange", "year": "2020", "original_content": "can flag posts in their name. Not long after that, we moved the system from casting a single automatic flag on each post, to casting three automatic flags on each post. We saw an almost instant reduction in time to deletion in both cases:In the time since then, we've continued to make improvements to the system, ultimately resulting in moving up again to four flags on the posts that the system is most confident are spam. We've also started casting one autoflag on every post from the SmokeDetector account to help moderators identify posts that were affected by this system, which has the handy side effect of letting us monitor accuracy from SmokeDetector's flag history. Spoiler alert: it's stupidly accurate.", "enriched_content": "The text describes an anomaly detection system used by Stack Exchange to flag potential spam posts. The system started by automatically casting a single flag on each post it identified as spam, which led to a reduction in the time it took to delete those posts. The system was later improved to cast three automatic flags per post, and then four flags on the posts it was most confident were spam. The system also casts one automatic flag on every post from the SmokeDetector account, which helps moderators identify affected posts and allows the accuracy of the system to be monitored.", "ml_techniques": ["text_classification", "nlp", "spam_detection"], "chunk_summary": "The text outlines the evolution of an anomaly detection system used by Stack Exchange to identify and flag potential spam posts, with improvements leading to increased accuracy and efficiency.", "keywords": ["anomaly_detection", "spam_detection", "text_classification", "natural_language_processing", "supervised_learning", "classification", "system_monitoring", "model_improvement"], "chunk_index": 14, "content_hash": "c436c58e33ce7742f97d397eb1d767cb"}
{"chunk_id": "Stack Exchange_2020_15_767d8fd3", "source_title": "How Does Spam Protection Work on Stack Exchange?", "source_url": "https://stackoverflow.blog/2020/06/25/how-does-spam-protection-work-on-stack-exchange/", "company": "Stack Exchange", "year": "2020", "original_content": "side effect of letting us monitor accuracy from SmokeDetector's flag history. Spoiler alert: it's stupidly accurate.Charcoal and SmokeDetector are, effectively, the last line of defence against spam on Stack Exchange. With all these systems in combination, Stack Exchange does a ridiculously good job of protecting itself against spam.So what's next?For Stack Exchange? Who knows—there are always improvements that can be made to spam detection systems. For Charcoal? We'll carry on tweaking the system and updating our detection rules, always looking for more spam to delete.If you're interested in finding out more about Charcoal, you can have a look around the website, our GitHub organisation, or you can drop into chat with us.", "enriched_content": "The machine learning anomaly detection approach described in this text chunk involves using a system called SmokeDetector to monitor the accuracy of spam detection on the Stack Exchange platform. The system is reported to be \"stupidly accurate\" in detecting spam, and it is used in combination with other techniques to provide a robust defense against spam on the platform. The approach is continuously being updated and improved, with the team behind Charcoal, the underlying system, always looking for new ways to detect and delete spam.", "ml_techniques": ["text_classification", "nlp", "spam_detection"], "chunk_summary": "This text chunk describes a highly accurate machine learning-based spam detection system used by Stack Exchange, which is continuously being improved and updated.", "keywords": ["text_classification", "nlp", "spam_detection", "anomaly_detection", "accuracy_monitoring", "SmokeDetector", "Charcoal"], "chunk_index": 15, "content_hash": "767d8fd3c237cd1695e70827aa993237"}
{"chunk_id": "Stack Exchange_2020_16_b76dd224", "source_title": "How Does Spam Protection Work on Stack Exchange?", "source_url": "https://stackoverflow.blog/2020/06/25/how-does-spam-protection-work-on-stack-exchange/", "company": "Stack Exchange", "year": "2020", "original_content": "finding out more about Charcoal, you can have a look around the website, our GitHub organisation, or you can drop into chat with us. We're always looking for new faces to help out—whether you're just mildly interested or you think you could work on the next big feature, we'd love to have you.", "enriched_content": "The provided text discusses the Charcoal project, which is an open-source machine learning-based anomaly detection system. It encourages interested individuals to explore the project's website, GitHub organization, or join the chat to get involved, whether they have a casual interest or the potential to work on major features.", "ml_techniques": ["text_classification", "nlp", "spam_detection"], "chunk_summary": "This text introduces the Charcoal project, an open-source anomaly detection system, and invites people to participate in the project through various channels.", "keywords": ["anomaly_detection", "open-source", "machine_learning", "text_analysis", "project_involvement", "community_engagement", "GitHub", "chat"], "chunk_index": 16, "content_hash": "b76dd2248c15540fb7241a77a816a79f"}
{"chunk_id": "Cloudflare_2020_0_ac134b4b", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "Cloudflare Bot Management: machine learning and more2020-05-06Alex Bocharov13 min readThis post is also available in 日本語 and 한국어. Introduction Building Cloudflare Bot Management platform is an exhilarating experience. It blends Distributed Systems, Web Development, Machine Learning, Security and Research (and every discipline in between) while fighting ever-adaptive and motivated adversaries at the same time.This is the ongoing story of Bot Management at Cloudflare and also an introduction to a series of blog posts about the detection mechanisms powering it. I’ll start with several definitions from the Bot Management world, then introduce the product and technical requirements, leading to an overview of the platform we’ve built.", "enriched_content": "The blog post discusses Cloudflare's Bot Management platform, which combines various disciplines such as distributed systems, web development, machine learning, security, and research to detect and manage bot traffic. It provides an introduction to the product and its technical requirements, as well as an overview of the platform developed by Cloudflare.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "This blog post introduces Cloudflare's Bot Management platform, which leverages a blend of technologies, including machine learning, to detect and manage bot traffic on the web.", "keywords": ["bot_management", "machine_learning", "distributed_systems", "web_development", "security", "research"], "chunk_index": 0, "content_hash": "ac134b4b5ee5cb3345b44c98913dfc25"}
{"chunk_id": "Cloudflare_2020_1_57fe1e14", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "from the Bot Management world, then introduce the product and technical requirements, leading to an overview of the platform we’ve built. Finally, I’ll share details about the detection mechanisms powering our platform.Let’s start with Bot Management’s nomenclature. Some Definitions Bot - an autonomous program on a network that can interact with computer systems or users, imitating or replacing a human user's behavior, performing repetitive tasks much faster than human users could.Good bots - bots which are useful to businesses they interact with, e.g. search engine bots like Googlebot, Bingbot or bots that operate on social media platforms like Facebook Bot.Bad bots - bots which are designed to perform malicious actions, ultimately hurting businesses, e.g.", "enriched_content": "What is the definition of a bot in the context of this paper? A bot is an autonomous program on a network that can interact with computer systems or users, imitating or replacing a human user's behavior and performing repetitive tasks much faster than human users could. The paper distinguishes between \"good bots\" that are useful to businesses, such as search engine bots, and \"bad bots\" that are designed to perform malicious actions and ultimately hurt businesses.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "This text chunk introduces the concept of bots and their classification into \"good bots\" and \"bad bots\" in the context of bot management. It sets the stage for discussing the technical requirements and detection mechanisms for a platform that addresses bot-related challenges.", "keywords": ["bot management", "behavioral analysis", "traffic analysis", "bot detection", "autonomous program", "malicious actions"], "chunk_index": 1, "content_hash": "57fe1e14ceb2c477ab9ec2f2dbc322db"}
{"chunk_id": "Cloudflare_2020_2_d13a3bc2", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "ot or bots that operate on social media platforms like Facebook Bot.Bad bots - bots which are designed to perform malicious actions, ultimately hurting businesses, e.g. credential stuffing bots, third-party scraping bots, spam bots and sneakerbots. Bot Management - blocking undesired or malicious Internet bot traffic while still allowing useful bots to access web properties by detecting bot activity, discerning between desirable and undesirable bot behavior, and identifying the sources of the undesirable activity.WAF - a security system that monitors and controls network traffic based on a set of security rules.", "enriched_content": " The paper discusses different types of bots and bot management techniques. It explains that there are \"good\" bots, which are useful, and \"bad\" bots, which are designed to perform malicious actions. The paper then describes bot management as the process of blocking undesired or malicious bot traffic while still allowing useful bots to access web properties. This involves detecting bot activity, discerning between desirable and undesirable bot behavior, and identifying the sources of the undesirable activity. Finally, the paper mentions a WAF (Web Application Firewall) as a security system that monitors and controls network traffic based on a set of security rules.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": " The paper discusses the challenges of managing different types of bots, including malicious bots, and the techniques used to detect and block undesirable bot traffic while allowing useful bots.", "keywords": [" bot detection", "bot management", "behavioral analysis", "traffic analysis", "web application firewall", "malicious bots", "credential stuffing", "web scraping"], "chunk_index": 2, "content_hash": "d13a3bc2f5954f127ce532a1579e4520"}
{"chunk_id": "Cloudflare_2020_3_bb4de258", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "of security rules. Gathering requirements Cloudflare has been stopping malicious bots from accessing websites or misusing APIs from the very beginning, at the same time helping the climate by offsetting the carbon costs from the bots. Over time it became clear that we needed a dedicated platform which would unite different bot fighting techniques and streamline the customer experience. In designing this new platform, we tried to fulfill the following key requirements.Complete, not complex - customers can turn on/off Bot Management with a single click of a button, to protect their websites, mobile applications, or APIs.Trustworthy - customers want to know whether they can trust the website visitor is who they say they are and provide a certainty indicator for that trust level.", "enriched_content": "Cloudflare's new bot management platform aims to provide a complete and easy-to-use solution for protecting websites, mobile apps, and APIs from malicious bots. The platform combines various bot fighting techniques to deliver a trustworthy solution that can determine the reliability of website visitors with a clear certainty indicator.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "This text describes Cloudflare's development of a comprehensive bot management platform that is designed to be simple to use and provide reliable bot detection capabilities for their customers.", "keywords": ["bot management", "bot detection", "behavioral analysis", "traffic analysis", "customer experience", "security", "cloud services"], "chunk_index": 3, "content_hash": "bb4de258f968eb4a2e454c86df4f678e"}
{"chunk_id": "Cloudflare_2020_4_b152e848", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "bile applications, or APIs.Trustworthy - customers want to know whether they can trust the website visitor is who they say they are and provide a certainty indicator for that trust level.Flexible - customers should be able to define what subset of the traffic Bot Management mitigations should be applied to, e.g. only login URLs, pricing pages or sitewide.Accurate - Bot Management detections should have a very small error, e.g. none or very few human visitors ever should be mistakenly identified as bots.Recoverable - in case a wrong prediction was made, human visitors still should be able to access websites as well as good bots being let through.", "enriched_content": "The machine learning approach for anomaly detection in this text chunk aims to address the following key requirements: Trustworthiness: The approach should provide a certainty indicator for the trust level of website visitors, allowing customers to verify if the visitors are who they claim to be. Flexibility: Customers should have the ability to define which specific subsets of traffic, such as login URLs or pricing pages, the Bot Management mitigations should be applied to, rather than a one-size-fits-all approach. Accuracy: The bot detection should have a very low error rate, ensuring that human visitors are rarely, if ever, mistakenly identified as bots. Recoverability: In case of a wrong prediction, the approach should still allow human visitors to access the website, and let good bots through without disruption.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "This text chunk outlines the key requirements for a machine learning-based anomaly detection approach, focusing on trustworthiness, flexibility, accuracy, and recoverability of the bot management system.", "keywords": ["anomaly_detection", "bot_detection", "traffic_analysis", "behavioral_analysis", "machine_learning", "trust_indicator", "flexibility", "accuracy", "recoverability"], "chunk_index": 4, "content_hash": "b152e84891691d459b27243a8eb272f4"}
{"chunk_id": "Cloudflare_2020_5_b550d630", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "cess websites as well as good bots being let through.Moreover, the goal for new Bot Management product was to make it work well on the following use cases: Technical requirements Additionally, to the product requirements above, we engineers had a list of must-haves for the new Bot Management platform. The most critical were:Scalability - the platform should be able to calculate a score on every request, even at over 10 million requests per second.Low latency - detections must be performed extremely quickly, not slowing down request processing by more than 100 microseconds, and not requiring additional hardware.Configurability - it should be possible to configure what detections are applied on what traffic, including on per domain/data center/server level.", "enriched_content": "The machine learning approach used in this paper aims to address the following key requirements for a Bot Management platform: 1. Scalability: The platform should be able to calculate a score on every request, even at over 10 million requests per second. 2. Low latency: Detections must be performed extremely quickly, not slowing down request processing by more than 100 microseconds, and not requiring additional hardware. 3. Configurability: It should be possible to configure what detections are applied on what traffic, including on a per domain/data center/server level. The platform also needs to effectively detect and manage both malicious bots and good bots, allowing legitimate traffic while blocking malicious activity.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "This paper describes the technical requirements and design considerations for a scalable, low-latency, and configurable machine learning-based Bot Management platform capable of handling high-volume traffic.", "keywords": ["machine learning", "anomaly detection", "bot management", "scalability", "low latency", "configurability", "behavioral analysis", "traffic analysis", "bot detection"], "chunk_index": 5, "content_hash": "b550d6306b47ee4504cdf99a5fece2b9"}
{"chunk_id": "Cloudflare_2020_6_a324a113", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "ditional hardware.Configurability - it should be possible to configure what detections are applied on what traffic, including on per domain/data center/server level.Modifiability - the platform should be easily extensible with more detection mechanisms, different mitigation actions, richer analytics and logs.Security - no sensitive information from one customer should be used to build models that protect another customer.Explainability & debuggability - we should be able to explain and tune predictions in an intuitive way.Equipped with these requirements, back in 2018, our small team of engineers got to work to design and build the next generation of Cloudflare Bot Management. Meet the Score “Simplicity is the ultimate sophistication.”- Leonardo Da VinciCloudflare operates on a vast scale.", "enriched_content": "The machine learning approach described in this text chunk should be configurable to apply different detection mechanisms on specific traffic, easily extensible with new detection and mitigation capabilities, and ensure that sensitive customer data is not used to protect other customers. The approach should also be explainable and debuggable, allowing for intuitive tuning of predictions. This is important as Cloudflare operates at a vast scale.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "The text describes the requirements for a scalable, configurable, and secure machine learning-based anomaly detection system for Cloudflare's bot management, emphasizing the need for explainability and extensibility.", "keywords": ["anomaly_detection", "bot_management", "configurability", "extensibility", "security", "explainability", "scalability", "Cloudflare"], "chunk_index": 6, "content_hash": "a324a113502c697ec9034fd4c62382a7"}
{"chunk_id": "Cloudflare_2020_7_bcc43fb3", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "ers got to work to design and build the next generation of Cloudflare Bot Management. Meet the Score “Simplicity is the ultimate sophistication.”- Leonardo Da VinciCloudflare operates on a vast scale. At the time of this writing, this means covering 26M+ Internet properties, processing on average 11M requests per second (with peaks over 14M), and examining more than 250 request attributes from different protocol levels. The key question is how to harness the power of such “gargantuan” data to protect all of our customers from modern day cyberthreats in a simple, reliable and explainable way?Bot management is hard.", "enriched_content": "Cloudflare's Bot Management system is designed to handle the massive scale of internet traffic it processes, with over 26 million properties, 11 million requests per second, and 250 request attributes analyzed. The key challenge is how to leverage this vast data to protect customers from cyberthreats in a simple, reliable, and explainable manner. The system aims to address the inherent complexity of bot management through a sophisticated yet straightforward approach.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "This text discusses Cloudflare's efforts to design and build the next generation of its Bot Management system, which must handle the company's massive scale of internet traffic and protect customers from cyberthreats in a simple, reliable, and explainable way.", "keywords": ["behavioral_analysis", "traffic_analysis", "bot_detection", "cybersecurity", "scalability", "simplicity", "explainability"], "chunk_index": 7, "content_hash": "bcc43fb3558ef972f2ed8d7d4cd565bc"}
{"chunk_id": "Cloudflare_2020_8_a86b3e9d", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "t management is hard. Some bots are much harder to detect and require looking at multiple dimensions of request attributes over a long time, and sometimes a single request attribute could give them away. More signals may help, but are they generalizable?When we classify traffic, should customers decide what to do with it or are there decisions we can make on behalf of the customer? What concept could possibly address all these uncertainty problems and also help us to deliver on the requirements from above?As you might’ve guessed from the section title, we came up with the concept of Trusted Score or simply The Score - one thing to rule them all - indicating the likelihood between 0 and 100 whether a request originated from a human (high score) vs. an automated program (low score).", "enriched_content": " What is the approach used in this paper to address the challenges of bot detection and traffic classification? The paper presents a concept called \"Trusted Score\" or \"The Score\" that aims to address the uncertainty and complexity of bot detection. This score indicates the likelihood that a request originated from a human (high score) or an automated program (low score). The paper explores the use of multiple request attributes and signals over time to determine this score, rather than relying on a single attribute. The authors also discuss the decision-making process, whether customers should determine the actions based on the score or if there are decisions the system can make on behalf of the customer.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": " This paper introduces a \"Trusted Score\" concept that uses behavioral analysis and traffic attributes over time to determine the likelihood of a request being from a human or an automated program, addressing the challenges of bot detection and traffic classification.", "keywords": [" anomaly_detection", "bot_detection", "behavioral_analysis", "traffic_analysis", "machine_learning", "trusted_score", "request_attributes"], "chunk_index": 8, "content_hash": "a86b3e9d29dce6ba0d59be56050d2d5b"}
{"chunk_id": "Cloudflare_2020_9_d95eda60", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "ore or simply The Score - one thing to rule them all - indicating the likelihood between 0 and 100 whether a request originated from a human (high score) vs. an automated program (low score). \"One Ring to rule them all\" by idreamlikecrazy, used under CC BY / Desaturated from originalOkay, let’s imagine that we are able to assign such a score on every incoming HTTP/HTTPS request, what are we or the customer supposed to do with it? Maybe it’s enough to provide such a score in the logs. Customers could then analyze them on their end, find the most frequent IPs with the lowest scores, and then use the Cloudflare Firewall to block those IPs.", "enriched_content": "To determine the likelihood of a request being from a human versus an automated program, the system assigns a score between 0 and 100, with a high score indicating a human and a low score indicating an automated program. The customer can then analyze the logs to find the most frequent IPs with the lowest scores and use the Cloudflare Firewall to block those IPs.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "This chunk describes a machine learning-based anomaly detection system that assigns a score to each incoming request to determine if it's from a human or an automated program, allowing the customer to analyze the logs and block suspicious IPs.", "keywords": ["behavioral_analysis", "traffic_analysis", "bot_detection", "anomaly_detection", "HTTP/HTTPS", "Cloudflare_Firewall"], "chunk_index": 9, "content_hash": "d95eda606e08533c95d3210b29a4ea6a"}
{"chunk_id": "Cloudflare_2020_10_cf21161c", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "the Cloudflare Firewall to block those IPs. Although useful, such a process would be manual, prone to error and most importantly cannot be done in real time to protect the customer's Internet property.Fortunately, around the same time we started worked on this system , our colleagues from the Firewall team had just announced Firewall Rules. This new capability provided customers the ability to control requests in a flexible and intuitive way, inspired by the widely known Wireshark® language. Firewall rules supported a variety of request fields, and we thought - why not have the score be one of these fields? Customers could then write granular rules to block very specific attack types. That’s how the cf.bot_management.score field was born.", "enriched_content": "The Cloudflare Firewall is used to block IP addresses that exhibit anomalous behavior. However, this manual process is prone to errors and cannot be done in real-time to protect customer internet properties. To address this, Cloudflare introduced Firewall Rules, which allow customers to control requests using a flexible and intuitive language similar to Wireshark. This new capability enabled the introduction of the cf.bot_management.score field, which allows customers to write granular rules to block specific types of attacks.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "This text describes Cloudflare's approach to real-time anomaly detection and mitigation using machine learning techniques integrated with their Firewall Rules capability.", "keywords": ["anomaly_detection", "behavioral_analysis", "traffic_analysis", "bot_detection", "firewall_rules"], "chunk_index": 10, "content_hash": "cf21161c73d6d803bac6a5a1c4f9fc70"}
{"chunk_id": "Cloudflare_2020_11_253078e0", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "f these fields? Customers could then write granular rules to block very specific attack types. That’s how the cf.bot_management.score field was born.Having a score in the heart of Cloudflare Bot Management addressed multiple product and technical requirements with one strike - it’s simple, flexible, configurable, and it provides customers with telemetry about bots on a per request basis. Customers can adjust the score threshold in firewall rules, depending on their sensitivity to false positives/negatives. Additionally, this intuitive score allows us to extend our detection capabilities under the hood without customers needing to adjust any configuration.So how can we produce this score and how hard is it? Let’s explore it in the following section.", "enriched_content": "The Cloudflare Bot Management system uses a bot detection score to help customers identify and block specific types of bot attacks. This score is flexible, configurable, and provides detailed telemetry on a per-request basis, allowing customers to adjust their sensitivity to false positives and negatives. The system is designed to extend detection capabilities without requiring customers to change their configurations.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "This text covers the design and implementation of a bot detection score in Cloudflare's Bot Management system, which provides a flexible and configurable way for customers to identify and block bot attacks.", "keywords": ["bot_detection", "behavioral_analysis", "traffic_analysis", "anomaly_detection", "telemetry", "false_positives", "false_negatives", "configurable_rules"], "chunk_index": 11, "content_hash": "253078e0bef5bf2dbf9c4df680c59dca"}
{"chunk_id": "Cloudflare_2020_12_6bcc1358", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "the hood without customers needing to adjust any configuration.So how can we produce this score and how hard is it? Let’s explore it in the following section. Architecture overview What is powering the Bot Management score? The short answer is a set of microservices. Building this platform we tried to re-use as many pipelines, databases and components as we could, however many services had to be built from scratch. Let’s have a look at overall architecture (this overly simplified version contains Bot Management related services): Core Bot Management services In a nutshell our systems process data received from the edge data centers, produce and store data required for bot detection mechanisms using the following technologies:Databases & data stores - Kafka, ClickHouse, Postgres, Redis, Cep", "enriched_content": "The Cloudflare paper discusses a machine learning-based approach to detecting bot activity on their network. The key components of this approach include processing data from the edge data centers, using various databases and data stores like Kafka, ClickHouse, Postgres, Redis, and CEP to power the bot detection mechanisms, and delivering a Bot Management score to customers without any configuration changes on their end.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "The paper describes Cloudflare's ML-based approach to bot detection, which involves processing edge data, using multiple databases and data stores, and providing a Bot Management score to customers.", "keywords": ["behavioral_analysis", "traffic_analysis", "bot_detection", "microservices", "edge_data_processing", "databases", "data_stores"], "chunk_index": 12, "content_hash": "6bcc13584125804d5d7b9fbaa937fd85"}
{"chunk_id": "Cloudflare_2020_13_e2d7e7ea", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "ata received from the edge data centers, produce and store data required for bot detection mechanisms using the following technologies:Databases & data stores - Kafka, ClickHouse, Postgres, Redis, Ceph.Programming languages - Go, Rust, Python, Java, Bash.Configuration & schema management - Salt, Quicksilver, Cap’n Proto.Containerization - Docker, Kubernetes, Helm, Mesos/Marathon.Each of these services is built with resilience, performance, observability and security in mind. Edge Bot Management module All bot detection mechanisms are applied on every request in real-time during the request processing stage in the Bot Management module running on every machine at Cloudflare’s edge locations.", "enriched_content": "The machine learning anomaly detection approach used by Cloudflare involves analyzing data received from edge data centers to detect bot activities. It utilizes various technologies such as databases, programming languages, configuration management tools, and containerization platforms to build resilient, high-performance, observable, and secure services. The Bot Management module at Cloudflare's edge locations applies the bot detection mechanisms in real-time during the request processing stage.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "This text chunk describes the technical infrastructure and components used by Cloudflare to implement a real-time, edge-based bot detection and management system.", "keywords": ["behavioral_analysis", "traffic_analysis", "bot_detection", "databases", "programming_languages", "containerization", "edge_computing", "resilience", "performance", "observability", "security"], "chunk_index": 13, "content_hash": "e2d7e7ea0defb68cc06c3eced1ebcf2f"}
{"chunk_id": "Cloudflare_2020_14_0f478906", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "cessing stage in the Bot Management module running on every machine at Cloudflare’s edge locations. When a request comes in we extract and transform the required request attributes and feed them to our detection mechanisms. The Bot Management module produces the following output:Firewall fields - Bot Management fields- cf.bot_management.score - an integer indicating the likelihood between 0 and 100 whether a request originated from an automated program (low score) to a human (high score).- cf.bot_management.verified_bot - a boolean indicating whether such request comes from a Cloudflare allowlisted bot.- cf.bot_management.static_resource - a boolean indicating whether request matches file extensions for many types of static resources.", "enriched_content": "The machine learning approach described in this text chunk involves a processing stage in the Bot Management module at Cloudflare's edge locations. When a request comes in, the relevant request attributes are extracted and transformed, and then fed into the detection mechanisms. The output of the Bot Management module includes fields such as the bot likelihood score, an indication of whether the request comes from a Cloudflare-allowlisted bot, and whether the request matches file extensions for static resources.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "This text chunk outlines the processing pipeline and output of Cloudflare's machine learning-based Bot Management module, which analyzes incoming requests to detect and categorize automated and human-generated traffic.", "keywords": ["machine learning", "anomaly detection", "bot detection", "traffic analysis", "behavioral analysis", "edge computing", "Cloudflare"], "chunk_index": 14, "content_hash": "0f478906bdf1b023b2c7678da0846dc1"}
{"chunk_id": "Cloudflare_2020_15_9e5aa7ff", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "isted bot.- cf.bot_management.static_resource - a boolean indicating whether request matches file extensions for many types of static resources.Cookies - most notably it produces cf_bm, which helps manage incoming traffic that matches criteria associated with bots.JS challenges - for some of our detections and customers we inject into invisible JavaScript challenges, providing us with more signals for bot detection.Detection logs - we log through our data pipelines to ClickHouse details about each applied detection, used features and flags, some of which are used for analytics and customer logs, while others are used to debug and improve our models.Once the Bot Management module has produced the required fields, the Firewall takes over the actual bot mitigation.", "enriched_content": "The machine learning approach used in this text chunk involves analyzing various signals and features to detect and mitigate bot traffic. These signals include static resource requests, cookies (notably the cf_bm cookie), JavaScript challenges, and detection logs. The Firewall module then takes over the actual bot mitigation process based on the information provided by the Bot Management module.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "This text chunk outlines the key components of a machine learning-based bot detection and mitigation system, including the use of various behavioral, traffic, and security-related signals to identify and handle bot traffic.", "keywords": ["bot detection", "behavioral analysis", "traffic analysis", "static resource detection", "cookie analysis", "JavaScript challenges", "detection logging", "firewall mitigation"], "chunk_index": 15, "content_hash": "9e5aa7ffefbf3dbbbcf6e00bb8090463"}
{"chunk_id": "Cloudflare_2020_16_11a352b1", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "s, while others are used to debug and improve our models.Once the Bot Management module has produced the required fields, the Firewall takes over the actual bot mitigation. Firewall integration The Cloudflare Firewall's intuitive dashboard enables users to build powerful rules through easy clicks and also provides Terraform integration. Every request to the firewall is inspected against the rule engine. Suspicious requests can be blocked, challenged or logged as per the needs of the user while legitimate requests are routed to the destination, based on the score produced by the Bot Management module and the configured threshold. Firewall rules provide the following bot mitigation actions:Log - records matching requests in the Cloudflare Logs provided to customers.", "enriched_content": "The text describes how Cloudflare's Bot Management module generates fields that are used to identify bots, and how the Cloudflare Firewall integrates with this module to mitigate bot activity. The Firewall's dashboard allows users to create rules to block, challenge, or log suspicious requests based on the bot scores generated by the Bot Management module. The Firewall takes over the actual bot mitigation process, routing legitimate requests to their destination.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "The text outlines Cloudflare's approach to bot mitigation, where the Bot Management module generates bot-related fields that are used by the Firewall to implement customizable rules for blocking, challenging, or logging suspicious traffic.", "keywords": ["bot detection", "behavioral analysis", "traffic analysis", "firewall integration", "anomaly detection", "rule-based mitigation", "Cloudflare"], "chunk_index": 16, "content_hash": "11a352b12648b5326fc6ffc1afb4465d"}
{"chunk_id": "Cloudflare_2020_17_5684cae9", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "module and the configured threshold. Firewall rules provide the following bot mitigation actions:Log - records matching requests in the Cloudflare Logs provided to customers.Bypass - allows customers to dynamically disable Cloudflare security features for a request.Allow - matching requests are exempt from challenge and block actions triggered by other Firewall Rules content.Challenge (Captcha) - useful for ensuring that the visitor accessing the site is human, and not automated.JS Challenge - useful for ensuring that bots and spam cannot access the requested resource; browsers, however, are free to satisfy the challenge automatically.Block - matching requests are denied access to the site.", "enriched_content": "The Cloudflare firewall rules provide various bot mitigation actions that can be applied to requests, including logging the requests, bypassing Cloudflare security features, allowing the requests, challenging the visitor with a CAPTCHA or JavaScript challenge, or blocking the requests entirely. These actions can be configured based on the output of the machine learning anomaly detection module and a specified threshold.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "This text chunk describes the bot mitigation actions available in the Cloudflare firewall rules, which can be used in conjunction with a machine learning anomaly detection module to address malicious traffic.", "keywords": ["machine learning", "anomaly detection", "bot mitigation", "firewall rules", "Cloudflare", "traffic analysis", "behavioral analysis", "bot detection"], "chunk_index": 17, "content_hash": "5684cae9d3ffe0b9ed7e67ecd7af31ae"}
{"chunk_id": "Cloudflare_2020_18_e5d31952", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "ree to satisfy the challenge automatically.Block - matching requests are denied access to the site.Our Firewall Analytics tool, powered by ClickHouse and GraphQL API, enables customers to quickly identify and investigate security threats using an intuitive interface. In addition to analytics, we provide detailed logs on all bots-related activity using either the Logpull API and/or LogPush, which provides the easy way to get your logs to your cloud storage. Cloudflare Workers integration In case a customer wants more flexibility on what to do with the requests based on the score, e.g. they might want to inject new, or change existing, HTML page content, or serve incorrect data to the bots, or stall certain requests, Cloudflare Workers provide an option to do that.", "enriched_content": " The described ML approach uses behavioral analysis and traffic analysis techniques to detect and mitigate security threats and malicious bot activity. The system leverages Cloudflare's Firewall Analytics tool, powered by ClickHouse and GraphQL API, to provide customers with an intuitive interface for quickly identifying and investigating these threats. The solution also offers detailed logs on bot-related activity through the Logpull API and LogPush, allowing customers to easily access and analyze their logs. Additionally, the integration with Cloudflare Workers provides customers with more flexibility in how they handle requests based on the detected threat scores, enabling them to take actions such as modifying content, serving incorrect data, or stalling certain requests.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": " The text discusses a machine learning-based anomaly detection system that uses behavioral and traffic analysis to identify and mitigate security threats and malicious bot activity, providing customers with analytical tools and flexible response options.", "keywords": [" anomaly_detection", "behavioral_analysis", "traffic_analysis", "bot_detection", "firewall_analytics", "clickhouse", "graphql", "logpull_api", "logpush", "cloudflare_workers"], "chunk_index": 18, "content_hash": "e5d31952d42969491e8ea7d44b69012e"}
{"chunk_id": "Cloudflare_2020_19_a930c78b", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "t want to inject new, or change existing, HTML page content, or serve incorrect data to the bots, or stall certain requests, Cloudflare Workers provide an option to do that. For example, using this small code-snippet, we can pass the score back to the origin server for more advanced real-time analysis or mitigation: addEventListener('fetch', event => { event.respondWith(handleRequest(event.request)) }) async function handleRequest(request) { request = new Request(request); request.headers.set(\"Cf-Bot-Score\", request.cf.bot_management.score) return fetch(request); } Now let’s have a look into how a single score is produced using multiple detection mechanisms.", "enriched_content": "The text discusses how Cloudflare's Workers feature can be used to analyze and respond to bot traffic. It describes how to pass the bot score back to the origin server for further analysis or mitigation, and how multiple detection mechanisms are used to produce a single bot score.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "The text outlines Cloudflare's approach to bot detection, which involves using Cloudflare Workers to analyze traffic, generate bot scores, and pass that information back to the origin server for further processing.", "keywords": ["bot_detection", "behavioral_analysis", "traffic_analysis", "Cloudflare_Workers", "anomaly_detection", "real-time_analysis", "mitigation"], "chunk_index": 19, "content_hash": "a930c78bb4256cdbd89cc89427726d7b"}
{"chunk_id": "Cloudflare_2020_20_85460780", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "ow a single score is produced using multiple detection mechanisms. Detection mechanisms The Cloudflare Bot Management platform currently uses five complementary detection mechanisms, producing their own scores, which we combine to form the single score going to the Firewall. Most of the detection mechanisms are applied on every request, while some are enabled on a per-customer basis to better fit their needs. Having a score on every request for every customer has the following benefits:Ease of onboarding - even before we enable Bot Management in active mode, we’re able to tell how well it’s going to work for the specific customer, including providing historical trends about bot activity.", "enriched_content": "The text describes how Cloudflare's Bot Management platform combines multiple detection mechanisms to produce a single anomaly detection score for each request. The platform uses five complementary detection mechanisms, with some enabled on a per-customer basis to better fit their needs. This approach provides benefits such as ease of onboarding, as the platform can provide historical trends about bot activity even before enabling Bot Management in active mode.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "The text explains Cloudflare's approach to anomaly detection, which leverages multiple complementary detection mechanisms to produce a single anomaly score for each request, with benefits such as ease of onboarding.", "keywords": ["anomaly_detection", "behavioral_analysis", "traffic_analysis", "bot_detection", "multi-modal_approach", "platform_architecture", "onboarding"], "chunk_index": 20, "content_hash": "85460780a4874e8b062d53717bab1ae4"}
{"chunk_id": "Cloudflare_2020_21_06fcb6b0", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "ing to work for the specific customer, including providing historical trends about bot activity.Feedback loop - availability of the score on every request along with all features has tremendous value for continuous improvement of our detection mechanisms.Ensures scaling - if we can compute for score every request and customer, it means that every Internet property behind Cloudflare is a potential Bot Management customer.Global bot insights - Cloudflare is sitting in front of more than 26M+ Internet properties, which allows us to understand and react to the tectonic shifts happening in security and threat intelligence over time.", "enriched_content": "The machine learning approach used in this paper is designed to provide personalized bot detection for each Cloudflare customer. The availability of the score and feature data on every request allows for continuous improvement of the detection mechanisms. The scalability of the approach means that any Internet property behind Cloudflare can potentially benefit from the bot management capabilities. Additionally, Cloudflare's position in front of over 26 million Internet properties gives the company a unique global perspective on security trends and threat intelligence.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "The paper describes a machine learning-based bot detection system that is tailored to individual customers, scalable, and leverages Cloudflare's global network to provide insights into security trends.", "keywords": ["behavioral_analysis", "traffic_analysis", "bot_detection", "anomaly_detection", "scalability", "threat_intelligence", "security_trends"], "chunk_index": 21, "content_hash": "06fcb6b048c3ae9e69ddeaa8638e031e"}
{"chunk_id": "Cloudflare_2020_22_309a44de", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "and threat intelligence over time.Overall globally, more than third of the Internet traffic visible to Cloudflare is coming from bad bots, while Bot Management customers have the ratio of bad bots even higher at ~43%! Let’s dive into specific detection mechanisms in chronological order of their integration with Cloudflare Bot Management. Machine learning The majority of decisions about the score are made using our machine learning models. These were also the first detection mechanisms to produce a score and to on-board customers back in 2018. The successful application of machine learning requires data high in Quantity, Diversity, and Quality, and thanks to both free and paid customers, Cloudflare has all three, enabling continuous learning and improvement of our models for all of our cus", "enriched_content": " The machine learning approach used in Cloudflare's Bot Management service involves several key elements: 1. What is the overall global trend in bad bot traffic observed by Cloudflare? More than a third of the internet traffic visible to Cloudflare is from bad bots, and for Bot Management customers, the ratio of bad bots is even higher at around 43%. 2. What were the first detection mechanisms used in Cloudflare's Bot Management? The majority of decisions about the bot score are made using machine learning models, which were the first detection mechanisms introduced back in 2018. 3. What are the key requirements for successful application of machine learning in this context? The successful application of machine learning requires data that is high in quantity, diversity, and quality. Cloudflare's free and paid customers provide the necessary data to enable continuous learning and improvement of their models.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": " This text chunk describes Cloudflare's use of machine learning for bot detection and management, highlighting the high prevalence of bad bots on the internet and the key requirements for successful machine learning-based detection.", "keywords": [" anomaly_detection", "bot_management", "machine_learning", "traffic_analysis", "behavioral_analysis", "threat_intelligence", "data_quality"], "chunk_index": 22, "content_hash": "309a44de539f7dcb613060df0da5a222"}
{"chunk_id": "Cloudflare_2020_23_927e76d3", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "uires data high in Quantity, Diversity, and Quality, and thanks to both free and paid customers, Cloudflare has all three, enabling continuous learning and improvement of our models for all of our customers.At the core of the machine learning detection mechanism is CatBoost - a high-performance open source library for gradient boosting on decision trees. The choice of CatBoost was driven by the library’s outstanding capabilities:Categorical features support - allowing us to train on even very high cardinality features.Superior accuracy - allowing us to reduce overfitting by using a novel gradient-boosting scheme.Inference speed - in our case it takes less than 50 microseconds to apply any of our models, making sure request processing stays extremely fast.", "enriched_content": "Cloudflare's machine learning approach for anomaly detection requires high-quality, diverse, and abundant data from both free and paid customers, enabling continuous learning and improvement of their models. The core of their detection mechanism is the CatBoost library, which was chosen for its strong support for categorical features, superior accuracy, and fast inference speed, ensuring that request processing remains extremely fast.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "This text chunk describes Cloudflare's machine learning approach for anomaly detection, which leverages the CatBoost library to provide efficient and accurate detection with minimal impact on request processing.", "keywords": ["anomaly_detection", "behavioral_analysis", "traffic_analysis", "bot_detection", "CatBoost", "gradient_boosting", "categorical_features", "inference_speed"], "chunk_index": 23, "content_hash": "927e76d3d7d16e3159b2fe7af616d8dd"}
{"chunk_id": "Cloudflare_2020_24_0d990e55", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "ent-boosting scheme.Inference speed - in our case it takes less than 50 microseconds to apply any of our models, making sure request processing stays extremely fast.C and Rust API - most of our business logic on the edge is written using Lua, more specifically LuaJIT, so having a compatible FFI interface to be able to apply models is fantastic.There are multiple CatBoost models run on Cloudflare’s Edge in the shadow mode on every request on every machine. One of the models is run in active mode, which influences the final score going to Firewall. All ML detection results and features are logged and recorded in ClickHouse for further analysis, model improvement, analytics and customer facing logs.", "enriched_content": "The text describes an ML-based anomaly detection approach used at Cloudflare. It mentions that the inference speed is less than 50 microseconds, allowing for fast request processing. The approach utilizes CatBoost models, with one model running in active mode to influence the final score sent to the Firewall. The results and features are logged in ClickHouse for further analysis, model improvement, and customer-facing logs.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "The text outlines an efficient ML-based anomaly detection system used at Cloudflare, with fast inference speed, multi-model architecture, and extensive logging for analysis and improvement.", "keywords": ["anomaly_detection", "edge_computing", "CatBoost", "inference_speed", "Lua", "ClickHouse"], "chunk_index": 24, "content_hash": "0d990e5507b3dbcd00e19a657babf819"}
{"chunk_id": "Cloudflare_2020_25_71a58fac", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "d and recorded in ClickHouse for further analysis, model improvement, analytics and customer facing logs. We feed both categorical and numerical features into our models, extracted from request attributes and inter-request features built using those attributes, calculated and delivered by the Gagarin inter-requests features platform.We’re able to deploy new ML models in a matter of seconds using an extremely reliable and performant Quicksilver configuration database. The same mechanism can be used to configure which version of an ML model should be run in active mode for a specific customer.", "enriched_content": "The machine learning approach described in the text chunk involves collecting and storing both categorical and numerical features extracted from request attributes and inter-request features. These features are then used to train and deploy new ML models in a matter of seconds using a reliable and performant configuration database. The same mechanism allows for configuring which version of an ML model should be used for a specific customer.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "The text chunk outlines a machine learning approach that leverages both categorical and numerical features extracted from request data and inter-request features to train and deploy new ML models quickly and efficiently for various customers.", "keywords": ["behavioral_analysis", "traffic_analysis", "bot_detection", "feature_extraction", "model_deployment", "configuration_management", "ClickHouse", "Gagarin"], "chunk_index": 25, "content_hash": "71a58fac0793890e125c15611ecd6999"}
{"chunk_id": "Cloudflare_2020_26_5e7be85a", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "deep dive into our machine learning detection mechanism deserves a blog post of its own and it will cover how do we train and validate our models on trillions of requests using GPUs, how model feature delivery and extraction works, and how we explain and debug model predictions both internally and externally. Heuristics engine Not all problems in the world are the best solved with machine learning. We can tweak the ML models in various ways, but in certain cases they will likely underperform basic heuristics. Often the problems machine learning is trying to solve are not entirely new. When building the Bot Management solution it became apparent that sometimes a single attribute of the request could give a bot away.", "enriched_content": "The machine learning detection mechanism involves training and validating models on trillions of requests using GPUs, feature delivery and extraction, and explaining and debugging model predictions internally and externally. Additionally, the paper discusses how heuristics can sometimes outperform machine learning models, especially for problems that are not entirely new, and how certain request attributes can be used to detect bots.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "The text covers the details of the machine learning detection mechanism, including model training, feature engineering, and model interpretation, as well as the role of heuristics in bot detection.", "keywords": ["machine learning", "anomaly detection", "model training", "feature engineering", "model interpretation", "heuristics", "bot detection"], "chunk_index": 26, "content_hash": "5e7be85a2ccf6f147757ecdf9568ae4b"}
{"chunk_id": "Cloudflare_2020_27_d44fdc2d", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "lding the Bot Management solution it became apparent that sometimes a single attribute of the request could give a bot away. This means that we can create a bunch of simple rules capturing bots in a straightforward way, while also ensuring lowest false positives.The heuristics engine was the second detection mechanism integrated into the Cloudflare Bot Management platform in 2019 and it’s also applied on every request. We have multiple heuristic types and hundreds of specific rules based on certain attributes of the request, some of which are very hard to spoof. When any of the requests matches any of the heuristics - we assign the lowest possible score of 1.", "enriched_content": "The Cloudflare Bot Management solution uses a combination of behavioral analysis and traffic analysis techniques to detect bots. The heuristics engine is one of the detection mechanisms, which applies hundreds of specific rules based on certain attributes of the request. When a request matches any of these heuristics, it is assigned the lowest possible score of 1, indicating a high likelihood of being a bot.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "The text describes the heuristics-based bot detection approach used in Cloudflare's Bot Management solution, which complements other techniques like behavioral and traffic analysis.", "keywords": ["anomaly_detection", "heuristics", "bot_detection", "behavioral_analysis", "traffic_analysis"], "chunk_index": 27, "content_hash": "d44fdc2d3f27f2aaed5d805c740dcaf0"}
{"chunk_id": "Cloudflare_2020_28_bc310275", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "s any of the heuristics - we assign the lowest possible score of 1.The engine has the following properties:Speed - if ML model inference takes less than 50 microseconds per model, hundreds of heuristics can be applied just under 20 microseconds!Deployability - the heuristics engine allows us to add new heuristic in a matter of seconds using Quicksilver, and it will be applied on every request.Vast coverage - using a set of simple heuristics allows us to classify ~15% of global traffic and ~30% of Bot Management customers’ traffic as bots. Not too bad for a few if conditions, right?Lowest false positives - because we’re very sure and conservative on the heuristics we add, this detection mechanism has the lowest FP rate among all detection mechanisms.", "enriched_content": "The text describes a machine learning-based anomaly detection engine with the following key properties: 1. Speed: The engine can apply hundreds of heuristics in under 20 microseconds, thanks to its fast model inference time of less than 50 microseconds per model. 2. Deployability: The engine allows for easy and quick addition of new heuristics using Quicksilver, which are then applied to every request. 3. Vast coverage: The set of simple heuristics used by the engine can classify around 15% of global traffic and 30% of Bot Management customers' traffic as bots. 4. Low false positives: The engine is very conservative in adding heuristics, resulting in the lowest false positive rate among all detection mechanisms.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "The text describes a machine learning-based anomaly detection engine that is fast, easily deployable, has wide coverage, and maintains a low false positive rate.", "keywords": ["machine learning", "anomaly detection", "heuristics", "bot detection", "traffic analysis", "behavioral analysis", "deployability", "speed", "false positives"], "chunk_index": 28, "content_hash": "bc310275cea5f8c7acebdf5141f7192f"}
{"chunk_id": "Cloudflare_2020_29_f5130e3b", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "positives - because we’re very sure and conservative on the heuristics we add, this detection mechanism has the lowest FP rate among all detection mechanisms.Labels for ML - because of the high certainty we use requests classified with heuristics to train our ML models, which then can generalize behavior learnt from from heuristics and improve detections accuracy.So heuristics gave us a lift when tweaked with machine learning and they contained a lot of the intuition about the bots, which helped to advance the Cloudflare Bot Management platform and allowed us to onboard more customers. Behavioral analysis Machine learning and heuristics detections provide tremendous value, but both of them require human input on the labels, or basically a teacher to distinguish between right and wrong.", "enriched_content": "The machine learning approach used in this anomaly detection paper/blog leverages a combination of heuristics and behavioral analysis to achieve high accuracy in bot detection. The heuristics are carefully designed to have a low false positive rate, and the labeled data from these heuristics is then used to train the machine learning models, which can further improve the detection accuracy by generalizing the learned behavior. The combination of heuristics and machine learning provides significant value, but both approaches require human input to distinguish between correct and incorrect classifications.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "This text discusses a machine learning approach that combines heuristic-based detection and behavioral analysis to achieve high accuracy in bot detection, with the heuristics providing labeled data to train the machine learning models.", "keywords": ["anomaly detection", "bot detection", "behavioral analysis", "heuristics", "machine learning", "labeled data", "false positive rate"], "chunk_index": 29, "content_hash": "f5130e3b21f61d7ac6fc295fcdf4bd90"}
{"chunk_id": "Cloudflare_2020_30_08bd5abf", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "oral analysis Machine learning and heuristics detections provide tremendous value, but both of them require human input on the labels, or basically a teacher to distinguish between right and wrong. While our supervised ML models can generalize well enough even on novel threats similar to what we taught them on, we decided to go further. What if there was an approach which doesn’t require a teacher, but rather can learn to distinguish bad behavior from the normal behavior?Enter the behavioral analysis detection mechanism, initially developed in 2018 and integrated with the Bot Management platform in 2019.", "enriched_content": "The text describes an approach to anomaly detection that does not require human input or labeling, unlike traditional supervised machine learning models. Instead, this approach, called behavioral analysis detection, aims to learn the difference between normal and abnormal behavior patterns without a teacher. The mechanism was initially developed in 2018 and integrated with the Bot Management platform in 2019.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "The text discusses a machine learning-based anomaly detection approach that can learn to distinguish normal from abnormal behavior without the need for human-labeled data, as opposed to traditional supervised ML models.", "keywords": ["anomaly_detection", "unsupervised_learning", "behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_index": 30, "content_hash": "08bd5abfe126e09f19772f786d6c1ca7"}
{"chunk_id": "Cloudflare_2020_31_bbeb26f2", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "rm in 2019. This is an unsupervised machine learning approach, which has the following properties:Fitting specific customer needs - it’s automatically enabled for all Bot Management customers, calculating and analyzing normal visitor behavior over an extended period of time.Detects bots never seen before - as it doesn’t use known bot labels, it can detect bots and anomalies from the normal behavior on specific customer’s website.Harder to evade - anomalous behavior is often a direct result of the bot’s specific goal.Please stay tuned for a more detailed blog about behavioral analysis models and the platform powering this incredible detection mechanism, protecting many of our customers from unseen attacks. Verified bots So far we’ve discussed how to detect bad bots and humans.", "enriched_content": "The machine learning approach used in this text chunk is an unsupervised method that automatically calculates and analyzes normal visitor behavior on a customer's website over an extended period of time. This allows the approach to detect bots and anomalies that have not been seen before, as it does not rely on known bot labels. The anomalous behavior detected is often a direct result of the bot's specific goal, making it harder to evade detection.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "This chunk describes an unsupervised machine learning approach that analyzes normal visitor behavior to detect previously unseen bots and anomalies, providing a robust and adaptive bot detection mechanism.", "keywords": ["unsupervised machine learning", "behavioral analysis", "traffic analysis", "bot detection", "anomaly detection"], "chunk_index": 31, "content_hash": "bbeb26f2e166389edf206df0020f010f"}
{"chunk_id": "Cloudflare_2020_32_757742c4", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "d the platform powering this incredible detection mechanism, protecting many of our customers from unseen attacks. Verified bots So far we’ve discussed how to detect bad bots and humans. What about good bots, some of which are extremely useful for the customer website? Is there a need for a dedicated detection mechanism or is there something we could use from previously described detection mechanisms? While the majority of good bot requests (e.g. Googlebot, Bingbot, LinkedInbot) already have low score produced by other detection mechanisms, we also need a way to avoid accidental blocks of useful bots. That’s how the Firewall field cf.bot_management.", "enriched_content": "The text discusses the need for detecting good bots, in addition to bad bots and humans, to avoid accidentally blocking useful bots on customer websites. It describes how the majority of good bot requests already have a low score from other detection mechanisms, but there is a need for a dedicated detection mechanism to avoid accidental blocks. The Firewall field cf.bot_management is introduced as the solution to this challenge.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "The text covers the challenge of detecting good bots while blocking bad bots and humans, and introduces the Firewall field cf.bot_management as a solution to avoid accidental blocks of useful bots.", "keywords": ["behavioral_analysis", "traffic_analysis", "bot_detection", "good_bots", "bad_bots", "firewall", "cf.bot_management"], "chunk_index": 32, "content_hash": "757742c4b0c882613f02b6c368f9a3d8"}
{"chunk_id": "Cloudflare_2020_33_4472f02d", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "ul bots. That’s how the Firewall field cf.bot_management.verified_bot came into existence in 2019, allowing customers to decide for themselves whether they want to let all of the good bots through or restrict access to certain parts of the website.The actual platform calculating Verified Bot flag deserves a detailed blog on its own, but in the nutshell it has the following properties:Validator based approach - we support multiple validation mechanisms, each of them allowing us to reliably confirm good bot identity by clustering a set of IPs.Reverse DNS validator - performs a reverse DNS check to determine whether or not a bots IP address matches its alleged hostname.ASN Block validator - similar to rDNS check, but performed on ASN block.", "enriched_content": "The machine learning approach described in this text chunk uses a validator-based approach to detect and manage good bots on a website. The approach involves multiple validation mechanisms, including reverse DNS checks and ASN block validation, to reliably confirm the identity of good bots. This allows customers to decide whether they want to let all of the good bots through or restrict access to certain parts of the website.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "The text chunk describes a machine learning-based approach to detecting and managing good bots on a website, using a validator-based approach with multiple validation mechanisms.", "keywords": ["anomaly_detection", "bot_management", "behavioral_analysis", "traffic_analysis", "reverse_DNS", "ASN_block", "validator_based_approach"], "chunk_index": 33, "content_hash": "4472f02d61442a26602467e71ce18629"}
{"chunk_id": "Cloudflare_2020_34_776d8008", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "to determine whether or not a bots IP address matches its alleged hostname.ASN Block validator - similar to rDNS check, but performed on ASN block.Downloader validator - collects good bot IPs from either text files or HTML pages hosted on bot owner sites.Machine learning validator - uses an unsupervised learning algorithm, clustering good bot IPs which are not possible to validate through other means.Bots Directory - a database with UI that stores and manages bots that pass through the Cloudflare network. Bots directory UI sample‌‌Using multiple validation methods listed above, the Verified Bots detection mechanism identifies hundreds of unique good bot identities, belonging to different companies and categories.", "enriched_content": " The machine learning approach used in this paper involves several techniques to detect and validate good bot traffic: 1. ASN Block validator: This checks if the bot's IP address matches its alleged hostname, similar to a reverse DNS (rDNS) check, but performed on the Autonomous System Number (ASN) block. 2. Downloader validator: This collects good bot IPs from text files or HTML pages hosted on bot owner sites. 3. Machine learning validator: This uses an unsupervised learning algorithm to cluster good bot IPs that cannot be validated through other means. 4. Bots Directory: A database with a user interface that stores and manages bots that pass through the Cloudflare network. By using these multiple validation methods, the Verified Bots detection mechanism can identify hundreds of unique good bot identities, belonging to different companies and categories.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": " The paper describes a multi-pronged approach to detect and validate good bot traffic, including ASN block validation, downloader validation, and an unsupervised machine learning-based clustering technique, as well as a Bots Directory to manage the identified bots.", "keywords": [" anomaly_detection", "bot_detection", "traffic_analysis", "behavioral_analysis", "unsupervised_learning"], "chunk_index": 34, "content_hash": "776d8008f5c963a043079b82025922cf"}
{"chunk_id": "Cloudflare_2020_35_6a3e646f", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "ts detection mechanism identifies hundreds of unique good bot identities, belonging to different companies and categories. JS fingerprinting When it comes to Bot Management detection quality it’s all about the signal quality and quantity. All previously described detections use request attributes sent over the network and analyzed on the server side using different techniques. Are there more signals available, which can be extracted from the client to improve our detections?As a matter of fact there are plenty, as every browser has unique implementation quirks. Every web browser graphics output such as canvas depends on multiple layers such as hardware (GPU) and software (drivers, operating system rendering).", "enriched_content": "The text describes a bot detection mechanism that identifies hundreds of unique good bot identities belonging to different companies and categories. It discusses the importance of signal quality and quantity in bot management detection, and explores the possibility of extracting additional signals from the client side to improve the detections. The mechanism analyzes request attributes sent over the network using various techniques, and it notes that every web browser has unique implementation quirks, including in its graphics output, which can be leveraged for better bot detection.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "The text discusses a machine learning-based bot detection approach that utilizes both server-side and client-side signals to identify unique good bot identities and improve detection quality.", "keywords": ["anomaly_detection", "bot_management", "behavioral_analysis", "traffic_analysis", "client-side_signals", "browser_fingerprinting", "web_graphics"], "chunk_index": 35, "content_hash": "6a3e646f6ee79dbb2cc12c38a28020f1"}
{"chunk_id": "Cloudflare_2020_36_117a1248", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "t such as canvas depends on multiple layers such as hardware (GPU) and software (drivers, operating system rendering). This highly unique output allows precise differentiation between different browser/device types. Moreover, this is achievable without sacrificing website visitor privacy as it’s not a supercookie, and it cannot be used to track and identify individual users, but only to confirm that request’s user agent matches other telemetry gathered through browser canvas API.This detection mechanism is implemented as a challenge-response system with challenge injected into the webpage on Cloudflare’s edge.", "enriched_content": "The ML approach utilizes the unique output of the canvas element, which depends on various hardware and software layers, to differentiate between different browser and device types. This detection mechanism is implemented as a challenge-response system, where the challenge is injected into the webpage on Cloudflare's edge, without compromising website visitor privacy as it is not a supercookie and cannot be used to track individual users.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "The ML approach leverages the unique canvas element output to differentiate between browser and device types, implementing a challenge-response system to detect anomalies without compromising user privacy.", "keywords": ["behavioral_analysis", "traffic_analysis", "bot_detection", "canvas", "challenge-response", "privacy", "browser/device differentiation"], "chunk_index": 36, "content_hash": "117a12486ff74f9cd304f07607ca59d9"}
{"chunk_id": "Cloudflare_2020_37_de6886d9", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "loudflare’s edge. The challenge is then rendered in the background using provided graphic instructions and the result sent back to Cloudflare for validation and further action such as producing the score. There is a lot going on behind the scenes to make sure we get reliable results without sacrificing users’ privacy while being tamper resistant to replay attacks. The system is currently in private beta and being evaluated for its effectiveness and we already see very promising results. Stay tuned for this new detection mechanism becoming widely available and the blog on how we’ve built it.This concludes an overview of the five detection mechanisms we’ve built so far.", "enriched_content": "The Cloudflare team has developed a new detection mechanism that aims to provide reliable anomaly detection while protecting user privacy and preventing tampering. The mechanism involves rendering challenges in the background and validating the results to produce a score. This new approach is currently in private beta and showing promising results, with plans to make it widely available in the future.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "The text describes a new anomaly detection mechanism developed by Cloudflare, which leverages background rendering of challenges and validation to provide reliable results while preserving user privacy and security.", "keywords": ["anomaly_detection", "behavioral_analysis", "traffic_analysis", "bot_detection", "privacy_preservation", "tamper_resistance"], "chunk_index": 37, "content_hash": "de6886d9bfbb90b11903670d79a04809"}
{"chunk_id": "Cloudflare_2020_38_56a6b746", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "s concludes an overview of the five detection mechanisms we’ve built so far. It’s time to sum it all up! Summary Cloudflare has the unique ability to collect data from trillions of requests flowing through its network every week. With this data, Cloudflare is able to identify likely bot activity with Machine Learning, Heuristics, Behavioral Analysis, and other detection mechanisms. Cloudflare Bot Management integrates seamlessly with other Cloudflare products, such as WAF and Workers. All this could not be possible without hard work across multiple teams! First of all thanks to everybody on the Bots Team for their tremendous efforts to make this platform come to life.", "enriched_content": "Cloudflare has built five detection mechanisms to identify bot activity using the vast amount of data flowing through its network. These mechanisms include machine learning, heuristics, and behavioral analysis. The bot detection system is integrated with other Cloudflare products, such as the web application firewall and Workers, to provide a comprehensive solution. The development of this platform involved the hard work of multiple teams at Cloudflare.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "This text covers Cloudflare's approach to bot detection using various techniques, including machine learning, heuristics, and behavioral analysis, and its integration with other Cloudflare products.", "keywords": ["bot detection", "machine learning", "heuristics", "behavioral analysis", "traffic analysis", "web application firewall", "cloud computing"], "chunk_index": 38, "content_hash": "56a6b7469072e2e77dc5548db7f74d80"}
{"chunk_id": "Cloudflare_2020_39_dfd3e89a", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "e Bots Team for their tremendous efforts to make this platform come to life. Other Cloudflare teams, most notably: Firewall, Data, Solutions Engineering, Performance, SRE, helped us a lot to design, build and support this incredible platform. Bots team during Austin team summit 2019 hunting bots with axes :)Lastly, there are more blogs from the Bots series coming soon, diving into internals of our detection mechanisms, so stay tuned for more exciting stories about Cloudflare Bot Management!Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.", "enriched_content": "The Cloudflare Bots Team has developed a robust bot detection platform that utilizes behavioral analysis, traffic analysis, and bot detection techniques to protect corporate networks, accelerate websites and internet applications, and defend against DDoS attacks. This platform was a collaborative effort involving several Cloudflare teams, including Firewall, Data, Solutions Engineering, Performance, and SRE. The team is excited to share more details about the internals of their detection mechanisms in upcoming blog posts.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "This text chunk outlines Cloudflare's bot detection platform, which was developed through a collaborative effort across multiple teams and leverages advanced machine learning techniques to protect customers' networks and applications.", "keywords": ["bot_detection", "behavioral_analysis", "traffic_analysis", "corporate_network_protection", "DDoS_defense", "cloud_platform"], "chunk_index": 39, "content_hash": "dfd3e89a419cc5b9e39865593d52ad19"}
{"chunk_id": "Cloudflare_2020_40_9e846f52", "source_title": "Cloudflare Bot Management: Machine Learning and More", "source_url": "https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/", "company": "Cloudflare", "year": "2020", "original_content": "applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions.Discuss on Hacker NewsDeep DiveBot ManagementBotsSecurityFirewallProduct NewsAISaltMachine Learning", "enriched_content": "Cloudflare's machine learning-based solution efficiently handles website and internet application traffic, providing protection against DDoS attacks and hacking attempts. It can be accessed through their free app, which aims to make the internet faster and safer. The solution utilizes techniques such as behavioral analysis, traffic analysis, and bot detection to achieve its goals. The company is further expanding its mission to build a better internet and has open positions available for those interested in this area.", "ml_techniques": ["behavioral_analysis", "traffic_analysis", "bot_detection"], "chunk_summary": "This text discusses Cloudflare's machine learning-based solution that enhances website and internet application performance, security, and safety, and is accessible through a free app.", "keywords": ["behavioral_analysis", "traffic_analysis", "bot_detection", "DDoS_attacks", "cybersecurity", "internet_performance", "machine_learning", "Zero_Trust"], "chunk_index": 40, "content_hash": "9e846f52561a91a597d72f9fa22d75a6"}
{"chunk_id": "OLX Group_2020_0_4ba10e67", "source_title": "Fighting fraud with Triplet Loss", "source_url": "https://tech.olx.com/fighting-fraud-with-triplet-loss-86e5f79c7a3e", "company": "OLX Group", "year": "2020", "original_content": "Fighting fraud with Triplet LossArtemii FrolovFollow7 min read·Oct 1, 2020--ListenShareImage by Reimund Bertrams from PixabayOne of the common problems of the online advertising industry is fraud. Even though it varies across markets, fraud methods have a lot of similarities worldwide.In this post, we’ll meet:Fraudsters, who change imagesEmbeddings, which help find distances so we can distinguish images from each other fasterSiamese Network with Triplet Loss explained in simple languageTricks and Hacks — so we can train network betterPossible attacksOne of the known methods of fraud is stealing pictures of the goods from the original seller. Fraudsters pass these pictures off for their own, selling the fake goods, or renting out fake apartments.", "enriched_content": " What is the common problem in the online advertising industry that this article addresses? The article discusses the problem of fraud, where fraudsters steal images of goods from original sellers and pass them off as their own to sell fake goods or rent out fake apartments. How does the article propose to address this problem using machine learning? The article introduces the use of triplet loss, a deep learning technique, to create image embeddings that can help distinguish between images and detect fraudulent activities. It also discusses tricks and hacks for training the network better and potential attacks.", "ml_techniques": ["triplet_loss", "deep_learning", "fraud_detection"], "chunk_summary": " This article discusses how the OLX Group uses triplet loss, a deep learning technique, to create image embeddings and detect fraudulent activities in the online advertising industry, where fraudsters steal images and pass them off as their own.", "keywords": [" triplet_loss", "deep_learning", "fraud_detection", "online_advertising", "image_embeddings", "siamese_network", "anomaly_detection"], "chunk_index": 0, "content_hash": "4ba10e67bb07c14c7dad22506326e756"}
{"chunk_id": "OLX Group_2020_1_7d63de28", "source_title": "Fighting fraud with Triplet Loss", "source_url": "https://tech.olx.com/fighting-fraud-with-triplet-loss-86e5f79c7a3e", "company": "OLX Group", "year": "2020", "original_content": "g pictures of the goods from the original seller. Fraudsters pass these pictures off for their own, selling the fake goods, or renting out fake apartments.Often, in order to bypass security systems, they not only copy the ad but also make changes both in the text and attached images. Sometimes the text is rewritten completely and the only way to determine the duplicate is an image.Original image and possible attackOf course, there are systems that help determine such duplicates. But as the number of images increases, it becomes longer and more difficult to compare them directly with each other.So here comes an embedding to help us.What is embedding?An embedding is a relatively low-dimensional space into which you can translate high-dimensional vectors — in our case, images.", "enriched_content": "The text describes a machine learning approach to address the challenge of detecting fraudulent listings that copy images from legitimate listings. The approach involves using image embeddings, which transform high-dimensional image data into a lower-dimensional space, to make it easier to identify duplicate or copied images. This helps bypass security systems that fraudsters use to bypass detection, such as rewriting the text and making changes to the images.", "ml_techniques": ["triplet_loss", "deep_learning", "fraud_detection"], "chunk_summary": "The text outlines a machine learning approach using image embeddings to detect fraudulent listings that copy images from legitimate listings, a common tactic used by fraudsters to bypass security systems.", "keywords": ["anomaly_detection", "image_embedding", "fraud_detection", "deep_learning", "triplet_loss"], "chunk_index": 1, "content_hash": "7d63de28d445c0a4bb1b3f9d909e31ef"}
{"chunk_id": "OLX Group_2020_2_e5e619bd", "source_title": "Fighting fraud with Triplet Loss", "source_url": "https://tech.olx.com/fighting-fraud-with-triplet-loss-86e5f79c7a3e", "company": "OLX Group", "year": "2020", "original_content": ".So here comes an embedding to help us.What is embedding?An embedding is a relatively low-dimensional space into which you can translate high-dimensional vectors — in our case, images.That means that we can transform an image of any size to a not very long vector and then compare not the images themselves but their embeddings, which is much faster. The speed is important here, as we have a large dataset. We can make it more efficient by converting the embeddings to hashes. For example, we can use locality-sensitive hashing for that.Embeddings and distancesSo, how does the process of determining a duplicate looks like?When a new image is uploaded to the database, distances between the embedding of the uploaded image and embeddings of the images, already stored in the database, are calculate", "enriched_content": "What is the purpose of using embeddings in the machine learning approach described in the text? The text explains that embeddings are used to transform high-dimensional vectors, such as images, into a relatively low-dimensional space. This allows for faster comparison of images by comparing their embeddings rather than the images themselves, which is important for the large dataset. The embeddings can be further optimized by converting them to hashes using locality-sensitive hashing. The process of detecting duplicates involves calculating the distances between the embedding of a newly uploaded image and the embeddings of the images already stored in the database.", "ml_techniques": ["triplet_loss", "deep_learning", "fraud_detection"], "chunk_summary": "The text describes the use of embeddings to enable efficient comparison of images for a large dataset, and the process of detecting duplicates by calculating distances between the embeddings.", "keywords": ["embedding", "deep_learning", "fraud_detection", "locality-sensitive_hashing", "image_processing"], "chunk_index": 2, "content_hash": "e5e619bd90a9e353e25bc9b465c8238a"}
{"chunk_id": "OLX Group_2020_3_80761616", "source_title": "Fighting fraud with Triplet Loss", "source_url": "https://tech.olx.com/fighting-fraud-with-triplet-loss-86e5f79c7a3e", "company": "OLX Group", "year": "2020", "original_content": "g a duplicate looks like?When a new image is uploaded to the database, distances between the embedding of the uploaded image and embeddings of the images, already stored in the database, are calculated.If the distance is less than the “Undoubtedly duplicate” threshold, we can immediately mark the listing as a fraud.If this distance is greater than the threshold “Undoubtedly original”, we can pass the image on to the site.If this distance is between these two thresholds, then moderators come to the rescue — they can determine whether the image is a duplicate or not.", "enriched_content": "When a new image is uploaded to the database, how does the system determine if it is a duplicate or not? If the distance between the embedding of the uploaded image and the embeddings of the existing images is less than the \"Undoubtedly duplicate\" threshold, the system can immediately mark the listing as a fraud. If the distance is greater than the \"Undoubtedly original\" threshold, the system can pass the image on to the site. If the distance is between these two thresholds, the moderators can determine whether the image is a duplicate or not.", "ml_techniques": ["triplet_loss", "deep_learning", "fraud_detection"], "chunk_summary": "The text describes an image-based anomaly detection approach that uses distance-based thresholds to automatically identify duplicate images, with a manual review process for ambiguous cases.", "keywords": ["triplet_loss", "deep_learning", "fraud_detection", "image_embeddings", "distance_thresholds", "anomaly_detection"], "chunk_index": 3, "content_hash": "807616167f07b53a76744fb6f1ae4b4d"}
{"chunk_id": "OLX Group_2020_4_ad6f4509", "source_title": "Fighting fraud with Triplet Loss", "source_url": "https://tech.olx.com/fighting-fraud-with-triplet-loss-86e5f79c7a3e", "company": "OLX Group", "year": "2020", "original_content": "rk for Duplicate Detection by Alexey GrigorevThus, there is another requirement for any system to search for duplicates — it must not only correctly mark the duplicate, but also find the most similar image to it.A possible example of a moderator’s UIMeet Siamese Network with Triplet LossNow we need to understand how we can get these embeddings. There are a lot of methods, both machine learning and not, but in this article, we will look at one interesting architecture — a Siamese network with triplet loss. In simple language, it is a network that trains to get embedding so that the distance between similar images is much smaller than the distance between completely different ones.", "enriched_content": "The paper discusses a machine learning approach for detecting duplicate images. The key aspects of this approach are: 1. The system must not only correctly identify duplicates, but also find the most similar image to the duplicate. 2. The authors use a Siamese network with triplet loss to generate image embeddings, where the distance between similar images is much smaller than the distance between different images. 3. This allows the system to effectively search for and identify duplicate images.", "ml_techniques": ["triplet_loss", "deep_learning", "fraud_detection"], "chunk_summary": "The paper presents a Siamese network with triplet loss for generating image embeddings to enable effective duplicate detection, where similar images have smaller distances than different images.", "keywords": ["triplet_loss", "siamese_network", "deep_learning", "image_embeddings", "duplicate_detection"], "chunk_index": 4, "content_hash": "ad6f4509e3e321240fe55c576c347ded"}
{"chunk_id": "OLX Group_2020_5_987243b3", "source_title": "Fighting fraud with Triplet Loss", "source_url": "https://tech.olx.com/fighting-fraud-with-triplet-loss-86e5f79c7a3e", "company": "OLX Group", "year": "2020", "original_content": "ween similar images is much smaller than the distance between completely different ones.After training, positive examples are closer to each other and the negative one is now farThat means that through the same neural network, which we will call the base network, we run the first image, then a similar image (for example, augmentation, as in our case!) and a different image. Let’s check what we do next with the formula below (don’t worry we’ll explain it soon!):L is for loss, A is for the original image, P is for similar image (positive), N is for dissimilar image (negative)Here we find the distance between the original and the similar image (‖A − P‖), and the distance between the original and the dissimilar image (‖A − N‖) so that one distance is much smaller than the other.", "enriched_content": "The neural network is trained using a triplet loss function, where the goal is to make the distance between similar images much smaller than the distance between dissimilar images. This is achieved by running the original image, a similar image (such as an augmented version), and a dissimilar image through the same base network. The triplet loss function is used to minimize the distance between the original and similar image, while maximizing the distance between the original and dissimilar image.", "ml_techniques": ["triplet_loss", "deep_learning", "fraud_detection"], "chunk_summary": "The text describes a machine learning approach that uses a triplet loss function to learn embeddings that separate similar and dissimilar images, for applications such as fraud detection.", "keywords": ["triplet_loss", "deep_learning", "embedding", "siamese_network", "fraud_detection"], "chunk_index": 5, "content_hash": "987243b349a81031eed2ddd930859114"}
{"chunk_id": "OLX Group_2020_6_fa35c6f8", "source_title": "Fighting fraud with Triplet Loss", "source_url": "https://tech.olx.com/fighting-fraud-with-triplet-loss-86e5f79c7a3e", "company": "OLX Group", "year": "2020", "original_content": "tance between the original and the similar image (‖A − P‖), and the distance between the original and the dissimilar image (‖A − N‖) so that one distance is much smaller than the other.What is alpha?Now let’s try to go one level deeper — where does the alpha come from and why is it needed? It’s simple: since the task of backpropagation is to minimize the loss, the most effective way to train this neural network with loss without alpha would be to zero all weights. Then the distances would be equal to 0 and the distance between the distances — also 0! The neural network is happy with zero loss, but we, on the contrary, are not happy, because no matter what we do run through, the output is always zeros.", "enriched_content": "The alpha parameter is used in the triplet loss function to ensure that the network learns to distinguish between similar and dissimilar images. It represents the desired margin between the distance of the original image to the positive (similar) image and the distance to the negative (dissimilar) image. The goal is to have the distance to the positive image much smaller than the distance to the negative image, with the difference being at least the value of alpha. Without the alpha parameter, the network could simply minimize the loss by setting all weights to zero, resulting in equal distances and a loss of 0, which would not achieve the desired objective.", "ml_techniques": ["triplet_loss", "deep_learning", "fraud_detection"], "chunk_summary": "This text discusses the role of the alpha parameter in the triplet loss function used for training a deep learning model for anomaly detection, specifically to ensure the model learns to distinguish between similar and dissimilar inputs.", "keywords": ["triplet_loss", "deep_learning", "anomaly_detection", "margin", "backpropagation"], "chunk_index": 6, "content_hash": "fa35c6f85f7946579b24a0519ad0567c"}
{"chunk_id": "OLX Group_2020_7_832aaca0", "source_title": "Fighting fraud with Triplet Loss", "source_url": "https://tech.olx.com/fighting-fraud-with-triplet-loss-86e5f79c7a3e", "company": "OLX Group", "year": "2020", "original_content": "but we, on the contrary, are not happy, because no matter what we do run through, the output is always zeros.So that this situation does not happen, there is an alpha — the margin between the positive (original minus similar) and negative (original minus different) distance. This margin will make zeroing not the most effective step, and the neural network will have to train a more effective way of making loss closer to zero.Triplet generationPreviously we defined the original image, the positive example, and the negative example. Together, they form a triplet that is used for training. One of the interesting features of a neural network with triplet loss, in our case, that we don’t need a large dataset.", "enriched_content": "The machine learning approach described in this text chunk aims to address the issue of the output always being zeros, which is an undesirable situation. To address this, the authors introduce a concept called \"alpha\" - a margin between the positive (original minus similar) and negative (original minus different) distance. This margin helps ensure that zeroing is not the most effective step, forcing the neural network to learn a more effective way of minimizing the loss. The approach also involves the use of triplet generation, where the original image, a positive example, and a negative example form a triplet that is used for training. Interestingly, the authors note that a neural network with triplet loss does not require a large dataset.", "ml_techniques": ["triplet_loss", "deep_learning", "fraud_detection"], "chunk_summary": "The text chunk describes a machine learning approach that uses triplet loss and a margin-based technique to address the issue of the output always being zeros, while also highlighting the advantage of not needing a large dataset.", "keywords": ["triplet_loss", "deep_learning", "fraud_detection", "anomaly_detection", "margin", "neural_network", "dataset"], "chunk_index": 7, "content_hash": "832aaca0fa4320008999e4dc0cf24dd0"}
{"chunk_id": "OLX Group_2020_8_8fb6a80a", "source_title": "Fighting fraud with Triplet Loss", "source_url": "https://tech.olx.com/fighting-fraud-with-triplet-loss-86e5f79c7a3e", "company": "OLX Group", "year": "2020", "original_content": "the interesting features of a neural network with triplet loss, in our case, that we don’t need a large dataset.Indeed, having one image, with the help of augmentations it is possible to generate several positive examples and select several negative examples. These examples can be any different images, but there are also some techniques on how to choose a proper negative example, which will be discussed later. It turns out that one image transforms into several (or even many!) triplets, and many triplets mean a better-trained network.An example of 9 augmentations made from one imageEasy, semi-hard, and hard tripletsAnother important detail of neural networks with triplet loss is a selection of negative examples.", "enriched_content": "The neural network with triplet loss used in this approach does not require a large dataset. Instead, a single image can be used to generate multiple positive examples through data augmentation, and negative examples can be selected using various techniques. The number of triplets generated from a single image is an important factor in training the network effectively.", "ml_techniques": ["triplet_loss", "deep_learning", "fraud_detection"], "chunk_summary": "This chunk describes a neural network that uses triplet loss and requires only a small dataset, generating multiple positive and negative examples from a single image to train the model effectively.", "keywords": ["neural_network", "triplet_loss", "data_augmentation", "negative_examples", "small_dataset"], "chunk_index": 8, "content_hash": "8fb6a80a274207255987a11c9ae3c980"}
{"chunk_id": "OLX Group_2020_9_8f1bd82d", "source_title": "Fighting fraud with Triplet Loss", "source_url": "https://tech.olx.com/fighting-fraud-with-triplet-loss-86e5f79c7a3e", "company": "OLX Group", "year": "2020", "original_content": "-hard, and hard tripletsAnother important detail of neural networks with triplet loss is a selection of negative examples. As practice shows, even without special techniques the network trains successfully, but with extra work, it does it both faster and more effectively. The selection is as follows — we enter the following groups of triplets:easy triplets: ‖A − P‖ + α < ‖A −N‖semi-hard triplets: ‖A − P‖ < ‖A − N‖ < ‖A − P‖ + αhard triplets: ‖A − N‖ < ‖A−P‖As usual, A is for the original image, P is for a similar image (positive), N is for dissimilar image (negative).Example of semi-hard (left) and hard (right) negatives.", "enriched_content": "The paper discusses an important detail of neural networks with triplet loss, which is the selection of negative examples. The authors explain that even without special techniques, the network can train successfully, but with extra work, it can train both faster and more effectively. They describe three types of triplets: easy triplets, where the distance between the anchor and the positive is less than the distance between the anchor and the negative plus a margin; semi-hard triplets, where the distance between the anchor and the positive is less than the distance between the anchor and the negative, but less than the distance between the anchor and the positive plus a margin; and hard triplets, where the distance between the anchor and the negative is less than the distance between the anchor and the positive. The authors provide examples of semi-hard and hard negatives.", "ml_techniques": ["triplet_loss", "deep_learning", "fraud_detection"], "chunk_summary": "The paper discusses the importance of selecting negative examples in neural networks with triplet loss, and describes three types of triplets that can be used to train the network more effectively.", "keywords": ["triplet_loss", "deep_learning", "neural_networks", "anomaly_detection", "negative_examples"], "chunk_index": 9, "content_hash": "8f1bd82d95448f96830aeb32eb377b0f"}
{"chunk_id": "OLX Group_2020_10_87fbe99e", "source_title": "Fighting fraud with Triplet Loss", "source_url": "https://tech.olx.com/fighting-fraud-with-triplet-loss-86e5f79c7a3e", "company": "OLX Group", "year": "2020", "original_content": ") and hard (right) negatives. Pay attention: a semi-hard example is not just a flipped version it is a completely different image!Of course, it’s most beneficial to train the network on hard examples (because network works the worst with them), with mixing semi-hard and easy so that the network does not forget its correct state — and one of the easiest ways to do this is the next:1. Evaluate several random batches2. Choose a few triplets with the highest loss3. Mix random triplets with these ones and get, thus, a batch for trainingAnother great example of semi-hard negativesLast, but not least — Transfer LearningThe last tool in training will be using a network with pre-trained weights as a basic network.", "enriched_content": "The paper discusses an approach to train a machine learning model for anomaly detection using triplet loss, deep learning, and transfer learning techniques. The key aspects are: 1. The model is trained on hard and semi-hard negative examples, as these are the most challenging for the network to learn. A semi-hard negative example is a completely different image, not just a flipped version. 2. To select the most challenging examples for training, the approach evaluates several random batches, chooses a few triplets with the highest loss, and mixes these with random triplets to create the training batch. 3. The model utilizes transfer learning, where the network is initialized with pre-trained weights as a starting point.", "ml_techniques": ["triplet_loss", "deep_learning", "fraud_detection"], "chunk_summary": "The paper presents a deep learning-based anomaly detection approach that leverages triplet loss, semi-hard negative examples, and transfer learning to improve model performance.", "keywords": ["triplet_loss", "deep_learning", "fraud_detection", "anomaly_detection", "transfer_learning"], "chunk_index": 10, "content_hash": "87fbe99e2fe8faa5c19aa38df9d534bc"}
{"chunk_id": "OLX Group_2020_11_049f8ae2", "source_title": "Fighting fraud with Triplet Loss", "source_url": "https://tech.olx.com/fighting-fraud-with-triplet-loss-86e5f79c7a3e", "company": "OLX Group", "year": "2020", "original_content": "— Transfer LearningThe last tool in training will be using a network with pre-trained weights as a basic network. They can be either fully trained or frozen with only the tail of the network trained, but the result of such a transfer learning will only improve the network as a whole.Using the networkThe network is trained, all that remains is to get embedding. To do this, one just needs to run the image through the base network (without using any triplets!), and the output will be the final vector. As it was written before, now it is possible to do anything with it — immediately use it as an image mapping, or convert it to a hash — it depends only on the task.", "enriched_content": "The paper discusses the use of transfer learning to improve the performance of the machine learning model. The pre-trained weights of the network can be used as a starting point, either by training the entire network or by freezing the base network and only training the tail of the network. This transfer learning approach can enhance the overall performance of the model. Once the network is trained, the image can be passed through the base network to obtain the final vector, which can then be used for various tasks such as image mapping or hashing, depending on the specific requirements of the application.", "ml_techniques": ["triplet_loss", "deep_learning", "fraud_detection"], "chunk_summary": "The paper explores the use of transfer learning to enhance the performance of a machine learning model, including the ability to use pre-trained weights and obtain final vector embeddings for various tasks.", "keywords": ["transfer_learning", "pre-trained_weights", "fine-tuning", "embedding", "image_mapping", "fraud_detection"], "chunk_index": 11, "content_hash": "049f8ae2f01be7d016cdaeda01fe5747"}
{"chunk_id": "OLX Group_2020_12_bd9f4525", "source_title": "Fighting fraud with Triplet Loss", "source_url": "https://tech.olx.com/fighting-fraud-with-triplet-loss-86e5f79c7a3e", "company": "OLX Group", "year": "2020", "original_content": "image mapping, or convert it to a hash — it depends only on the task. The main thing is that this technology can help to quickly and effectively identify the fraudsters trying to change the image in the ad.ConclusionToday we learned:Fraudsters can cheat by stealing and changing the image of other users to create a fake listing;We need a fast way to find similar images, so we can find distances between corresponding embeddings;We can compute embeddings using Siamese Network with Triplet Loss;We can generate many positive and select the best negative example to generate triplets;This way, we can quickly and effectively identify the fraudsters trying to use someone else’s image in their ad.", "enriched_content": " The ML approach discussed in this text chunk helps quickly and effectively identify fraudsters who try to change the image in an ad to create a fake listing. It does this by: - Converting the image to a hash or embedding it using a Siamese Network with Triplet Loss - Comparing the image embedding to a database of known images to find similar ones - Using the distance between the embeddings to detect when someone is trying to use an image that doesn't belong to them", "ml_techniques": ["triplet_loss", "deep_learning", "fraud_detection"], "chunk_summary": " The text describes an ML-based approach to detect image-based fraud in online ads by computing image embeddings and using Triplet Loss to identify similar images and catch fraudsters.", "keywords": [" image_mapping", "deep_learning", "triplet_loss", "fraud_detection", "siamese_network"], "chunk_index": 12, "content_hash": "bd9f4525af5c2b91b5c8fac1bf0373a5"}
{"chunk_id": "Grab_2022_0_c347843d", "source_title": "Graph for Fraud Detection", "source_url": "https://engineering.grab.com/graph-for-fraud-detection", "company": "Grab", "year": "2022", "original_content": "In earlier articles of this series, we’ve covered the importance of graph networks, graph concepts and how graph visualisation makes fraud investigations easier and more effective. In this article, we will explore how we use graph-based models to tackle fraud detection as fraud patterns increase and diversify. Grab has grown rapidly in the past few years. It has expanded its business from ride hailing to food and grocery delivery, financial services, and more. Fraud detection is challenging in Grab, because new fraud patterns always arise whenever we introduce a new business product. We cannot afford to develop a new model whenever a new fraud pattern appears as it is time consuming and introduces a cold start problem, that is no protection at the early stage.", "enriched_content": "In this article, we will explore how Grab uses graph-based models to tackle the challenge of fraud detection. As Grab has rapidly expanded its business, new fraud patterns have emerged with the introduction of new products. The challenge is to address these new fraud patterns without having to develop a new model each time, which can be time-consuming and leaves the business vulnerable in the early stages. The article builds on previous discussions about the importance of graph networks, graph concepts, and how graph visualization can make fraud investigations more effective.", "ml_techniques": ["graph_ml", "fraud_detection", "network_analysis"], "chunk_summary": "This article explores Grab's use of graph-based models to tackle the challenge of evolving fraud patterns as the company expands its business offerings, while addressing the limitations of developing new models for each new fraud pattern.", "keywords": ["graph_ml", "fraud_detection", "network_analysis", "graph_visualization", "business_expansion", "cold_start_problem"], "chunk_index": 0, "content_hash": "c347843dbfb218824a72bdc4536008dc"}
{"chunk_id": "Grab_2022_1_10be0202", "source_title": "Graph for Fraud Detection", "source_url": "https://engineering.grab.com/graph-for-fraud-detection", "company": "Grab", "year": "2022", "original_content": "afford to develop a new model whenever a new fraud pattern appears as it is time consuming and introduces a cold start problem, that is no protection at the early stage. We need a general fraud detection framework to better protect Grab from various unknown fraud risks. Our key observation is that although Grab has many different business verticals, the entities within those businesses are connected to each other (Figure 1. Left), for example, two passengers may be connected by a Wi-Fi router or phone device, a merchant may be connected to a passenger by a food order, and so on. A graph provides an elegant way to capture the spatial correlation among different entities in the Grab ecosystem.", "enriched_content": "The paper discusses a general fraud detection framework that leverages the connections between entities in the Grab ecosystem, represented as a graph. This approach allows for the detection of various unknown fraud risks without the need to develop a new model for each new fraud pattern, which can be time-consuming and introduces a cold start problem. The key idea is that entities within different Grab business verticals are connected to each other, and a graph-based representation can capture these spatial correlations to enhance fraud detection.", "ml_techniques": ["graph_ml", "fraud_detection", "network_analysis"], "chunk_summary": "The paper presents a graph-based fraud detection framework that can adapt to various unknown fraud risks, avoiding the need to develop new models for each new pattern.", "keywords": ["graph_ml", "fraud_detection", "network_analysis", "spatial_correlation", "entity_connections", "cold_start_problem"], "chunk_index": 1, "content_hash": "10be0202072e342ee0ec3c6780d62ed4"}
{"chunk_id": "Grab_2022_2_375d3388", "source_title": "Graph for Fraud Detection", "source_url": "https://engineering.grab.com/graph-for-fraud-detection", "company": "Grab", "year": "2022", "original_content": "des an elegant way to capture the spatial correlation among different entities in the Grab ecosystem. A common fraud shows clear patterns on a graph, for example, a fraud syndicate tends to share physical devices, and collusion happens between a merchant and an isolated set of passengers (Figure 1. Right). Figure 1. Left: The graph captures different correlations in the Grab ecosystem. Right: The graph shows that common fraud has clear patterns. We believe graphs can help us discover subtle traces and complicated fraud patterns more effectively. Graph-based solutions will be a sustainable foundation for us to fight against known and unknown fraud risks.", "enriched_content": "The paper presents a graph-based approach to capture the spatial correlation among different entities in the Grab ecosystem. This method can effectively identify common fraud patterns, such as fraud syndicates sharing physical devices or collusion between merchants and isolated passengers. The authors believe that graph-based solutions provide a sustainable foundation to fight against known and unknown fraud risks.", "ml_techniques": ["graph_ml", "fraud_detection", "network_analysis"], "chunk_summary": "The paper describes a graph-based anomaly detection approach that can effectively capture spatial correlations and uncover complex fraud patterns in the Grab ecosystem.", "keywords": ["graph_ml", "fraud_detection", "network_analysis", "spatial_correlation", "anomaly_detection"], "chunk_index": 2, "content_hash": "375d338811ca666e7d486e989714ce70"}
{"chunk_id": "Grab_2022_3_4e2b7d40", "source_title": "Graph for Fraud Detection", "source_url": "https://engineering.grab.com/graph-for-fraud-detection", "company": "Grab", "year": "2022", "original_content": "dation for us to fight against known and unknown fraud risks. Why graph? The most common fraud detection methods include the rule engine and the decision tree-based models, for example, boosted tree, random forest, and so on. Rules are a set of simple logical expressions designed by human experts to target a particular fraud problem. They are good for simple fraud detection, but they usually do not work well in complicated fraud or unknown fraud cases. Fraud detection methods Utilises correlations (Higher is better) Detects unknown fraud (Higher is better) Requires feature engineering (Lower is better) Depends on labels (Lower is better) Rule engine Low N/A N/A Low Decision tree Low Low High High Graph model High High Low Low Table 1. Graph vs. common fraud detection methods.", "enriched_content": "The graph-based machine learning approach presented in this text chunk is a powerful tool for fighting against known and unknown fraud risks. It outperforms traditional fraud detection methods like rule engines and decision tree-based models in several key areas. The graph model can better utilize correlations in the data, detect unknown fraud cases, and requires less feature engineering and label dependency compared to the other methods. This approach offers a more comprehensive and effective solution for fraud detection.", "ml_techniques": ["graph_ml", "fraud_detection", "network_analysis"], "chunk_summary": "This text chunk introduces a graph-based machine learning approach for fraud detection, highlighting its advantages over traditional methods like rule engines and decision tree-based models.", "keywords": ["graph_ml", "fraud_detection", "network_analysis", "anomaly_detection", "feature_engineering", "correlation_analysis", "unknown_fraud"], "chunk_index": 3, "content_hash": "4e2b7d4086fe50832446d3205b99d2e0"}
{"chunk_id": "Grab_2022_4_e8a9be00", "source_title": "Graph for Fraud Detection", "source_url": "https://engineering.grab.com/graph-for-fraud-detection", "company": "Grab", "year": "2022", "original_content": "s better) Depends on labels (Lower is better) Rule engine Low N/A N/A Low Decision tree Low Low High High Graph model High High Low Low Table 1. Graph vs. common fraud detection methods. Decision tree-based models have been dominating fraud detection and Kaggle competitions for structured or tabular data in the past few years. With that said, the performance of a tree-based model is highly dependent on the quality of labels and feature engineering, which is often hard to obtain in real life. In addition, it usually does not work well in unknown fraud which has not been seen in the labels.", "enriched_content": "The text compares the performance of different machine learning techniques for fraud detection, including decision trees, rule engines, and graph models. Decision trees are widely used but depend heavily on the quality of labels and feature engineering, and may not perform well on unknown fraud cases. Graph models, on the other hand, have high performance on both interpretability and robustness to unknown fraud, but may require more data and computational resources.", "ml_techniques": ["graph_ml", "fraud_detection", "network_analysis"], "chunk_summary": "The text compares the strengths and weaknesses of different machine learning techniques for fraud detection, highlighting the advantages of graph-based models for handling unknown fraud cases.", "keywords": ["fraud detection", "graph ML", "decision tree", "rule engine", "network analysis", "interpretability", "robustness"], "chunk_index": 4, "content_hash": "e8a9be00251aa4b4ca2308ce8bf9ffa6"}
{"chunk_id": "Grab_2022_5_eda065ff", "source_title": "Graph for Fraud Detection", "source_url": "https://engineering.grab.com/graph-for-fraud-detection", "company": "Grab", "year": "2022", "original_content": "he other hand, a graph-based model requires little amount of feature engineering and it is applicable to unknown fraud detection with less dependence on labels, because it utilises the structural correlations on the graph. In particular, fraudsters tend to show strong correlations on a graph, because they have to share physical properties such as personal identities, phone devices, Wi-Fi routers, delivery addresses, and so on, to reduce cost and maximise revenue as shown in Figure 2 (left). An example of such strong correlations is shown in Figure 2 (right), where the entities on the graph are densely connected, and the known fraudsters are highlighted in red.", "enriched_content": "The graph-based model used in this approach requires minimal feature engineering and is applicable to detecting unknown fraud with less dependence on labels. This is because the model utilizes the structural correlations on the graph, as fraudsters tend to share physical properties like personal identities, devices, and addresses to reduce costs and maximize revenue. The graph shows strong correlations between entities, with known fraudsters highlighted in red.", "ml_techniques": ["graph_ml", "fraud_detection", "network_analysis"], "chunk_summary": "This approach uses a graph-based model for fraud detection that requires little feature engineering and can detect unknown fraud with less dependence on labeled data, leveraging the structural correlations in the graph.", "keywords": ["graph_ml", "fraud_detection", "network_analysis", "structural_correlations", "feature_engineering", "unknown_fraud"], "chunk_index": 5, "content_hash": "eda065ffd331e217e3b6790dc5d023d5"}
{"chunk_id": "Grab_2022_6_1d785849", "source_title": "Graph for Fraud Detection", "source_url": "https://engineering.grab.com/graph-for-fraud-detection", "company": "Grab", "year": "2022", "original_content": "densely connected, and the known fraudsters are highlighted in red. Those strong correlations on the graph are the key reasons that make the graph based approach a sustainable foundation for various fraud detection tasks. Figure 2. Fraudsters tend to share physical properties to reduce cost (left), and they are densely connected as shown on a graph (right). Semi-supervised graph learning Unlike traditional decision tree-based models, the graph-based machine learning model can utilise the graph’s correlations and achieve great performance even with few labels. The semi-supervised Graph Convolutional Network model has been extremely popular in recent years 1.", "enriched_content": "The graph-based machine learning approach is effective for fraud detection tasks because fraudsters tend to be densely connected, sharing physical properties to reduce costs. The semi-supervised Graph Convolutional Network model can leverage the graph's correlations to achieve strong performance even with limited labeled data.", "ml_techniques": ["graph_ml", "fraud_detection", "network_analysis"], "chunk_summary": "This text chunk discusses how graph-based machine learning models, particularly the semi-supervised Graph Convolutional Network, can be effectively used for fraud detection tasks by leveraging the dense connections and shared attributes of fraudsters.", "keywords": ["graph_ml", "fraud_detection", "network_analysis", "semi-supervised_learning", "graph_convolutional_network"], "chunk_index": 6, "content_hash": "1d785849b86e74d97de917ad1cb88644"}
{"chunk_id": "Grab_2022_7_ea25719e", "source_title": "Graph for Fraud Detection", "source_url": "https://engineering.grab.com/graph-for-fraud-detection", "company": "Grab", "year": "2022", "original_content": "tional Network model has been extremely popular in recent years 1. It has proven its success in many fraud detection tasks across industries, for example, e-commerce fraud, financial fraud, internet traffic fraud, etc. We apply the Relational Graph Convolutional Network (RGCN) 2 for fraud detection in Grab’s ecosystem. Figure 3 shows the overall architecture of RGCN. It takes a graph as input, and the graph passes through several graph convolutional layers to get node embeddings. The final layer outputs a fraud probability for each node. At each graph convolutional layer, the information is propagated along the neighbourhood nodes within the graph, that is nodes that are close on the graph are similar to each other. Fig 3. A semi-supervised Relational Graph Convolutional Network model.", "enriched_content": "The Relational Graph Convolutional Network (RGCN) model has been widely used for fraud detection across various industries, including e-commerce, finance, and internet traffic. In Grab's ecosystem, the RGCN model is applied to detect fraud. The model takes a graph as input, and the graph passes through multiple graph convolutional layers to generate node embeddings. The final layer outputs a fraud probability for each node. The information is propagated along the neighboring nodes within the graph, so that nodes that are close on the graph are similar to each other.", "ml_techniques": ["graph_ml", "fraud_detection", "network_analysis"], "chunk_summary": "This text chunk describes the application of the Relational Graph Convolutional Network (RGCN) model for fraud detection in Grab's ecosystem, highlighting its architecture and how it leverages graph-based information propagation.", "keywords": ["graph_ml", "fraud_detection", "network_analysis", "semi-supervised_learning", "node_embeddings", "graph_convolutional_network", "relational_graph_convolutional_network"], "chunk_index": 7, "content_hash": "ea25719e0a07bb15bd2b2eec649731d0"}
{"chunk_id": "Grab_2022_8_9137ad50", "source_title": "Graph for Fraud Detection", "source_url": "https://engineering.grab.com/graph-for-fraud-detection", "company": "Grab", "year": "2022", "original_content": "opagated along the neighbourhood nodes within the graph, that is nodes that are close on the graph are similar to each other. Fig 3. A semi-supervised Relational Graph Convolutional Network model. We train the RGCN model on a graph with millions of nodes and edges, where only a few percentages of the nodes on the graph have labels. The semi-supervised graph model has little dependency on the labels, which makes it a robust model for tackling various types of unknown fraud. Figure 4 shows the overall performance of the RGCN model. On the left is the Receiver Operating Characteristic (ROC) curve on the label dataset, in particular, the Area Under the Receiver Operating Characteristic (AUROC) value is close to 1, which means the RGCN model can fit the label data quite well.", "enriched_content": " The Grab team used a semi-supervised Relational Graph Convolutional Network (RGCN) model to tackle fraud detection. The RGCN model was trained on a large graph with millions of nodes and edges, where only a small percentage of the nodes had labels. The model was able to leverage the graph structure and the relationships between nodes to make predictions, even for the nodes without labels. The RGCN model achieved excellent performance, with an AUROC value close to 1 on the labeled dataset, indicating that it can fit the labeled data very well.", "ml_techniques": ["graph_ml", "fraud_detection", "network_analysis"], "chunk_summary": " The text discusses a semi-supervised RGCN model used by Grab for fraud detection, which leverages graph structure and relationships to make robust predictions even with limited labeled data.", "keywords": [" graph_ml", "semi-supervised_learning", "fraud_detection", "network_analysis", "RGCN"], "chunk_index": 8, "content_hash": "9137ad5050003be69b8c99569905cc36"}
{"chunk_id": "Grab_2022_9_dfc97a6a", "source_title": "Graph for Fraud Detection", "source_url": "https://engineering.grab.com/graph-for-fraud-detection", "company": "Grab", "year": "2022", "original_content": "on the label dataset, in particular, the Area Under the Receiver Operating Characteristic (AUROC) value is close to 1, which means the RGCN model can fit the label data quite well. The right column shows the low dimensional projections of the node embeddings on the label dataset. It is clear that the embeddings of the genuine passenger are well separated from the embeddings of the fraud passenger. The model can distinguish between a fraud and a genuine passenger quite well. Fig 4. Left: ROC curve of the RGCN model on the label dataset. Right: Low dimensional projections of the graph node embeddings. Finally, we would like to share a few tips that will make the RGCN model work well in practice.", "enriched_content": "The RGCN model is highly effective at distinguishing between genuine and fraudulent passengers in the labeled dataset. The AUROC value is close to 1, indicating the model can fit the labeled data very well. The low-dimensional projections of the node embeddings show a clear separation between the embeddings of genuine and fraudulent passengers, demonstrating the model's ability to differentiate between them. The paper also provides practical tips to ensure the RGCN model works well in real-world applications.", "ml_techniques": ["graph_ml", "fraud_detection", "network_analysis"], "chunk_summary": "The text discusses the performance of an RGCN model on a labeled dataset for fraud detection, showing its ability to accurately distinguish between genuine and fraudulent passengers.", "keywords": ["graph_ml", "fraud_detection", "network_analysis", "node_embeddings", "AUROC", "RGCN"], "chunk_index": 9, "content_hash": "dfc97a6a727d401e769755ec97648bb0"}
{"chunk_id": "Grab_2022_10_731ae50e", "source_title": "Graph for Fraud Detection", "source_url": "https://engineering.grab.com/graph-for-fraud-detection", "company": "Grab", "year": "2022", "original_content": "ddings. Finally, we would like to share a few tips that will make the RGCN model work well in practice. Use less than three convolutional layers: The node feature will be over-smoothed if there are many convolutional layers, that is all the nodes on the graph look similar. Node features are important: Domain knowledge of the node can be formulated as node features for the graph model, and rich node features are likely to boost the model performance. Graph explainability Unlike other deep network models, graph neural network models usually come with great explainability, that is why a user is classified as fraudulent.", "enriched_content": "The RGCN model can be used effectively for anomaly detection tasks by following a few key guidelines. Firstly, it is recommended to use less than three convolutional layers to avoid over-smoothing of node features, where all nodes start to look similar. Secondly, incorporating domain-specific node features can significantly boost the model's performance, as the model can leverage this prior knowledge. Additionally, graph neural network models like RGCN are inherently more explainable, allowing users to understand why a particular entity is classified as fraudulent.", "ml_techniques": ["graph_ml", "fraud_detection", "network_analysis"], "chunk_summary": "This text chunk discusses best practices for using the RGCN model effectively for anomaly detection, including guidelines on the number of convolutional layers, the importance of node features, and the inherent explainability of graph neural network models.", "keywords": ["graph_ml", "fraud_detection", "network_analysis", "node_features", "explainability", "RGCN", "convolutional_layers"], "chunk_index": 10, "content_hash": "731ae50ee70ae034aae4b257945f6631"}
{"chunk_id": "Grab_2022_11_c8069417", "source_title": "Graph for Fraud Detection", "source_url": "https://engineering.grab.com/graph-for-fraud-detection", "company": "Grab", "year": "2022", "original_content": "lassified as fraudulent. For example, fraudulent accounts are likely to share hardware devices and form dense clusters on the graph, and those fraud clusters can be easily spotted on a graph visualiser 3. Figure 5 shows an example where graph visualisation helps to explain the model prediction scores. The genuine passenger with a low RGCN score does not share devices with other passengers, while the fraudulent passenger with a high RGCN score shares devices with many other passengers, that is, dense clusters. Figure 5. Upper left: A genuine passenger with a low RGCN score has no device sharing with other passengers. Bottom right: A fraudulent user with a high RGCN score shares devices with many other passengers.", "enriched_content": "The graph-based machine learning model used in this approach is able to identify fraudulent accounts by detecting dense clusters of accounts that share hardware devices. The model's prediction scores are explained through graph visualizations, where genuine accounts with low scores do not share devices, while fraudulent accounts with high scores form dense clusters by sharing devices with many other accounts.", "ml_techniques": ["graph_ml", "fraud_detection", "network_analysis"], "chunk_summary": "This approach uses a graph-based machine learning model to detect fraudulent accounts by identifying dense clusters of accounts that share hardware devices, as explained through graph visualizations.", "keywords": ["graph_ml", "fraud_detection", "network_analysis", "device_sharing", "cluster_analysis", "RGCN", "graph_visualization"], "chunk_index": 11, "content_hash": "c80694173644f2d064fcb8c0818edb6a"}
{"chunk_id": "Grab_2022_12_b02effb3", "source_title": "Graph for Fraud Detection", "source_url": "https://engineering.grab.com/graph-for-fraud-detection", "company": "Grab", "year": "2022", "original_content": "with other passengers. Bottom right: A fraudulent user with a high RGCN score shares devices with many other passengers. Closing thoughts Graphs provide a sustainable foundation for combating many different types of fraud risks. Fraudsters are evolving very fast these days, and the best traditional rules or models can do is to chase after those fraudsters given that a fraud pattern has already been discovered. This is suboptimal as the damage has already been done on the platform. With the help of graph models, we can potentially detect those fraudsters before any fraudulent activity has been conducted, thus reducing the fraud cost.", "enriched_content": "The text describes how graph-based machine learning models can be used for proactive fraud detection. The model can identify fraudulent users who share devices with many other passengers, indicating suspicious activity before any actual fraud has occurred. This allows the platform to take preventive action and reduce the overall fraud cost, as opposed to traditional approaches that can only react after the damage has been done.", "ml_techniques": ["graph_ml", "fraud_detection", "network_analysis"], "chunk_summary": "The text discusses how graph-based machine learning models can be used for proactive fraud detection, enabling platforms to identify suspicious activity and take preventive action before any actual fraud has occurred.", "keywords": ["graph_ml", "fraud_detection", "network_analysis", "graph_models", "proactive_detection", "device_sharing", "anomaly_detection"], "chunk_index": 12, "content_hash": "b02effb377a8500a6205acba7fd7c231"}
{"chunk_id": "Grab_2022_13_416780e7", "source_title": "Graph for Fraud Detection", "source_url": "https://engineering.grab.com/graph-for-fraud-detection", "company": "Grab", "year": "2022", "original_content": "conducted, thus reducing the fraud cost. The graph structural information can significantly boost the model performance without much dependence on labels, which is often hard to get and might have a large bias in fraud detection tasks. We have shown that with only a small percentage of labelled nodes on the graph, our model can already achieve great performance. With that said, there are also many challenges to making a graph model work well in practice. We are working towards solving the following challenges we are facing. Feature initialisation: Sometimes, it is hard to initialise the node feature, for example, a device node does not carry many semantic meanings.", "enriched_content": "The proposed ML approach leverages graph structural information to boost the model performance in fraud detection tasks, even with limited labeled data. The key challenges include initializing node features, especially for nodes with limited semantic information.", "ml_techniques": ["graph_ml", "fraud_detection", "network_analysis"], "chunk_summary": "The text covers a graph-based ML approach for fraud detection that can perform well with limited labeled data, while also discussing the challenges of feature initialization, particularly for nodes with minimal semantic information.", "keywords": ["graph_ml", "fraud_detection", "network_analysis", "node_features", "label_scarcity", "unsupervised_learning"], "chunk_index": 13, "content_hash": "416780e7e9b1b0d2f37efa5ff51234d6"}
{"chunk_id": "Grab_2022_14_2c9b2f1e", "source_title": "Graph for Fraud Detection", "source_url": "https://engineering.grab.com/graph-for-fraud-detection", "company": "Grab", "year": "2022", "original_content": "feature, for example, a device node does not carry many semantic meanings. We have explored self-supervised pre-training 4 to help the feature initialisation, and the preliminary results are promising. Real-time model prediction: Realtime graph model prediction is challenging because real-time graph updating is a heavy operation in most cases. One possible solution is to do batch real-time prediction to reduce the overhead. Noisy connections: Some connections on the graph are inherently noisy on the graph, for example, two users sharing the same IP address does not necessarily mean they are physically connected. The IP might come from a mobile network.", "enriched_content": "The text discusses challenges in using graph-based machine learning models for real-time anomaly detection in fraud detection applications. It mentions that basic features like device nodes may not carry much semantic meaning, and explores using self-supervised pre-training to improve feature initialization. The paper also addresses the challenge of real-time graph model prediction, which can be computationally expensive, and the issue of noisy connections in the graph data that may not accurately reflect physical relationships.", "ml_techniques": ["graph_ml", "fraud_detection", "network_analysis"], "chunk_summary": "The text covers challenges in applying graph-based machine learning models for real-time fraud detection, including feature engineering, real-time model prediction, and dealing with noisy data connections.", "keywords": ["graph_ml", "fraud_detection", "network_analysis", "self-supervised_learning", "real-time_prediction"], "chunk_index": 14, "content_hash": "2c9b2f1eab4ba1b2dc6622f4f17ea46e"}
{"chunk_id": "Grab_2022_15_aec33fcb", "source_title": "Graph for Fraud Detection", "source_url": "https://engineering.grab.com/graph-for-fraud-detection", "company": "Grab", "year": "2022", "original_content": "ysically connected. The IP might come from a mobile network. One possible solution is to use the attention mechanism in the graph convolutional kernel and control the message passing based on the type of connection and node profiles. Speak to us GrabDefence is a proprietary fraud prevention platform built by Grab, Southeast Asia’s leading superapp. Since 2019, the GrabDefence team has shared its fraud management capabilities and platform with enterprises and startups to leverage Grab’s advanced AI/ML models, hyper local insights and patented device intelligence technologies. To learn more about GrabDefence or to speak to our fraud management experts, contact us at gd.contact@grabtaxi.com.", "enriched_content": "The machine learning approach described in this text chunk utilizes a graph convolutional network with an attention mechanism to detect anomalies in a fraud detection system. It leverages Grab's proprietary GrabDefence platform, which provides advanced AI/ML models, hyper-local insights, and patented device intelligence technologies to enterprises and startups for their fraud management needs.", "ml_techniques": ["graph_ml", "fraud_detection", "network_analysis"], "chunk_summary": "This text chunk outlines a graph-based machine learning approach for fraud detection, which leverages Grab's proprietary GrabDefence platform to offer advanced fraud prevention capabilities to enterprises and startups.", "keywords": ["graph_ml", "fraud_detection", "network_analysis", "attention_mechanism", "graph_convolutional_network", "GrabDefence", "device_intelligence"], "chunk_index": 15, "content_hash": "aec33fcb6acc72a3c694945bc31995be"}
{"chunk_id": "Grab_2022_16_1de9e90c", "source_title": "Graph for Fraud Detection", "source_url": "https://engineering.grab.com/graph-for-fraud-detection", "company": "Grab", "year": "2022", "original_content": "t GrabDefence or to speak to our fraud management experts, contact us at gd.contact@grabtaxi.com. Join us Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries. Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, join our team today! References T. Kipf and M.", "enriched_content": "Grab is the leading superapp platform in Southeast Asia, offering a wide range of on-demand services including ride-hailing, food delivery, package and grocery delivery, mobile payments, and financial services across 428 cities in eight countries. The company's mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If you are interested in joining Grab's team, you can contact the company's fraud management experts at gd.contact@grabtaxi.com.", "ml_techniques": ["graph_ml", "fraud_detection", "network_analysis"], "chunk_summary": "This text chunk introduces Grab, a leading superapp platform in Southeast Asia, and its mission to drive economic empowerment in the region through a wide range of on-demand services. It also provides contact information for the company's fraud management experts.", "keywords": ["superapp", "Southeast Asia", "on-demand services", "ride-hailing", "food delivery", "mobile payments", "financial services", "fraud management"], "chunk_index": 16, "content_hash": "1de9e90c7c34430d09bc9982a5e3deb3"}
{"chunk_id": "Grab_2022_17_3c9b6742", "source_title": "Graph for Fraud Detection", "source_url": "https://engineering.grab.com/graph-for-fraud-detection", "company": "Grab", "year": "2022", "original_content": "r everyone. If this mission speaks to you, join our team today! References T. Kipf and M. Welling, “Semi-supervised classification with graph convolutional networks,” in ICLR, 2017 ↩ Schlichtkrull, Michael, et al. “Modeling relational data with graph convolutional networks.” European semantic web conference. Springer, Cham, 2018. ↩ Fujiao Liu, Shuqi Wang, et al.. “Graph Networks - 10X investigation with Graph Visualisations”. Grab Tech Blog. ↩ Wang, Chen, et al.. “Deep Fraud Detection on Non-attributed Graph.” IEEE Big Data conference, PSBD, 2021. ↩", "enriched_content": "The paper describes a machine learning approach for detecting anomalies, particularly in the context of fraud detection. It utilizes graph convolutional networks (GCNs) to model relational data and leverage network analysis for identifying fraudulent activities. The approach aims to leverage the power of graph-based techniques to enhance fraud detection capabilities.", "ml_techniques": ["graph_ml", "fraud_detection", "network_analysis"], "chunk_summary": "This paper presents a graph-based machine learning approach for fraud detection, leveraging graph convolutional networks and network analysis to identify anomalies in relational data.", "keywords": ["graph_ml", "fraud_detection", "network_analysis", "graph_convolutional_networks", "semi-supervised_learning", "relational_data", "anomaly_detection"], "chunk_index": 17, "content_hash": "3c9b6742effd84ea1d58b99203499e82"}
{"chunk_id": "Netflix_2019_0_b635b541", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "Detecting Performance Anomalies in External Firmware DeploymentsNetflix Technology BlogFollow6 min read·Jan 31, 2019--ListenShareby Richard CoolNetflix has over 139M members streaming on more than half a billion devices spanning over 1,700 different types of devices from hundreds of brands. This diverse device ecosystem results in a high dimensionality feature space, often with sparse data, and can make identifying device performance issues challenging. Identifying ways to scale solutions in this space is vital as the ecosystem continues to grow both in volume and diversity. Streaming devices are also used on a wide range of networks which directly impact the delivered user experience.", "enriched_content": "What challenges does Netflix face in detecting performance anomalies across their device ecosystem? Netflix serves over 139M members streaming on more than half a billion devices, spanning over 1,700 different device types from hundreds of brands. How does this diversity impact anomaly detection? This diverse ecosystem creates a high dimensionality feature space with often sparse data, making it challenging to identify device performance issues. Why is scaling solutions important in this context? As the device ecosystem continues to grow in both volume and diversity, finding scalable solutions becomes vital for maintaining service quality. What additional factors affect user experience? Streaming devices operate on a wide range of networks, which directly impacts the delivered user experience and adds another layer of complexity to performance monitoring.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "Netflix faces challenges in detecting performance anomalies across 1,700+ device types serving 139M+ members due to high dimensionality and sparse data. The diverse device ecosystem and varying network conditions create complexity that requires scalable anomaly detection solutions.", "keywords": ["anomaly_detection", "high_dimensionality", "sparse_data", "device_performance", "scalability", "streaming_devices", "feature_space", "performance_monitoring"], "chunk_index": 0, "content_hash": "b635b541877e227c88ebd2305ab4279b"}
{"chunk_id": "Netflix_2019_1_00af07be", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "are also used on a wide range of networks which directly impact the delivered user experience. The video quality and app performance that can be delivered to a limited-memory mobile phone with a spotty cellular connection is quite different than what can be achieved on a cable set top box with high speed broadband; understanding how device characteristics and network behavior interact adds a layer of complexity in triaging potential device performance issues.We strive to ensure that when a member opens the Netflix app and presses play, they are presented with a high-quality experience every step of the way. Encountering an error page, waiting a very long time for video to begin playing, or having the video pause during playback, etc. are poor experiences, and we strive to minimize them.", "enriched_content": "How do device and network variations affect Netflix's performance monitoring? Device characteristics and network conditions create significant complexity in performance analysis - a mobile phone with limited memory on a cellular connection delivers vastly different performance than a cable set-top box with broadband. What user experience challenges does Netflix aim to address? Netflix focuses on eliminating poor experiences like error pages, long video startup times, and playback interruptions to ensure members consistently receive high-quality streaming from app launch to video playback.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "Netflix faces complex performance monitoring challenges due to varying device capabilities and network conditions across their platform. The company prioritizes eliminating poor user experiences like errors, delays, and interruptions to maintain consistent high-quality streaming.", "keywords": ["performance_monitoring", "user_experience", "device_characteristics", "network_behavior", "video_quality", "streaming_performance", "mobile_optimization", "playback_optimization"], "chunk_index": 1, "content_hash": "00af07beec30cb15bed8acbeff1d75bf"}
{"chunk_id": "Netflix_2019_2_07dcc8a1", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "ep of the way. Encountering an error page, waiting a very long time for video to begin playing, or having the video pause during playback, etc. are poor experiences, and we strive to minimize them. Previous blog posts have detailed the efforts of the Device Reliability Team (part 1, part 2) to identify issues and troubleshoot them and have given examples of the uses of machine learning to improve streaming quality.Device-related issues typically occur in one of two scenarios: (1) Netflix introduces a change to the app or backend servers that interacts badly with some devices or (2) a consumer electronics partner, browser developer, or operating system developer pushes a change (e.g. a firmware change or browser/OS change) that interacts poorly with our app.", "enriched_content": "What types of poor user experiences does Netflix aim to minimize through their anomaly detection approach? Netflix focuses on detecting issues like error pages, long video loading times, and playback interruptions. What are the two main scenarios where device-related streaming issues typically occur? First, when Netflix introduces changes to their app or backend servers that interact poorly with certain devices, and second, when external partners like consumer electronics manufacturers, browser developers, or operating system developers push updates (firmware, browser, or OS changes) that don't work well with Netflix's application.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "Netflix's Device Reliability Team uses machine learning for anomaly detection to identify and minimize poor streaming experiences like errors, delays, and interruptions. Device-related issues typically stem from either Netflix's own app/backend changes or external partner updates that interact poorly with Netflix's systems.", "keywords": ["anomaly_detection", "streaming_quality", "device_reliability", "performance_monitoring", "backend_servers", "firmware_updates", "playback_issues", "statistical_analysis"], "chunk_index": 2, "content_hash": "07dcc8a1ac7f151345027c3b388afbaa"}
{"chunk_id": "Netflix_2019_3_aef2991b", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "electronics partner, browser developer, or operating system developer pushes a change (e.g. a firmware change or browser/OS change) that interacts poorly with our app. While we have tools for dealing with the first scenario (for example, automated canary analysis using Kayenta), the second type previously was only detected when the update had reached a sufficient volume of devices to shift core performance metrics. Being able to quickly identify firmware updates that result in poorer member experience allows us to minimize the impact of these issues and work with device partners to root-cause problems.Figure 1 — Monthly number of firmware releases seen on consumer electronics devices streaming Netflix.", "enriched_content": "How does Netflix detect performance issues caused by external partners' updates? Netflix faces two main scenarios when external partners (electronics manufacturers, browser developers, or OS developers) push changes like firmware or software updates that negatively interact with their app. While they have automated tools like Kayenta for canary analysis to handle the first scenario, the second type of issue was previously only detected after updates reached enough devices to impact core performance metrics. By quickly identifying problematic firmware updates, Netflix can minimize member experience impact and collaborate with device partners for root-cause analysis, as evidenced by the monthly volume of firmware releases across consumer electronics devices streaming Netflix.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "Netflix addresses performance degradation caused by external partner updates (firmware, browser, OS changes) that negatively affect their streaming app. Quick identification of problematic updates helps minimize user impact and enables faster collaboration with partners for issue resolution.", "keywords": ["firmware updates", "canary analysis", "performance monitoring", "device compatibility", "external dependencies", "impact detection", "root-cause analysis", "Kayenta"], "chunk_index": 3, "content_hash": "aef2991b894e9b1387aa633366a4cb05"}
{"chunk_id": "Netflix_2019_4_9e896fda", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "problems.Figure 1 — Monthly number of firmware releases seen on consumer electronics devices streaming Netflix.Figure 1 shows that the rate at which our consumer electronics device partners are pushing new firmware is growing rapidly. In 2018, our partners pushed over 500 firmware pushes a month; this value will likely pass 1,000 firmware upgrades per month by 2020. Often firmware rollouts begin slowly with a fraction of all devices receiving the new firmware for several days before the rest of the devices are upgraded. These rollouts are not random; often a specific subset of devices are targeted for new firmwares and sometimes rollouts target specific geographic regions.", "enriched_content": "What challenges does Netflix face with firmware releases on consumer electronics devices? Netflix observes rapidly increasing firmware release rates from their consumer electronics device partners, with over 500 firmware pushes per month in 2018 and projections exceeding 1,000 per month by 2020. How are these firmware rollouts typically deployed? Firmware rollouts follow staged deployment patterns, starting with a small fraction of devices for several days before expanding to all devices. Are these rollouts random in nature? No, these rollouts are strategic and non-random, often targeting specific device subsets or geographic regions rather than being distributed randomly across the device population.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "Netflix faces rapidly increasing firmware release rates from device partners, growing from 500+ monthly releases in 2018 to projected 1,000+ by 2020. These firmware rollouts follow non-random, staged deployment patterns targeting specific device subsets or geographic regions.", "keywords": ["firmware_releases", "staged_deployment", "consumer_electronics", "performance_monitoring", "device_targeting", "geographic_rollouts", "release_frequency", "Netflix"], "chunk_index": 4, "content_hash": "9e896fda342f61c2a66e77d442aebdaa"}
{"chunk_id": "Netflix_2019_5_3bae513f", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "eted for new firmwares and sometimes rollouts target specific geographic regions. Naive analysis of metric changes between new firmwares and devices on older firmwares can be confounded by the non-random rollout, so it’s important to control for this when asking if a new firmware has negatively impacted the Netflix member experience.Putting the Pieces TogetherConsider the case of a metric which follows the grey distribution (with a mean value of ~ 4,570) shown in Figure 2. We see a new firmware deploy in the field (red distribution) which follows an approximately normal distribution with noticeably higher mean of 5,600, indicating that devices using the new firmware have a poor experience than the mean of the full device population.", "enriched_content": "How does Netflix handle firmware rollout analysis and what challenges arise? Netflix faces complications when analyzing metric changes between new and old firmwares because rollouts are non-random - they target specific device types or geographic regions. This non-random deployment can confound naive statistical comparisons, making it crucial to control for these factors when evaluating firmware impact on user experience. What does a practical example of firmware impact detection look like? Consider a baseline metric following a grey distribution with mean ~4,570. When a new firmware deploys, the resulting red distribution shows a normal pattern but with a significantly higher mean of 5,600, clearly indicating that devices running the new firmware deliver worse user experience compared to the overall device population.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "Netflix addresses challenges in firmware rollout analysis where non-random deployment patterns can confound statistical comparisons between old and new firmware performance. A practical example demonstrates detecting firmware impact through distribution comparison, showing how a new firmware's higher metric mean (5,600 vs 4,570) indicates degraded user experience.", "keywords": ["firmware_rollout_analysis", "statistical_confounding", "non-random_deployment", "distribution_comparison", "performance_metrics", "user_experience_monitoring", "anomaly_detection", "A/B_testing"], "chunk_index": 5, "content_hash": "3bae513fbcd8d2d6d26b06969db06c60"}
{"chunk_id": "Netflix_2019_6_ef4c6a5b", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "eably higher mean of 5,600, indicating that devices using the new firmware have a poor experience than the mean of the full device population. Should we be concerned that the new firmware has resulted in lower performance than prior versions?Figure 2 — Left: Hypothetical distribution of a device performance metric between the control sample of devices (grey) and a population of the same devices which have been upgraded to a new firmware (red). Right: The control sample (red) has been broken into multiple sub-components (grey) based on geographic region.If the devices running the new firmware were a random subsample of the control sample, we very likely should be concerned.", "enriched_content": "How do we determine if firmware upgrades are causing performance degradation in device populations? When comparing device performance metrics, we observe that devices with new firmware show a considerably higher mean of 5,600 compared to the overall device population mean, suggesting these devices experience poorer performance. But should this difference raise concerns about the new firmware's impact on performance compared to previous versions? The key consideration is whether the devices running new firmware represent a random subsample of the control group - if so, the performance difference would indeed be concerning and warrant investigation.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "This chunk discusses comparing device performance metrics between firmware versions to detect potential performance degradation. It emphasizes the importance of proper sampling methodology when evaluating whether firmware updates negatively impact device performance.", "keywords": ["firmware_performance_analysis", "control_group_comparison", "device_metrics", "performance_degradation", "random_sampling", "statistical_comparison", "A/B_testing", "population_analysis"], "chunk_index": 6, "content_hash": "ef4c6a5bd67b55602a7d2b33a71e2d76"}
{"chunk_id": "Netflix_2019_7_0c67ace1", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "ere a random subsample of the control sample, we very likely should be concerned. Unfortunately, this is not an assumption we can make when working with firmware deployments with our consumer electronics partners. In this example, we can break down the control sample by geographic region (right panel of Figure 2) and see that the control sample is an aggregation of distinct distributions from each region. If our partners roll out a new firmware preferentially to some regions compared to others, we must correct for this effect before quantifying any changes in performance metrics on devices with the new firmware.Figure 3 — Comparison of the treatment sample distribution (red) with one of the randomly matched control samples (grey) using the methodology described in the text.", "enriched_content": " Q: What challenges arise when analyzing firmware deployment performance across different geographic regions? A: When working with firmware deployments with consumer electronics partners, we cannot assume that the control sample represents a random subsample of the overall population. The control sample is actually an aggregation of distinct distributions from each geographic region. If partners roll out new firmware preferentially to certain regions over others, this creates a bias that must be corrected before we can accurately quantify any changes in performance metrics on devices with the new firmware. Q: How can geographic bias in firmware deployments be addressed? A: We can break down the control sample by geographic region to identify distinct distributions, then use random matching methodology to create comparable treatment and control samples that account for regional differences, as shown in Figure 3's comparison of treatment sample distribution with randomly matched control samples.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": " This chunk discusses challenges in firmware deployment analysis where geographic bias affects control samples, requiring correction methods before measuring performance changes. It explains how regional distribution differences must be accounted for when partners deploy firmware non-uniformly across geographic areas.", "keywords": ["control_sample", "treatment_sample", "geographic_bias", "firmware_deployment", "random_matching", "distribution_correction", "performance_metrics", "sampling_bias"], "chunk_index": 7, "content_hash": "0c67ace1eac8b061ab28aec0cbc45f40"}
{"chunk_id": "Netflix_2019_8_2dad30a5", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "h the new firmware.Figure 3 — Comparison of the treatment sample distribution (red) with one of the randomly matched control samples (grey) using the methodology described in the text. While the treatment sample has a larger mean metric value than the full control sample shown in Figure 2, when we account for the fact that the treatment sample came from a different population than the control sample, we can see that treatment sample has a lower mean (which is an improved member experience in this case).We created a framework, Jigsaw, which allows data scientists and engineering teams at Netflix to understand changes in metrics with biased treatment populations. For each treatment sample, we create a Monte Carlo “matched” sample from our control sample.", "enriched_content": "How does Netflix handle biased treatment populations when analyzing metric changes? Netflix developed a framework called Jigsaw that addresses this challenge by creating Monte Carlo \"matched\" samples from control groups. What does the comparison in Figure 3 demonstrate? It shows how the treatment sample (red) compares against a randomly matched control sample (grey), revealing that while the treatment sample initially appeared to have a larger mean metric value than the full control sample, proper population matching revealed the treatment actually had a lower mean, indicating improved member experience. Why is this matching methodology important? It allows data scientists and engineering teams to accurately understand metric changes by accounting for the fact that treatment and control samples often come from different underlying populations.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "Netflix's Jigsaw framework uses Monte Carlo matched sampling to compare treatment and control groups while accounting for population bias. The methodology revealed that proper matching can reverse initial conclusions about metric performance, showing treatment groups may actually perform better than initially apparent.", "keywords": ["Monte Carlo sampling", "matched control groups", "population bias", "metric comparison", "treatment analysis", "statistical matching", "Jigsaw framework", "A/B testing"], "chunk_index": 8, "content_hash": "2dad30a5d0dfbf37739255f691b9194c"}
{"chunk_id": "Netflix_2019_9_dc8573c9", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "x to understand changes in metrics with biased treatment populations. For each treatment sample, we create a Monte Carlo “matched” sample from our control sample. This matched sample is constructed to mirror the same property distribution as the treatment sample using a list of user-specified dimensions. In our example above, we would construct a matched control sample that follows the same geographic distribution as the devices in the treatment sample. This process is not limited to one dimension — in practice, we often match on geographic dimensions as well as key device characteristics (such as device model or device model year). Increasing the number of dimensions used in the matching, however, can lead to data sparsity issues.", "enriched_content": "How does Netflix handle biased treatment populations when analyzing metric changes? Netflix creates Monte Carlo \"matched\" samples from control data that mirror the property distribution of treatment samples using user-specified dimensions. For example, if analyzing device performance, they construct a matched control sample with the same geographic distribution as the treatment devices. Can this matching process use multiple dimensions? Yes, Netflix typically matches on both geographic dimensions and key device characteristics like device model or model year, though using too many dimensions can create data sparsity problems.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "Netflix uses Monte Carlo sampling to create matched control groups that mirror treatment population characteristics across multiple dimensions. The matching process helps reduce bias but must balance dimensionality with data sparsity concerns.", "keywords": ["Monte Carlo sampling", "matched sampling", "control groups", "treatment populations", "bias reduction", "dimensionality matching", "data sparsity", "population matching"], "chunk_index": 9, "content_hash": "dc8573c9b71caee9caba89bf66ba7054"}
{"chunk_id": "Netflix_2019_10_7f105add", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "h as device model or device model year). Increasing the number of dimensions used in the matching, however, can lead to data sparsity issues. For our analysis we typically limit matching to one or two device properties to ensure sufficient data. Once we have compared the metric distributions for both the matched control and treatment samples, we repeat the Monte Carlo matching procedure multiple times to estimate the probability that the treatment sample could have been drawn from the control sample given the sampling uncertainties. Figure 3 shows one matched sample realization in the example described above.", "enriched_content": "How does Netflix handle dimensional matching in their anomaly detection system? They increase matching dimensions using device properties like device model or model year, but this can create data sparsity problems. To address this, they typically limit matching to one or two device properties to ensure they have sufficient data for analysis. What statistical method do they use to validate their results? After comparing metric distributions between matched control and treatment samples, they employ a Monte Carlo matching procedure that runs multiple iterations. This estimates the probability that the treatment sample could have originated from the control sample while accounting for sampling uncertainties. How do they visualize their results? Figure 3 demonstrates one matched sample realization from their example analysis.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "Netflix limits dimensional matching to 1-2 device properties to avoid data sparsity while ensuring statistical validity. They use Monte Carlo sampling procedures to estimate probabilities and account for sampling uncertainties in their anomaly detection system.", "keywords": ["dimensional_matching", "data_sparsity", "Monte_Carlo_sampling", "control_treatment_analysis", "sampling_uncertainties", "metric_distributions", "device_properties", "statistical_validation"], "chunk_index": 10, "content_hash": "7f105add295b7d15237e30408303837e"}
{"chunk_id": "Netflix_2019_11_a2135402", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "described above. While the treatment sample has a higher mean metric in the overall comparison, controlling for differences in the underlying population show that the treatment cell has actually lowered the metric and improved our member experience.The Bigger PictureFigure 4 — Workflow diagram illustrating the daily cycle of Jigsaw alerts.The introduction of Jigsaw into the Netflix device reliability engineering team’s workflow quickly made direct impact on our members’ experiences. During the summer of 2018, two device performance deteriorations were detected while the culpable new firmware was only present on 0.5% of the several million potentially impacted devices.", "enriched_content": "How effective was Netflix's Jigsaw anomaly detection system in real-world deployment? When controlling for population differences, the treatment group showed improved member experience metrics despite having a higher overall mean. What impact did Jigsaw have on Netflix's device reliability workflow? Jigsaw was integrated into the daily operational cycle and made immediate impact on member experiences. How sensitive was the system in detecting performance issues? During summer 2018, Jigsaw successfully detected two critical device performance deteriorations when problematic firmware was present on only 0.5% of several million potentially affected devices, demonstrating high sensitivity for early detection.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "Netflix's Jigsaw anomaly detection system was successfully integrated into daily device reliability workflows and demonstrated high sensitivity by detecting performance issues affecting only 0.5% of devices. The system showed measurable improvements in member experience when controlling for population differences.", "keywords": ["anomaly_detection", "device_reliability", "performance_monitoring", "statistical_analysis", "firmware_detection", "workflow_automation", "member_experience", "early_detection"], "chunk_index": 11, "content_hash": "a2135402da29cdca23f5a8f16e061d7a"}
{"chunk_id": "Netflix_2019_12_57ad3313", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "as only present on 0.5% of the several million potentially impacted devices. With the early alerts from Jigsaw, the device reliability team was able to work with our consumer electronics partners to correct the problem and prevent millions of users from experiencing errors during playback. Work is underway to use the Jigsaw framework to understand more than firmware changes, as well. Comparing metrics between two web browser software versions or operating system versions is aiding several of the Netflix engineering teams understand the effects of in-field software changes on performance metrics.Netflix members have many options when it comes to entertainment. We strive to provide the best possible experience each time anyone launches Netflix.", "enriched_content": "How effective was Netflix's Jigsaw anomaly detection framework in preventing widespread device issues? The framework successfully identified a critical firmware problem that was present on only 0.5% of several million potentially impacted devices, enabling early alerts that allowed the device reliability team to collaborate with consumer electronics partners to correct the issue before millions of users experienced playback errors. What are the planned expansions for the Jigsaw framework beyond firmware monitoring? Netflix is extending Jigsaw's capabilities to compare performance metrics between different web browser software versions and operating system versions, helping multiple engineering teams understand how in-field software changes affect performance metrics and ultimately supporting Netflix's goal of providing the best possible user experience.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "Netflix's Jigsaw framework successfully detected a rare firmware issue affecting 0.5% of devices, preventing widespread user impact through early intervention with hardware partners. The framework is being expanded beyond firmware monitoring to analyze software version changes and their performance impacts across different platforms.", "keywords": ["Jigsaw_framework", "anomaly_detection", "firmware_monitoring", "early_alert_system", "performance_metrics", "device_reliability", "software_version_comparison", "Netflix_engineering"], "chunk_index": 12, "content_hash": "57ad33135698ce11c3924e1bf24e6cc4"}
{"chunk_id": "Netflix_2019_13_66944274", "source_title": "Detecting Performance Anomalies in External Firmware Deployments", "source_url": "https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46", "company": "Netflix", "year": "2019", "original_content": "s.Netflix members have many options when it comes to entertainment. We strive to provide the best possible experience each time anyone launches Netflix. By enriching our device performance monitoring with automated anomaly detection, we can scale our efforts as the device ecosystem continues to grow and evolve. Through being proactive rather than reacting to issues after they have had wide impact, we protect our members from poor experiences, empowering them to continue to find more moments of uninterrupted joy.Check out the Netflix Research Page if you want to learn more. We are always looking for new stunning colleagues to join us!", "enriched_content": "How does Netflix ensure optimal streaming experience for its members across diverse devices? Netflix addresses this challenge by implementing automated anomaly detection systems integrated with device performance monitoring. What are the benefits of this approach? This enables Netflix to scale their monitoring efforts effectively as the device ecosystem expands, while shifting from reactive to proactive issue resolution. Why is this proactive approach important? By detecting and addressing performance issues before they impact users widely, Netflix protects members from poor streaming experiences and maintains uninterrupted entertainment enjoyment.", "ml_techniques": ["statistical_analysis", "anomaly_detection", "performance_monitoring"], "chunk_summary": "Netflix uses automated anomaly detection integrated with device performance monitoring to proactively identify and resolve streaming issues before they impact users. This approach enables scalable monitoring across their growing device ecosystem while ensuring optimal member experience.", "keywords": ["automated anomaly detection", "device performance monitoring", "proactive monitoring", "scalable systems", "user experience optimization", "streaming performance", "Netflix platform"], "chunk_index": 13, "content_hash": "66944274417d47d2066d98a62224b3d8"}
